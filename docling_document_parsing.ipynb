{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Parsing with Docling for RAG Systems\n",
    "\n",
    "## A Comprehensive Guide to Document Conversion and Processing\n",
    "\n",
    "This notebook demonstrates the powerful document parsing capabilities of **Docling** (v2.55.1), a Python library developed by IBM for converting various document formats into structured representations suitable for AI/ML workflows, particularly Retrieval-Augmented Generation (RAG) systems.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Basic Document Conversion** - Convert PDFs and other formats to Markdown, JSON, HTML\n",
    "2. **Multiple File Formats** - PDF, DOCX, XLSX, PPTX, HTML, Markdown, Images, Audio\n",
    "3. **Pipeline Configuration** - OCR engines, table extraction, layout analysis, VLM\n",
    "4. **LangChain Integration** - DoclingLoader and RAG pipeline with Chroma\n",
    "5. **Advanced Topics** - Enrichment, error handling\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3.12 (recommended for full compatibility)\n",
    "- OpenAI API key (for RAG examples)\n",
    "- Sufficient disk space for model downloads (~2-4GB)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup\n",
    "\n",
    "### 1.1 Create Python 3.12 Virtual Environment\n",
    "\n",
    "```bash\n",
    "# Create virtual environment with Python 3.12\n",
    "python3.12 -m venv .venv\n",
    "\n",
    "# Activate the environment\n",
    "source .venv/bin/activate  # On macOS/Linux\n",
    "# .venv\\Scripts\\activate  # On Windows\n",
    "```\n",
    "\n",
    "### 1.2 Install Dependencies\n",
    "\n",
    "Run the following commands in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m116 packages\u001b[0m \u001b[2min 1.40s\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)                                                  \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)------------------\u001b[0m\u001b[0m     0 B/60.83 KiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)------------------\u001b[0m\u001b[0m     0 B/60.83 KiB           \u001b[1A\n",
      "\u001b[2mmarko               \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/41.69 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)------------------\u001b[0m\u001b[0m     0 B/60.83 KiB           \u001b[2A\n",
      "\u001b[2mmarko               \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/41.69 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)------------------\u001b[0m\u001b[0m     0 B/60.83 KiB           \u001b[2A\n",
      "\u001b[2mmarko               \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/41.69 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)------------------\u001b[0m\u001b[0m     0 B/60.83 KiB           \u001b[2A\n",
      "\u001b[2mjsonlines           \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/8.50 KiB\n",
      "\u001b[2mmarko               \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/41.69 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)------------------\u001b[0m\u001b[0m     0 B/60.83 KiB           \u001b[3A\n",
      "\u001b[2mjsonlines           \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/8.50 KiB\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/41.69 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)------------------\u001b[0m\u001b[0m     0 B/60.83 KiB           \u001b[3A\n",
      "\u001b[2mjsonlines             \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/8.50 KiB\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/41.69 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)------------------\u001b[0m\u001b[0m     0 B/60.83 KiB           \u001b[3A\n",
      "\u001b[2mjsonlines             \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/8.50 KiB\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/41.69 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/60.83 KiB         \u001b[3A\n",
      "\u001b[2mjsonlines             \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/8.50 KiB\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/41.69 KiB\n",
      "\u001b[2mtree-sitter-java      \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/294.93 KiB        \u001b[4A\n",
      "\u001b[2mjsonlines             \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/8.50 KiB\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 16.00 KiB/41.69 KiB\n",
      "\u001b[2mtree-sitter-java      \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/294.93 KiB        \u001b[4A\n",
      "\u001b[2mjsonlines             \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 8.50 KiB/8.50 KiB\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 16.00 KiB/41.69 KiB\n",
      "\u001b[2mtree-sitter-java      \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/294.93 KiB        \u001b[4A\n",
      "\u001b[2mjsonlines             \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 8.50 KiB/8.50 KiB\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 16.00 KiB/41.69 KiB\n",
      "\u001b[2mtree-sitter-java      \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/294.93 KiB        \u001b[4A\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 16.00 KiB/41.69 KiB\n",
      "\u001b[2mtree-sitter-java      \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/294.93 KiB        \u001b[3A\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 32.00 KiB/41.69 KiB\n",
      "\u001b[2mtree-sitter-java      \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/294.93 KiB        \u001b[3A\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 32.00 KiB/41.69 KiB\n",
      "\u001b[2mtree-sitter-java      \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/294.93 KiB        \u001b[3A\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 32.00 KiB/41.69 KiB\n",
      "\u001b[2mtree-sitter-java      \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/294.93 KiB        \u001b[3A\n",
      "\u001b[2mmarko                 \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 32.00 KiB/41.69 KiB\n",
      "\u001b[2mtree-sitter-java      \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/294.93 KiB        \u001b[3A\n",
      "\u001b[2mtree-sitter-java      \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.83 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/294.93 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/1.89 MiB          \u001b[3A\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/294.93 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/1.89 MiB          \u001b[2A\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/294.93 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)--------------------\u001b[0m\u001b[0m     0 B/1.89 MiB          \u001b[2A\n",
      "\u001b[2mpolyfactory           \u001b[0m \u001b[32m--------------------\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 42.01 KiB/60.39 KiB\n",
      "\u001b[2mtree-sitter-javascript\u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 30.90 KiB/64.88 KiB\n",
      "\u001b[2mtree-sitter-python    \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 48.00 KiB/74.89 KiB\n",
      "\u001b[2mlangchain-openai      \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 30.88 KiB/82.31 KiB\n",
      "\u001b[2mtree-sitter-c         \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 32.00 KiB/84.28 KiB\n",
      "\u001b[2mdocling-ibm-models    \u001b[0m \u001b[32m----------------\u001b[30m\u001b[2m--------------\u001b[0m\u001b[0m 47.89 KiB/85.31 KiB\n",
      "\u001b[2mtree-sitter           \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 32.00 KiB/134.48 KiB\n",
      "\u001b[2mdocling-core          \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 48.00 KiB/195.47 KiB\n",
      "\u001b[2mtifffile              \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 30.91 KiB/225.74 KiB\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 32.00 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 48.00 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 30.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 20.34 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 30.91 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 32.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 48.00 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 30.75 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 32.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[19A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)-------------------\u001b[0m\u001b[0m 32.00 KiB/13.94 MiB       \u001b[19A\n",
      "\u001b[2mtree-sitter-javascript\u001b[0m \u001b[32m-----------------------------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 62.90 KiB/64.88 KiB\n",
      "\u001b[2mtree-sitter-python    \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 63.97 KiB/74.89 KiB\n",
      "\u001b[2mlangchain-openai      \u001b[0m \u001b[32m----------------------\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 62.88 KiB/82.31 KiB\n",
      "\u001b[2mtree-sitter-c         \u001b[0m \u001b[32m----------------------\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 64.00 KiB/84.28 KiB\n",
      "\u001b[2mdocling-ibm-models    \u001b[0m \u001b[32m----------------------\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 64.00 KiB/85.31 KiB\n",
      "\u001b[2mtree-sitter           \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 64.00 KiB/134.48 KiB\n",
      "\u001b[2mdocling-core          \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 64.00 KiB/195.47 KiB\n",
      "\u001b[2mtifffile              \u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 62.91 KiB/225.74 KiB\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 63.89 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 79.14 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 46.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 52.34 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 62.91 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 63.89 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 78.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 62.75 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 63.89 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[18A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)-------------------\u001b[0m\u001b[0m 64.00 KiB/13.94 MiB       \u001b[18A\n",
      "\u001b[2mtree-sitter-python    \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 63.97 KiB/74.89 KiB\n",
      "\u001b[2mlangchain-openai      \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 78.88 KiB/82.31 KiB\n",
      "\u001b[2mtree-sitter-c         \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 80.00 KiB/84.28 KiB\n",
      "\u001b[2mdocling-ibm-models    \u001b[0m \u001b[32m----------------------\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 64.00 KiB/85.31 KiB\n",
      "\u001b[2mtree-sitter           \u001b[0m \u001b[32m-----------------\u001b[30m\u001b[2m-------------\u001b[0m\u001b[0m 79.52 KiB/134.48 KiB\n",
      "\u001b[2mdocling-core          \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 80.00 KiB/195.47 KiB\n",
      "\u001b[2mtifffile              \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 78.91 KiB/225.74 KiB\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 64.00 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 79.14 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 62.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 78.91 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 64.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 78.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 77.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 64.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[17A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)-------------------\u001b[0m\u001b[0m 64.00 KiB/13.94 MiB       \u001b[17A\n",
      "\u001b[2mlangchain-openai      \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 78.88 KiB/82.31 KiB\n",
      "\u001b[2mtree-sitter-c         \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 84.28 KiB/84.28 KiB\n",
      "\u001b[2mdocling-ibm-models    \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 80.00 KiB/85.31 KiB\n",
      "\u001b[2mtree-sitter           \u001b[0m \u001b[32m---------------------\u001b[30m\u001b[2m---------\u001b[0m\u001b[0m 95.52 KiB/134.48 KiB\n",
      "\u001b[2mdocling-core          \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 96.00 KiB/195.47 KiB\n",
      "\u001b[2mtifffile              \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 94.91 KiB/225.74 KiB\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 80.00 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 111.14 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 78.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 80.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 78.91 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 64.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 110.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 77.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 80.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[16A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)-------------------\u001b[0m\u001b[0m 80.67 KiB/13.94 MiB       \u001b[16A\n",
      "\u001b[2mlangchain-openai      \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 82.31 KiB/82.31 KiB\n",
      "\u001b[2mdocling-ibm-models    \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 80.00 KiB/85.31 KiB\n",
      "\u001b[2mtree-sitter           \u001b[0m \u001b[32m---------------------\u001b[30m\u001b[2m---------\u001b[0m\u001b[0m 95.52 KiB/134.48 KiB\n",
      "\u001b[2mdocling-core          \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 96.00 KiB/195.47 KiB\n",
      "\u001b[2mtifffile              \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 94.91 KiB/225.74 KiB\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 80.00 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 111.14 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 78.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 80.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 94.91 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 80.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 110.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 93.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 80.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[15A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)-------------------\u001b[0m\u001b[0m 80.67 KiB/13.94 MiB       \u001b[15A\n",
      "\u001b[2mdocling-ibm-models    \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 80.00 KiB/85.31 KiB\n",
      "\u001b[2mtree-sitter           \u001b[0m \u001b[32m---------------------\u001b[30m\u001b[2m---------\u001b[0m\u001b[0m 95.52 KiB/134.48 KiB\n",
      "\u001b[2mdocling-core          \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 96.00 KiB/195.47 KiB\n",
      "\u001b[2mtifffile              \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 94.91 KiB/225.74 KiB\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 80.00 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 111.14 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 78.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 80.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 94.91 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 80.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 110.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 93.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 80.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[14A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)-------------------\u001b[0m\u001b[0m 80.67 KiB/13.94 MiB       \u001b[14A\n",
      "\u001b[2mdocling-ibm-models    \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 80.18 KiB/85.31 KiB\n",
      "\u001b[2mtree-sitter           \u001b[0m \u001b[32m------------------------\u001b[30m\u001b[2m------\u001b[0m\u001b[0m 111.52 KiB/134.48 KiB\n",
      "\u001b[2mdocling-core          \u001b[0m \u001b[32m-----------------\u001b[30m\u001b[2m-------------\u001b[0m\u001b[0m 112.00 KiB/195.47 KiB\n",
      "\u001b[2mtifffile              \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 110.91 KiB/225.74 KiB\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 80.00 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 111.14 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 78.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 80.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 94.91 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 80.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 126.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 93.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 96.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[14A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)-------------------\u001b[0m\u001b[0m 80.67 KiB/13.94 MiB       \u001b[14A\n",
      "\u001b[2mtree-sitter           \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 127.52 KiB/134.48 KiB\n",
      "\u001b[2mdocling-core          \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 128.00 KiB/195.47 KiB\n",
      "\u001b[2mtifffile              \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 110.91 KiB/225.74 KiB\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 96.00 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 127.14 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 94.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 96.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 110.91 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 96.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 126.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 93.58 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 96.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[13A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)-------------------\u001b[0m\u001b[0m 96.00 KiB/13.94 MiB       \u001b[13A\n",
      "\u001b[2mdocling-core          \u001b[0m \u001b[32m------------------------\u001b[30m\u001b[2m------\u001b[0m\u001b[0m 160.00 KiB/195.47 KiB\n",
      "\u001b[2mtifffile              \u001b[0m \u001b[32m------------------\u001b[30m\u001b[2m------------\u001b[0m\u001b[0m 142.91 KiB/225.74 KiB\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 128.00 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m----------------\u001b[30m\u001b[2m--------------\u001b[0m\u001b[0m 159.04 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 126.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 128.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 142.91 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 128.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 158.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 125.58 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 128.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[12A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)-------------------\u001b[0m\u001b[0m 128.00 KiB/13.94 MiB      \u001b[12A\n",
      "\u001b[2mtifffile              \u001b[0m \u001b[32m---------------------------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 206.06 KiB/225.74 KiB\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m----------------------\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 191.78 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m---------------------\u001b[30m\u001b[2m---------\u001b[0m\u001b[0m 207.14 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m------------------\u001b[30m\u001b[2m------------\u001b[0m\u001b[0m 190.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m---------------\u001b[30m\u001b[2m---------------\u001b[0m\u001b[0m 191.78 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 206.06 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 180.72 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 238.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 189.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 192.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[11A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/23)-------------------\u001b[0m\u001b[0m 192.00 KiB/13.94 MiB      \u001b[11A\n",
      "\u001b[2mtifffile              \u001b[0m \u001b[32m---------------------------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 206.06 KiB/225.74 KiB\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m----------------------\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 192.00 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m----------------------\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 223.14 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m--------------------\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 206.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m---------------\u001b[30m\u001b[2m---------------\u001b[0m\u001b[0m 191.78 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 206.06 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 180.72 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 254.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 205.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 192.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[11A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/23)------------------\u001b[0m\u001b[0m 208.00 KiB/13.94 MiB      \u001b[11A\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m------------------------\u001b[30m\u001b[2m------\u001b[0m\u001b[0m 208.00 KiB/257.01 KiB\n",
      "\u001b[2mtree-sitter-typescript\u001b[0m \u001b[32m---------------------------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 271.14 KiB/294.93 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 238.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m----------------\u001b[30m\u001b[2m--------------\u001b[0m\u001b[0m 208.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m----------------\u001b[30m\u001b[2m--------------\u001b[0m\u001b[0m 239.70 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 208.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 286.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 236.69 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 240.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[10A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/23)------------------\u001b[0m\u001b[0m 224.00 KiB/13.94 MiB      \u001b[10A\n",
      "\u001b[2mpython-bidi           \u001b[0m \u001b[32m-----------------------------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 256.00 KiB/257.01 KiB\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m--------------------------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 270.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m--------------------\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 256.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m------------------\u001b[30m\u001b[2m------------\u001b[0m\u001b[0m 270.06 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 256.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 318.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 269.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 257.41 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[9A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/23)-------------------\u001b[0m\u001b[0m 272.00 KiB/13.94 MiB      \u001b[9A\n",
      "\u001b[2mimageio               \u001b[0m \u001b[32m--------------------------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 270.88 KiB/310.20 KiB\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m--------------------\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 256.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 286.06 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 256.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 318.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 269.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 273.41 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[8A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/23)-------------------\u001b[0m\u001b[0m 288.00 KiB/13.94 MiB      \u001b[8A\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 288.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m----------------------\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 334.06 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 305.30 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 366.43 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 301.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 320.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/23)-------------------\u001b[0m\u001b[0m 320.00 KiB/13.94 MiB      \u001b[7A\n",
      "\u001b[2maccelerate            \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 320.00 KiB/372.01 KiB\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m--------------------------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 378.64 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 352.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 398.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 333.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 384.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/23)-------------------\u001b[0m\u001b[0m 352.00 KiB/13.94 MiB      \u001b[7A\n",
      "\u001b[2msafetensors           \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 414.06 KiB/436.58 KiB\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 384.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 446.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 365.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 416.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[6A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/23)-------------------\u001b[0m\u001b[0m 400.00 KiB/13.94 MiB      \u001b[6A\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 400.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 462.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 397.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 448.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/23)-------------------\u001b[0m\u001b[0m 432.00 KiB/13.94 MiB      \u001b[5A\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 592.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 622.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 589.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 672.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/23)-------------------\u001b[0m\u001b[0m 608.00 KiB/13.94 MiB      \u001b[5A\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 767.33 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 766.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 733.03 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 848.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/23)-------------------\u001b[0m\u001b[0m 731.04 KiB/13.94 MiB      \u001b[5A\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 880.00 KiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-------------\u001b[30m\u001b[2m-----------------\u001b[0m\u001b[0m 894.54 KiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 860.92 KiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 976.00 KiB/11.44 MiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/23)-------------------\u001b[0m\u001b[0m 891.04 KiB/13.94 MiB      \u001b[5A\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m------------------\u001b[30m\u001b[2m------------\u001b[0m\u001b[0m 1.13 MiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m----------------\u001b[30m\u001b[2m--------------\u001b[0m\u001b[0m 1.02 MiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m----------------\u001b[30m\u001b[2m--------------\u001b[0m\u001b[0m 1.08 MiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 1.20 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/23)-------------------\u001b[0m\u001b[0m 1.14 MiB/13.94 MiB        \u001b[5A\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m----------------------\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 1.33 MiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m--------------------\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 1.27 MiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m--------------------\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 1.31 MiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 1.44 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/23)-------------------\u001b[0m\u001b[0m 1.34 MiB/13.94 MiB        \u001b[5A\n",
      "\u001b[2mtorchvision           \u001b[0m \u001b[32m--------------------------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 1.56 MiB/1.80 MiB\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 1.50 MiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 1.55 MiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 1.73 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/23)-------------------\u001b[0m\u001b[0m 1.64 MiB/13.94 MiB        \u001b[5A\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m---------------------------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 1.70 MiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m---------------------------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 1.81 MiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 2.05 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/23)-------------------\u001b[0m\u001b[0m 1.87 MiB/13.94 MiB        \u001b[4A\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m---------------------------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 1.70 MiB/1.89 MiB\n",
      "\u001b[2mnetworkx              \u001b[0m \u001b[32m---------------------------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 1.81 MiB/1.97 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 2.06 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/23)-------------------\u001b[0m\u001b[0m 1.87 MiB/13.94 MiB        \u001b[4A\n",
      "\u001b[2mfaker                 \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 1.80 MiB/1.89 MiB\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 2.22 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/23)-------------------\u001b[0m\u001b[0m 2.06 MiB/13.94 MiB        \u001b[3A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 2.27 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/23)-------------------\u001b[0m\u001b[0m 2.07 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 2.50 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)-------------------\u001b[0m\u001b[0m 2.35 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 3.17 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)-------------------\u001b[0m\u001b[0m 3.00 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 3.95 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)-------------------\u001b[0m\u001b[0m 3.42 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 4.69 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)-------------------\u001b[0m\u001b[0m 4.04 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m-------------\u001b[30m\u001b[2m-----------------\u001b[0m\u001b[0m 5.23 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)-------------------\u001b[0m\u001b[0m 4.70 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m---------------\u001b[30m\u001b[2m---------------\u001b[0m\u001b[0m 6.03 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)-------------------\u001b[0m\u001b[0m 5.06 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m----------------\u001b[30m\u001b[2m--------------\u001b[0m\u001b[0m 6.19 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)2m-----------------\u001b[0m\u001b[0m 6.05 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m------------------\u001b[30m\u001b[2m------------\u001b[0m\u001b[0m 6.89 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)[2m----------------\u001b[0m\u001b[0m 6.75 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 7.36 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)\u001b[2m---------------\u001b[0m\u001b[0m 7.02 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m---------------------\u001b[30m\u001b[2m---------\u001b[0m\u001b[0m 8.16 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)m\u001b[2m--------------\u001b[0m\u001b[0m 7.59 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m----------------------\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 8.72 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)30m\u001b[2m------------\u001b[0m\u001b[0m 8.75 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 9.67 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)[30m\u001b[2m-----------\u001b[0m\u001b[0m 9.25 MiB/13.94 MiB        \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m--------------------------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 10.07 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)-\u001b[30m\u001b[2m---------\u001b[0m\u001b[0m 10.00 MiB/13.94 MiB       \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m---------------------------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 10.59 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)---\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 10.73 MiB/13.94 MiB       \u001b[2A\n",
      "\u001b[2mtransformers          \u001b[0m \u001b[32m-----------------------------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 11.19 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)----\u001b[30m\u001b[2m------\u001b[0m\u001b[0m 11.27 MiB/13.94 MiB       \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)----\u001b[30m\u001b[2m------\u001b[0m\u001b[0m 11.48 MiB/13.94 MiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/23)------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 12.32 MiB/13.94 MiB       \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m23 packages\u001b[0m \u001b[2min 1.43s\u001b[0m\u001b[0m                                                     \u001b[1A\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m88 packages\u001b[0m \u001b[2min 930ms\u001b[0m\u001b[0m                              \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdistro\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocling\u001b[0m\u001b[2m==2.55.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocling-core\u001b[0m\u001b[2m==2.54.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocling-ibm-models\u001b[0m\u001b[2m==3.10.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocling-parse\u001b[0m\u001b[2m==4.7.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1measyocr\u001b[0m\u001b[2m==1.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1met-xmlfile\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfaker\u001b[0m\u001b[2m==38.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfiletype\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimageio\u001b[0m\u001b[2m==2.37.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjiter\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonlines\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonpatch\u001b[0m\u001b[2m==1.33\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonref\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-docling\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-openai\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.4.49\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlatex2mathml\u001b[0m\u001b[2m==3.78.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlazy-loader\u001b[0m\u001b[2m==0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlxml\u001b[0m\u001b[2m==5.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarko\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpire\u001b[0m\u001b[2m==2.10.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.18\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mninja\u001b[0m\u001b[2m==1.13.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==2.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopencv-python-headless\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenpyxl\u001b[0m\u001b[2m==3.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.11.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpluggy\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpolyfactory\u001b[0m\u001b[2m==3.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyclipper\u001b[0m\u001b[2m==1.3.0.post6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.41.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-settings\u001b[0m\u001b[2m==2.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpylatexenc\u001b[0m\u001b[2m==2.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypdfium2\u001b[0m\u001b[2m==4.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-bidi\u001b[0m\u001b[2m==0.6.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-docx\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-pptx\u001b[0m\u001b[2m==1.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2025.11.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests-toolbelt\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrtree\u001b[0m\u001b[2m==1.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-image\u001b[0m\u001b[2m==0.25.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msemchunk\u001b[0m\u001b[2m==2.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshapely\u001b[0m\u001b[2m==2.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtabulate\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtenacity\u001b[0m\u001b[2m==9.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtifffile\u001b[0m\u001b[2m==2025.10.16\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtiktoken\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtree-sitter\u001b[0m\u001b[2m==0.25.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtree-sitter-c\u001b[0m\u001b[2m==0.24.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtree-sitter-java\u001b[0m\u001b[2m==0.23.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtree-sitter-javascript\u001b[0m\u001b[2m==0.25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtree-sitter-python\u001b[0m\u001b[2m==0.25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtree-sitter-typescript\u001b[0m\u001b[2m==0.23.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mxlsxwriter\u001b[0m\u001b[2m==3.2.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzstandard\u001b[0m\u001b[2m==0.25.0\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m131 packages\u001b[0m \u001b[2min 2.01s\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m                                   \n",
      "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m                           \u001b[1A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2K\u001b[2A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m     0 B/72.30 KiB           \u001b[2A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2K\u001b[2A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 14.91 KiB/72.30 KiB         \u001b[2A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2K\u001b[2A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 14.91 KiB/72.30 KiB         \u001b[2A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 14.91 KiB/72.30 KiB         \u001b[3A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 14.91 KiB/72.30 KiB         \u001b[3A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 14.91 KiB/72.30 KiB         \u001b[3A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 14.91 KiB/72.30 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m     0 B/108.27 KiB          \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 14.91 KiB/72.30 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 14.88 KiB/108.27 KiB        \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 30.91 KiB/72.30 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 14.88 KiB/108.27 KiB        \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 46.91 KiB/72.30 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 14.88 KiB/108.27 KiB        \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 46.91 KiB/72.30 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 14.88 KiB/108.27 KiB        \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 46.91 KiB/72.30 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 14.88 KiB/108.27 KiB        \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 46.91 KiB/72.30 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 14.88 KiB/108.27 KiB        \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 46.91 KiB/72.30 KiB\n",
      "\u001b[2mfastapi             \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 14.88 KiB/108.27 KiB\n",
      "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m     0 B/1.05 MiB            \u001b[5A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 46.91 KiB/72.30 KiB\n",
      "\u001b[2mfastapi             \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 14.88 KiB/108.27 KiB\n",
      "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m     0 B/1.05 MiB            \u001b[5A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 46.91 KiB/72.30 KiB\n",
      "\u001b[2mfastapi             \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 14.88 KiB/108.27 KiB\n",
      "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m     0 B/1.05 MiB            \u001b[5A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mannotated-doc       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/5.18 KiB\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m--------------------------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 62.91 KiB/72.30 KiB\n",
      "\u001b[2mfastapi             \u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 30.88 KiB/108.27 KiB\n",
      "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m     0 B/1.05 MiB            \u001b[5A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mstarlette           \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 72.30 KiB/72.30 KiB\n",
      "\u001b[2mfastapi             \u001b[0m \u001b[32m-----------------\u001b[30m\u001b[2m-------------\u001b[0m\u001b[0m 62.88 KiB/108.27 KiB\n",
      "\u001b[2msoundfile           \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 16.00 KiB/1.05 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/35.53 MiB\n",
      "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m     0 B/42.80 MiB           \u001b[6A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mfastapi             \u001b[0m \u001b[32m-----------------\u001b[30m\u001b[2m-------------\u001b[0m\u001b[0m 62.88 KiB/108.27 KiB\n",
      "\u001b[2msoundfile           \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 16.00 KiB/1.05 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/35.53 MiB\n",
      "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m     0 B/42.80 MiB           \u001b[5A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mmlx-vlm             \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/386.28 KiB\n",
      "\u001b[2msoundfile           \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 159.01 KiB/1.05 MiB\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.56 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/35.53 MiB\n",
      "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m     0 B/42.80 MiB           \u001b[6A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mmlx-vlm             \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 64.00 KiB/386.28 KiB\n",
      "\u001b[2msoundfile           \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 335.01 KiB/1.05 MiB\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 64.00 KiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 80.00 KiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 64.00 KiB/35.53 MiB\n",
      "\u001b[2K\u001b[7A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 64.00 KiB/42.80 MiB         \u001b[7A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2mmlx-vlm             \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 192.00 KiB/386.28 KiB\n",
      "\u001b[2msoundfile           \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 463.01 KiB/1.05 MiB\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 208.00 KiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 208.00 KiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 224.00 KiB/35.53 MiB\n",
      "\u001b[2K\u001b[7A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 224.00 KiB/42.80 MiB        \u001b[7A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2msoundfile           \u001b[0m \u001b[32m------------------\u001b[30m\u001b[2m------------\u001b[0m\u001b[0m 671.01 KiB/1.05 MiB\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 429.85 KiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 400.00 KiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 432.00 KiB/35.53 MiB\n",
      "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 432.00 KiB/42.80 MiB        \u001b[6A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2msoundfile           \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 687.01 KiB/1.05 MiB\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 443.46 KiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 416.00 KiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 448.00 KiB/35.53 MiB\n",
      "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 448.00 KiB/42.80 MiB        \u001b[6A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/13)\n",
      "\u001b[2msoundfile           \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 831.01 KiB/1.05 MiB\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 592.00 KiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 592.00 KiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 640.00 KiB/35.53 MiB\n",
      "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 656.00 KiB/42.80 MiB        \u001b[6A\n",
      "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/13)\n",
      "\u001b[2msoundfile           \u001b[0m \u001b[32m-----------------------------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 1.03 MiB/1.05 MiB\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 864.00 KiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 832.00 KiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 888.76 KiB/35.53 MiB\n",
      "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 863.89 KiB/42.80 MiB        \u001b[6A\n",
      "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/13)\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 896.00 KiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 872.65 KiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 896.00 KiB/35.53 MiB\n",
      "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 896.00 KiB/42.80 MiB        \u001b[5A\n",
      "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/13)\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 1.09 MiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.14 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 1.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 1.00 MiB/42.80 MiB          \u001b[5A\n",
      "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/13)\n",
      "\u001b[2mmlx-lm              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/287.60 KiB\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m------------------\u001b[30m\u001b[2m------------\u001b[0m\u001b[0m 1.55 MiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 1.61 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 1.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 1.00 MiB/42.80 MiB          \u001b[6A\n",
      "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/13)\n",
      "\u001b[2mmlx-lm              \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 112.00 KiB/287.60 KiB\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 1.69 MiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 2.17 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 1.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 1.00 MiB/42.80 MiB          \u001b[6A\n",
      "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/13)\n",
      "\u001b[2mmlx                 \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 64.00 KiB/541.34 KiB\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 1.97 MiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 2.34 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 1.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 1.00 MiB/42.80 MiB          \u001b[6A\n",
      "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/13)\n",
      "\u001b[2mmlx                 \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 224.00 KiB/541.34 KiB\n",
      "\u001b[2mnumba               \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 2.46 MiB/2.56 MiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 2.56 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 1.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 1.00 MiB/42.80 MiB          \u001b[6A\n",
      "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/13)\n",
      "\u001b[2mmlx                 \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 352.00 KiB/541.34 KiB\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 2.67 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 1.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 1.00 MiB/42.80 MiB          \u001b[5A\n",
      "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/13)\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 2.86 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 1.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 1.00 MiB/42.80 MiB          \u001b[4A\n",
      "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/13)\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 3.20 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 1.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 1.00 MiB/42.80 MiB          \u001b[4A\n",
      "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/13)\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 4.00 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.25 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 1.00 MiB/42.80 MiB          \u001b[4A\n",
      "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/13)\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 4.22 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.09 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 1.20 MiB/42.80 MiB          \u001b[4A\n",
      "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/13)\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 4.53 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 2.44 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[4A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m openai-whisper\u001b[2m==20250625\u001b[0m---\u001b[0m\u001b[0m 1.52 MiB/42.80 MiB          \u001b[4A\n",
      "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/13)\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 4.92 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 2.84 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/13)------------------\u001b[0m\u001b[0m 1.94 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 4.98 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 2.92 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/13)------------------\u001b[0m\u001b[0m 2.01 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 5.14 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 3.12 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/13)------------------\u001b[0m\u001b[0m 2.69 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 5.53 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 3.55 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 3.08 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 5.98 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 4.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 3.55 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 6.36 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 4.44 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 3.92 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 7.09 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 5.09 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 4.00 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 7.62 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 5.98 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 4.00 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 8.06 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 6.53 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 4.00 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 8.72 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-----\u001b[30m\u001b[2m-------------------------\u001b[0m\u001b[0m 6.73 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 4.00 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-------------\u001b[30m\u001b[2m-----------------\u001b[0m\u001b[0m 9.41 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 7.44 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 4.11 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-------------\u001b[30m\u001b[2m-----------------\u001b[0m\u001b[0m 9.41 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 7.72 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 5.00 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 9.80 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 8.12 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 5.38 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m---------------\u001b[30m\u001b[2m---------------\u001b[0m\u001b[0m 10.41 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 8.64 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 5.48 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m---------------\u001b[30m\u001b[2m---------------\u001b[0m\u001b[0m 10.75 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 8.89 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 6.18 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m----------------\u001b[30m\u001b[2m--------------\u001b[0m\u001b[0m 11.12 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-------\u001b[30m\u001b[2m-----------------------\u001b[0m\u001b[0m 9.37 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 6.65 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m----------------\u001b[30m\u001b[2m--------------\u001b[0m\u001b[0m 11.61 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 9.92 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 6.72 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-----------------\u001b[30m\u001b[2m-------------\u001b[0m\u001b[0m 12.11 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 10.16 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 7.11 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-----------------\u001b[30m\u001b[2m-------------\u001b[0m\u001b[0m 12.22 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 10.41 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 8.08 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m------------------\u001b[30m\u001b[2m------------\u001b[0m\u001b[0m 12.78 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 11.33 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 8.08 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 13.14 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 11.48 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 8.72 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 13.75 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 11.88 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 9.00 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m---------------------\u001b[30m\u001b[2m---------\u001b[0m\u001b[0m 15.14 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 12.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 9.00 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 16.42 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 12.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 9.00 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 17.47 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 12.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 9.50 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m--------------------------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 18.14 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 12.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 9.98 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m---------------------------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 18.83 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m----------\u001b[30m\u001b[2m--------------------\u001b[0m\u001b[0m 12.56 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 9.98 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m---------------------------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 18.95 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 13.56 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 9.98 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 19.83 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 13.56 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 9.98 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mav                  \u001b[0m \u001b[32m-----------------------------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 20.17 MiB/20.71 MiB\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 14.33 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 9.98 MiB/42.80 MiB          \u001b[3A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 14.89 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 9.98 MiB/42.80 MiB          \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 14.94 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (10/13)-----------------\u001b[0m\u001b[0m 10.08 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m------------\u001b[30m\u001b[2m------------------\u001b[0m\u001b[0m 15.00 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 11.45 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-------------\u001b[30m\u001b[2m-----------------\u001b[0m\u001b[0m 16.30 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 11.55 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-------------\u001b[30m\u001b[2m-----------------\u001b[0m\u001b[0m 16.30 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 12.73 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 16.98 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.00 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 16.98 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.02 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 16.98 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.03 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 16.98 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.05 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 16.98 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.06 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------------\u001b[30m\u001b[2m----------------\u001b[0m\u001b[0m 17.28 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.97 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m---------------\u001b[30m\u001b[2m---------------\u001b[0m\u001b[0m 18.55 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.97 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m----------------\u001b[30m\u001b[2m--------------\u001b[0m\u001b[0m 19.70 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.97 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-----------------\u001b[30m\u001b[2m-------------\u001b[0m\u001b[0m 20.83 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.97 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m------------------\u001b[30m\u001b[2m------------\u001b[0m\u001b[0m 21.84 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.97 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-------------------\u001b[30m\u001b[2m-----------\u001b[0m\u001b[0m 23.02 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.97 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------------------\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 24.25 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 13.97 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------------------\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 24.52 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 14.75 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------------------\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 24.76 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 15.61 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m---------------------\u001b[30m\u001b[2m---------\u001b[0m\u001b[0m 25.89 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 15.85 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m----------------------\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 27.05 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-----------------------\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 27.75 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m------------------------\u001b[30m\u001b[2m------\u001b[0m\u001b[0m 28.86 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 29.84 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------------------------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 31.31 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m--------------------------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 31.62 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 33.20 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m----------------------------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 33.81 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2mllvmlite            \u001b[0m \u001b[32m-----------------------------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 35.26 MiB/35.53 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (11/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 15.96 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.02 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.03 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.05 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.06 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.08 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.09 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.11 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.12 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.14 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.25 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.98 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 16.98 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 17.02 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 17.03 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 17.05 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 17.06 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 17.20 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 18.67 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----------------\u001b[0m\u001b[0m 19.92 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.00 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.00 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.02 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.03 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.05 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.06 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.06 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.06 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.08 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.09 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.11 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.12 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.14 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.16 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.17 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.19 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.20 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m----------------\u001b[0m\u001b[0m 21.32 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)2m---------------\u001b[0m\u001b[0m 21.57 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)2m---------------\u001b[0m\u001b[0m 21.97 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)2m---------------\u001b[0m\u001b[0m 22.80 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)[2m--------------\u001b[0m\u001b[0m 24.20 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)\u001b[2m-------------\u001b[0m\u001b[0m 25.48 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m\u001b[2m------------\u001b[0m\u001b[0m 25.93 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m\u001b[2m------------\u001b[0m\u001b[0m 26.01 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m\u001b[2m------------\u001b[0m\u001b[0m 26.03 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m\u001b[2m------------\u001b[0m\u001b[0m 26.04 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m\u001b[2m------------\u001b[0m\u001b[0m 26.06 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)m\u001b[2m------------\u001b[0m\u001b[0m 26.25 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)0m\u001b[2m-----------\u001b[0m\u001b[0m 27.61 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)30m\u001b[2m----------\u001b[0m\u001b[0m 28.84 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)[30m\u001b[2m---------\u001b[0m\u001b[0m 30.17 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)[30m\u001b[2m---------\u001b[0m\u001b[0m 30.95 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 32.39 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 33.78 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)--\u001b[30m\u001b[2m------\u001b[0m\u001b[0m 34.97 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)---\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 36.38 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)----\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 37.36 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 38.86 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 38.98 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.02 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.03 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.05 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.06 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.06 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.08 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.08 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.09 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.11 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.12 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.14 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.20 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.28 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.48 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-----\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 39.79 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 39.96 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 40.02 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 41.33 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 41.98 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.02 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.03 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.05 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.06 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.06 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.08 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.09 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.09 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.11 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.12 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.14 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.16 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.17 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.20 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/13)-------\u001b[30m\u001b[2m-\u001b[0m\u001b[0m 42.36 MiB/42.80 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m13 packages\u001b[0m \u001b[2min 8.37s\u001b[0m\u001b[0m                                                     \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 80ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m28 packages\u001b[0m \u001b[2min 200ms\u001b[0m\u001b[0m.88                           \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohappyeyeballs\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.13.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-doc\u001b[0m\u001b[2m==0.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mav\u001b[0m\u001b[2m==16.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.123.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfrozenlist\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.45.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmlx\u001b[0m\u001b[2m==0.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmlx-lm\u001b[0m\u001b[2m==0.28.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmlx-metal\u001b[0m\u001b[2m==0.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmlx-vlm\u001b[0m\u001b[2m==0.3.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmore-itertools\u001b[0m\u001b[2m==10.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultidict\u001b[0m\u001b[2m==6.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.62.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenai-whisper\u001b[0m\u001b[2m==20250625\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.12.0.88\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpropcache\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==22.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mqwen-vl-utils\u001b[0m\u001b[2m==0.0.14\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msoundfile\u001b[0m\u001b[2m==0.13.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.50.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mxxhash\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1myarl\u001b[0m\u001b[2m==1.22.0\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `docling==2.55.1` does not have an extra named `easyocr`\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m98 packages\u001b[0m \u001b[2min 602ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m     0 B/18.98 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 16.00 KiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 32.00 KiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 48.00 KiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 64.00 KiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 80.00 KiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 96.00 KiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 112.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 128.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 144.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 160.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 176.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 192.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 208.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 224.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 240.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 256.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 272.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 288.00 KiB/18.98 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 1008.00 KiB/18.98 MiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 1008.00 KiB/18.98 MiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 1.02 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 1.03 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 1.05 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 1.06 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 1.08 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 1.09 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 1.23 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 1.64 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 1.98 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 2.48 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 2.92 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 3.37 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 3.86 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 4.39 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 4.95 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 5.50 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 6.02 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 6.03 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 6.43 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 6.90 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 7.38 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)m------------------\u001b[0m\u001b[0m 8.03 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)2m-----------------\u001b[0m\u001b[0m 8.74 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)[2m----------------\u001b[0m\u001b[0m 9.03 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)[2m----------------\u001b[0m\u001b[0m 9.38 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\u001b[2m---------------\u001b[0m\u001b[0m 9.97 MiB/18.98 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)m\u001b[2m--------------\u001b[0m\u001b[0m 10.72 MiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)0m\u001b[2m-------------\u001b[0m\u001b[0m 11.22 MiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)30m\u001b[2m------------\u001b[0m\u001b[0m 11.97 MiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)[30m\u001b[2m-----------\u001b[0m\u001b[0m 12.61 MiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 13.27 MiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 14.06 MiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 14.88 MiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[30m\u001b[2m------\u001b[0m\u001b[0m 15.80 MiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 16.58 MiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 17.48 MiB/18.98 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 2.08s\u001b[0m\u001b[0m                                                       \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m43 packages\u001b[0m \u001b[2min 147ms\u001b[0m\u001b[0m                              \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbackoff\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbcrypt\u001b[0m\u001b[2m==5.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbuild\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcachetools\u001b[0m\u001b[2m==6.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mchromadb\u001b[0m\u001b[2m==1.3.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcoloredlogs\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdurationpy\u001b[0m\u001b[2m==0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mflatbuffers\u001b[0m\u001b[2m==25.9.23\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-auth\u001b[0m\u001b[2m==2.43.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogleapis-common-protos\u001b[0m\u001b[2m==1.72.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.76.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhumanfriendly\u001b[0m\u001b[2m==10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-metadata\u001b[0m\u001b[2m==8.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-resources\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkubernetes\u001b[0m\u001b[2m==34.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmmh3\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1moauthlib\u001b[0m\u001b[2m==3.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1monnxruntime\u001b[0m\u001b[2m==1.23.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-api\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-common\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-grpc\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-proto\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-sdk\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-semantic-conventions\u001b[0m\u001b[2m==0.59b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1moverrides\u001b[0m\u001b[2m==7.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mposthog\u001b[0m\u001b[2m==5.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1-modules\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpybase64\u001b[0m\u001b[2m==1.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypika\u001b[0m\u001b[2m==0.48.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyproject-hooks\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests-oauthlib\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrsa\u001b[0m\u001b[2m==4.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentence-transformers\u001b[0m\u001b[2m==5.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzipp\u001b[0m\u001b[2m==3.23.0\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install Docling and its optional dependencies\n",
    "# Uncomment and run these lines if you haven't installed the packages yet\n",
    "\n",
    "# !uv pip install docling==2.55.1 langchain-docling langchain-openai python-dotenv\n",
    "# !uv pip install 'docling[easyocr,vlm,asr]'\n",
    "# !uv pip install 'docling-core[chunking]'\n",
    "# !uv pip install chromadb transformers sentence-transformers\n",
    "# !uv pip install pandas openpyxl  # For table export examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.55.1\n"
     ]
    }
   ],
   "source": [
    "# Verify installation\n",
    "import docling\n",
    "from importlib.metadata import version\n",
    "\n",
    "print(version(\"docling\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "print(\"Core imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key is configured\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify OpenAI API key is set (for RAG examples later)\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"OpenAI API key is configured\")\n",
    "else:\n",
    "    print(\"Warning: OpenAI API key not found. Some RAG examples will not work.\")\n",
    "    print(\"Create a .env file with: OPENAI_API_KEY=your-key-here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import core modules that we'll use throughout the notebook\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output\n",
    "\n",
    "# Docling imports\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.base_models import InputFormat, ConversionStatus\n",
    "\n",
    "# Set up paths\n",
    "SAMPLE_DIR = Path(\"sample_documents\")\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Core imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Basic Document Conversion\n",
    "\n",
    "The `DocumentConverter` class is the main entry point for document conversion in Docling. It handles format detection, backend selection, and pipeline execution automatically.\n",
    "\n",
    "### Key Concepts:\n",
    "- **ConversionResult**: Contains the converted document, status, and any errors\n",
    "- **DoclingDocument**: The unified internal representation of any document\n",
    "- **Export Formats**: Markdown, JSON, HTML, Text, DocTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Simple PDF Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF from: https://arxiv.org/pdf/2408.09869\n",
      "This may take a minute for the first run as models are downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 09:57:49,845 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-06 09:57:49,890 - INFO - Going to convert document batch...\n",
      "2025-12-06 09:57:49,890 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e647edf348883bed75367b22fbe60347\n",
      "2025-12-06 09:57:51,163 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2025-12-06 09:57:51,164 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-06 09:57:51,165 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-12-06 09:57:51,176 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2025-12-06 09:57:51,176 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-06 09:57:51,182 - INFO - Registered ocr engines: ['easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-12-06 09:57:51,412 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 09:57:54,446 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 09:57:56,677 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 09:57:57,332 - INFO - Processing document 2408.09869v5.pdf\n",
      "2025-12-06 09:58:15,949 - INFO - Finished converting document 2408.09869v5.pdf in 26.40 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversion Status: ConversionStatus.SUCCESS\n",
      "Document Name: 2408.09869v5.pdf\n",
      "Number of Pages: 9\n"
     ]
    }
   ],
   "source": [
    "# Basic PDF conversion example\n",
    "# Using the Docling paper from arXiv as an example\n",
    "\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "# Initialize the converter with default settings\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Convert a PDF from URL\n",
    "# The Docling paper: \"Docling Technical Report\"\n",
    "pdf_url = \"https://arxiv.org/pdf/2408.09869\"\n",
    "\n",
    "print(f\"Converting PDF from: {pdf_url}\")\n",
    "print(\"This may take a minute for the first run as models are downloaded...\")\n",
    "\n",
    "# Perform conversion\n",
    "result = converter.convert(pdf_url)\n",
    "\n",
    "# Check conversion status\n",
    "print(f\"\\nConversion Status: {result.status}\")\n",
    "print(f\"Document Name: {result.input.file.name}\")\n",
    "print(f\"Number of Pages: {len(result.pages) if result.pages else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Type: DoclingDocument\n",
      "Number of Tables: 3\n",
      "Number of Pictures: 5\n"
     ]
    }
   ],
   "source": [
    "# Access the converted document\n",
    "doc = result.document\n",
    "\n",
    "# Display document structure information\n",
    "print(f\"Document Type: {type(doc).__name__}\")\n",
    "print(f\"Number of Tables: {len(doc.tables) if hasattr(doc, 'tables') else 0}\")\n",
    "print(f\"Number of Pictures: {len(doc.pictures) if hasattr(doc, 'pictures') else 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 10:02:13,348 - WARNING - Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "2025-12-06 10:02:13,350 - WARNING - Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "2025-12-06 10:02:13,352 - WARNING - Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Table 1 ---\n",
      "| CPU                     | Thread budget   | native backend   | native backend   | native backend   | pypdfium backend   | pypdfium backend   | pypdfium backend   |\n",
      "|-------------------------|-----------------|------------------|------------------|------------------|--------------------|--------------------|--------------------|\n",
      "|                         |                 | TTS              | Pages/s          | Mem              | TTS                | Pages/s            | Mem                |\n",
      "| Apple M3 Max (16 cores) | 4 16            | 177 s 167 s      | 1.27 1.34        | 6.20 GB          | 103 s 92 s         | 2.18 2.45          | 2.56 GB            |\n",
      "| Intel(R) Xeon E5-2690   | 4 16            | 375 s 244 s      | 0.60 0.92        | 6.16 GB          | 239 s 143 s        | 0.94 1.57          | 2.42 GB            |\n",
      "\n",
      "--- Table 2 ---\n",
      "|                                                                                                        | human                                                                   | MRCNN R50 R101                                                                                                          | FRCNN R101                                                  | YOLO v5x6                                                   |\n",
      "|--------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------|-------------------------------------------------------------|\n",
      "| Caption Footnote Formula List-item Page-footer Page-header Picture Section-header Table Text Title All | 84-89 83-91 83-85 87-88 93-94 85-89 69-71 83-84 77-81 84-86 60-72 82-83 | 68.4 71.5 70.9 71.8 60.1 63.4 81.2 80.8 61.6 59.3 71.9 70.0 71.7 72.7 67.6 69.3 82.2 82.9 84.6 85.8 76.7 80.4 72.4 73.5 | 70.1 73.7 63.5 81.0 58.9 72.0 72.0 68.4 82.2 85.4 79.9 73.4 | 77.7 77.2 66.2 86.2 61.1 67.9 77.1 74.6 86.3 88.1 82.7 76.8 |\n",
      "\n",
      "--- Table 3 ---\n",
      "\n",
      "\n",
      "==================================================\n",
      "PICTURES\n",
      "==================================================\n",
      "\n",
      "--- Picture 1 ---\n",
      "Provenance: [ProvenanceItem(page_no=1, bbox=BoundingBox(l=256.3820495605469, t=719.1313552856445, r=355.6946105957031, b=622.8831176757812, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))]\n",
      "\n",
      "--- Picture 2 ---\n",
      "Provenance: [ProvenanceItem(page_no=3, bbox=BoundingBox(l=109.05867767333984, t=720.8739471435547, r=502.184814453125, b=581.8076019287109, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))]\n",
      "\n",
      "--- Picture 3 ---\n",
      "Provenance: [ProvenanceItem(page_no=7, bbox=BoundingBox(l=110.70008087158203, t=671.6737823486328, r=528.5218505859375, b=434.72979736328125, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))]\n",
      "\n",
      "--- Picture 4 ---\n",
      "Provenance: [ProvenanceItem(page_no=8, bbox=BoundingBox(l=237.43873596191406, t=550.6194763183594, r=337.52294921875, b=476.10931396484375, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))]\n",
      "\n",
      "--- Picture 5 ---\n",
      "Provenance: [ProvenanceItem(page_no=9, bbox=BoundingBox(l=107.29144287109375, t=578.4564971923828, r=544.7594604492188, b=308.90594482421875, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))]\n"
     ]
    }
   ],
   "source": [
    "# # Display Tables\n",
    "# print(\"=\" * 50)\n",
    "# print(\"TABLES\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "if hasattr(doc, 'tables') and doc.tables:\n",
    "    for i, table in enumerate(doc.tables):\n",
    "        print(f\"\\n--- Table {i+1} ---\")\n",
    "        # Export table to markdown format\n",
    "        print(table.export_to_markdown())\n",
    "else:\n",
    "    print(\"No tables found\")\n",
    "\n",
    "# Display Pictures\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PICTURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if hasattr(doc, 'pictures') and doc.pictures:\n",
    "    for i, picture in enumerate(doc.pictures):\n",
    "        print(f\"\\n--- Picture {i+1} ---\")\n",
    "        # Get caption or text associated with the picture\n",
    "        if hasattr(picture, 'caption') and picture.caption:\n",
    "            print(f\"Caption: {picture.caption}\")\n",
    "        if hasattr(picture, 'text') and picture.text:\n",
    "            print(f\"Text: {picture.text}\")\n",
    "        # Show any available metadata\n",
    "        if hasattr(picture, 'prov'):\n",
    "            print(f\"Provenance: {picture.prov}\")\n",
    "else:\n",
    "    print(\"No pictures found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Export Formats\n",
    "\n",
    "Docling supports multiple export formats:\n",
    "\n",
    "| Method | Output | Use Case |\n",
    "|--------|--------|----------|\n",
    "| `export_to_markdown()` | Markdown text | LLM input, readable output |\n",
    "| `export_to_dict()` | Python dict | Programmatic access |\n",
    "| `save_as_json()` | JSON file | Persistence, API responses |\n",
    "| `save_as_html()` | HTML file | Web display |\n",
    "| `export_to_text()` | Plain text | Simple text extraction |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MARKDOWN OUTPUT (first 2000 chars)\n",
      "================================================================================\n",
      "<!-- image -->\n",
      "\n",
      "## Docling Technical Report\n",
      "\n",
      "## Version 1.0\n",
      "\n",
      "Christoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\n",
      "\n",
      "AI4K Group, IBM Research R¨ uschlikon, Switzerland\n",
      "\n",
      "## Abstract\n",
      "\n",
      "This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.\n",
      "\n",
      "## 1 Introduction\n",
      "\n",
      "Converting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.\n",
      "\n",
      "With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with per\n",
      "\n",
      "... [truncated] ...\n"
     ]
    }
   ],
   "source": [
    "# Export to Markdown\n",
    "markdown_content = doc.export_to_markdown()\n",
    "\n",
    "# Display first 2000 characters\n",
    "print(\"=\" * 80)\n",
    "print(\"MARKDOWN OUTPUT (first 2000 chars)\")\n",
    "print(\"=\" * 80)\n",
    "print(markdown_content[:2000])\n",
    "print(\"\\n... [truncated] ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON saved to: output/docling_paper.json\n",
      "HTML saved to: output/docling_paper.html\n",
      "Markdown saved to: output/docling_paper.md\n"
     ]
    }
   ],
   "source": [
    "# Export to JSON (save to file)\n",
    "json_output_path = OUTPUT_DIR / \"docling_paper.json\"\n",
    "doc.save_as_json(json_output_path)\n",
    "print(f\"JSON saved to: {json_output_path}\")\n",
    "\n",
    "# Export to HTML\n",
    "html_output_path = OUTPUT_DIR / \"docling_paper.html\"\n",
    "doc.save_as_html(html_output_path)\n",
    "print(f\"HTML saved to: {html_output_path}\")\n",
    "\n",
    "# Export to Markdown file\n",
    "md_output_path = OUTPUT_DIR / \"docling_paper.md\"\n",
    "with open(md_output_path, \"w\") as f:\n",
    "    f.write(markdown_content)\n",
    "print(f\"Markdown saved to: {md_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Dictionary Keys:\n",
      "  - schema_name\n",
      "  - version\n",
      "  - name\n",
      "  - origin\n",
      "  - furniture\n",
      "  - body\n",
      "  - groups\n",
      "  - texts\n",
      "  - pictures\n",
      "  - tables\n",
      "  - key_value_items\n",
      "  - form_items\n",
      "  - pages\n"
     ]
    }
   ],
   "source": [
    "# Export to dictionary for programmatic access\n",
    "doc_dict = doc.export_to_dict()\n",
    "\n",
    "# Explore the structure\n",
    "print(\"Document Dictionary Keys:\")\n",
    "for key in doc_dict.keys():\n",
    "    print(f\"  - {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ConversionResult Structure\n",
    "\n",
    "The `ConversionResult` object contains valuable metadata about the conversion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConversionResult Attributes:\n",
      "  status: ConversionStatus.SUCCESS\n",
      "  input.file: 2408.09869v5.pdf\n",
      "  input.format: InputFormat.PDF\n",
      "  input.document_hash: 82dd470712ce8389...\n",
      "\n",
      "No errors during conversion!\n"
     ]
    }
   ],
   "source": [
    "# Examine the ConversionResult structure\n",
    "print(\"ConversionResult Attributes:\")\n",
    "print(f\"  status: {result.status}\")\n",
    "print(f\"  input.file: {result.input.file}\")\n",
    "print(f\"  input.format: {result.input.format}\")\n",
    "print(f\"  input.document_hash: {result.input.document_hash[:16]}...\")\n",
    "\n",
    "# Check for errors\n",
    "if result.errors:\n",
    "    print(f\"\\nErrors ({len(result.errors)}):\")\n",
    "    for error in result.errors:\n",
    "        print(f\"  - {error.component_type}: {error.error_message}\")\n",
    "else:\n",
    "    print(\"\\nNo errors during conversion!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Supported File Formats\n",
    "\n",
    "Docling supports a wide variety of input formats, each handled by specialized backends:\n",
    "\n",
    "| Format | Extensions | Backend | Pipeline |\n",
    "|--------|-----------|---------|----------|\n",
    "| PDF | `.pdf` | DoclingParseV4Backend | StandardPdfPipeline |\n",
    "| Word | `.docx` | MsWordDocumentBackend | SimplePipeline |\n",
    "| Excel | `.xlsx` | MsExcelDocumentBackend | SimplePipeline |\n",
    "| PowerPoint | `.pptx` | MsPowerpointDocumentBackend | SimplePipeline |\n",
    "| HTML | `.html`, `.htm` | HTMLDocumentBackend | SimplePipeline |\n",
    "| Markdown | `.md` | MarkdownDocumentBackend | SimplePipeline |\n",
    "| Images | `.png`, `.jpg`, `.tiff` | ImageDocumentBackend | StandardPdfPipeline |\n",
    "| Audio | `.wav`, `.mp3` | AudioBackend | AsrPipeline |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 PDF Documents\n",
    "\n",
    "PDF is the most feature-rich format with support for:\n",
    "- Layout analysis (headers, paragraphs, lists)\n",
    "- Table structure extraction\n",
    "- OCR for scanned pages\n",
    "- Image/figure extraction\n",
    "- Reading order determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 10:28:46,794 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-06 10:28:46,799 - INFO - Going to convert document batch...\n",
      "2025-12-06 10:28:46,800 - INFO - Initializing pipeline for StandardPdfPipeline with options hash c5864bf7476cef264d361ef9410e72bc\n",
      "2025-12-06 10:28:46,801 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 10:28:48,521 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 10:28:49,091 - INFO - Processing document 2408.09869v5.pdf\n",
      "2025-12-06 10:28:55,147 - INFO - Finished converting document 2408.09869v5.pdf in 8.68 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion status: ConversionStatus.SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# PDF with detailed options\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "# Configure PDF pipeline with specific options\n",
    "pdf_options = PdfPipelineOptions(\n",
    "    do_ocr=False,              # Disable OCR for native PDFs (faster)\n",
    "    do_table_structure=True,   # Enable table structure extraction\n",
    "    generate_page_images=True, # Generate page images for HTML export\n",
    ")\n",
    "\n",
    "# Create converter with custom options\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pdf_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert the PDF\n",
    "result = converter.convert(pdf_url)\n",
    "print(f\"Conversion status: {result.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 10:29:29,104 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-12-06 10:29:29,113 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 tables in the document\n",
      "\n",
      "Table 1:\n",
      "----------------------------------------\n",
      "                      CPU. Thread budget. native backend.TTS  \\\n",
      "0  Apple M3 Max (16 cores)           4 16        177 s 167 s   \n",
      "1    Intel(R) Xeon E5-2690           4 16        375 s 244 s   \n",
      "\n",
      "  native backend.Pages/s native backend.Mem pypdfium backend.TTS  \\\n",
      "0              1.27 1.34            6.20 GB           103 s 92 s   \n",
      "1              0.60 0.92            6.16 GB          239 s 143 s   \n",
      "\n",
      "  pypdfium backend.Pages/s pypdfium backend.Mem  \n",
      "0                2.18 2.45              2.56 GB  \n",
      "1                0.94 1.57              2.42 GB  \n",
      "\n",
      "Table 2:\n",
      "----------------------------------------\n",
      "                                                      \\\n",
      "0  Caption Footnote Formula List-item Page-footer...   \n",
      "\n",
      "                                               human  \\\n",
      "0  84-89 83-91 83-85 87-88 93-94 85-89 69-71 83-8...   \n",
      "\n",
      "                                      MRCNN R50 R101  \\\n",
      "0  68.4 71.5 70.9 71.8 60.1 63.4 81.2 80.8 61.6 5...   \n",
      "\n",
      "                                          FRCNN R101  \\\n",
      "0  70.1 73.7 63.5 81.0 58.9 72.0 72.0 68.4 82.2 8...   \n",
      "\n",
      "                                           YOLO v5x6  \n",
      "0  77.7 77.2 66.2 86.2 61.1 67.9 77.1 74.6 86.3 8...  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Access tables from the converted document\n",
    "doc = result.document\n",
    "\n",
    "if hasattr(doc, 'tables') and doc.tables:\n",
    "    print(f\"Found {len(doc.tables)} tables in the document\\n\")\n",
    "    \n",
    "    # Display first table\n",
    "    for i, table in enumerate(doc.tables[:2]):  # Show first 2 tables\n",
    "        print(f\"Table {i+1}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Try to export to DataFrame if pandas is available\n",
    "        try:\n",
    "            df = table.export_to_dataframe()\n",
    "            print(df.head())\n",
    "        except Exception as e:\n",
    "            print(f\"Table markdown: {table.export_to_markdown()[:500]}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No tables found in the document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Microsoft Office Documents\n",
    "\n",
    "Docling supports Office Open XML formats (DOCX, XLSX, PPTX) with rich formatting preservation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 10:31:09,252 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-12-06 10:31:09,255 - INFO - Going to convert document batch...\n",
      "2025-12-06 10:31:09,256 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-12-06 10:31:09,256 - INFO - Processing document sample.html\n",
      "2025-12-06 10:31:09,265 - INFO - Finished converting document sample.html in 0.01 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML Conversion Status: ConversionStatus.SUCCESS\n",
      "\n",
      "Converted HTML to Markdown:\n",
      "============================================================\n",
      "# Introduction to Document Parsing\n",
      "\n",
      "A comprehensive guide to understanding document parsing techniques\n",
      "\n",
      "## 1. Overview\n",
      "\n",
      "Document parsing is the process of analyzing and extracting structured information from various document formats. This includes PDFs, Word documents, HTML pages, and more.\n",
      "\n",
      "### 1.1 Key Benefits\n",
      "\n",
      "- Automated data extraction\n",
      "- Structured content analysis\n",
      "- Integration with AI/ML pipelines\n",
      "- Support for multiple formats\n",
      "\n",
      "## 2. Core Features\n",
      "\n",
      "Modern document parsers offer a variety of features:\n",
      "\n",
      "| Feature          | Description                                         | Use Case                         |\n",
      "|------------------|-----------------------------------------------------|----------------------------------|\n",
      "| OCR Support      | Optical Character Recognition for scanned documents | Scanned PDFs, Images             |\n",
      "| Table Extraction | Structured table data extraction                    | Financial reports, Data tables   |\n",
      "| Layout Analysis  | Understanding document structure                    | Academic papers, Legal documents |\n",
      "| Image Processing | Extract and classify images                         | Technical manuals, Presentations |\n",
      "\n",
      "## 3. Applications in RAG Systems\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) systems benefit significantly from proper document parsing:\n",
      "\n",
      "1. **Knowledge Base Creation:** Convert documents into searchable chunks\n",
      "2. **Semantic Search:** Enable meaning-based document retrieval\n",
      "3. **Question Answering:** Provide accurate answers fr\n"
     ]
    }
   ],
   "source": [
    "# Convert HTML document (from our sample files)\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Convert the sample HTML file\n",
    "html_path = SAMPLE_DIR / \"sample.html\"\n",
    "\n",
    "if html_path.exists():\n",
    "    result = converter.convert(str(html_path))\n",
    "    print(f\"HTML Conversion Status: {result.status}\")\n",
    "    \n",
    "    # Display converted content\n",
    "    html_markdown = result.document.export_to_markdown()\n",
    "    print(\"\\nConverted HTML to Markdown:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(html_markdown[:1500])\n",
    "else:\n",
    "    print(f\"Sample HTML file not found at {html_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 11:30:55,622 - INFO - detected formats: [<InputFormat.MD: 'md'>]\n",
      "2025-12-04 11:30:55,623 - INFO - Going to convert document batch...\n",
      "2025-12-04 11:30:55,624 - INFO - Processing document sample.md\n",
      "2025-12-04 11:30:55,705 - INFO - Finished converting document sample.md in 0.08 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown Conversion Status: ConversionStatus.SUCCESS\n",
      "\n",
      "Parsed and re-exported Markdown:\n",
      "============================================================\n",
      "# Document Parsing Best Practices\n",
      "\n",
      "A comprehensive guide to document parsing for RAG systems.\n",
      "\n",
      "## Table of Contents\n",
      "\n",
      "1. [Introduction](#introduction)\n",
      "2. [Supported Formats](#supported-formats)\n",
      "3. [Parsing Strategies](#parsing-strategies)\n",
      "4. [Integration Guide](#integration-guide)\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Document parsing is a critical component in modern AI applications. It enables the extraction of structured information from unstructured documents, making it possible to:\n",
      "\n",
      "- Build searchable knowledge bases\n",
      "- Create training datasets for machine learning\n",
      "- Enable semantic search and retrieval\n",
      "- Power question-answering systems\n",
      "\n",
      "**Note:** The quality of document parsing directly impacts the performance of downstream AI applications.\n",
      "\n",
      "## Supported Formats\n",
      "\n",
      "### Primary Formats\n",
      "\n",
      "`.pdf` `.docx` `.xlsx` `.pptx` `.html` `.md`\n",
      "\n",
      "| Format   | Extension   | Description   |\n",
      "|----------|-------------|---------------|\n",
      "| PDF      |             |               |\n",
      "\n",
      "| Portable Document Format   |\n",
      "|----------------------------|\n",
      "\n",
      "| Microsoft Word documents   |\n",
      "|----------------------------|\n",
      "\n",
      "| Microsoft Excel spreadsheets   |\n",
      "|--------------------------------|\n",
      "\n",
      "| Microsoft PowerPoint presentations   |\n",
      "|--------------------------------------|\n",
      "\n",
      "| Web pages   |\n",
      "|-------------|\n",
      "\n",
      "| Plain text formatting   |\n",
      "|-------------------------|\n",
      "\n",
      "### Additional Formats\n",
      "\n",
      "- **Images** : PNG, JPEG, TIFF, BMP\n",
      "- **Audio** : WAV, MP3 (via ASR)\n",
      "- **XML** : JATS, USPTO patents\n",
      "\n",
      "## Parsing Strategies\n",
      "\n",
      "### 1. Standard Pipeline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert Markdown document\n",
    "md_path = SAMPLE_DIR / \"sample.md\"\n",
    "\n",
    "if md_path.exists():\n",
    "    result = converter.convert(str(md_path))\n",
    "    print(f\"Markdown Conversion Status: {result.status}\")\n",
    "    \n",
    "    # Markdown to Markdown (demonstrates parsing and re-export)\n",
    "    output_md = result.document.export_to_markdown()\n",
    "    print(\"\\nParsed and re-exported Markdown:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(output_md[:1500])\n",
    "else:\n",
    "    print(f\"Sample Markdown file not found at {md_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 10:33:36,265 - INFO - detected formats: [<InputFormat.DOCX: 'docx'>]\n",
      "2025-12-06 10:33:36,271 - INFO - Going to convert document batch...\n",
      "2025-12-06 10:33:36,272 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-12-06 10:33:36,272 - INFO - Processing document sample.docx\n",
      "2025-12-06 10:33:36,299 - INFO - Finished converting document sample.docx in 0.03 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel (XLSX) Conversion:\n",
      "----------------------------------------\n",
      "Word document conversion pattern demonstrated.\n",
      "To convert a Word document, use: converter.convert('your_document.docx')\n",
      "# Deepfake Technology: A Technical Analysis of GAN-Based Synthetic Media\n",
      "\n",
      "Technical Report\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Deepfake technology represents one of the most significant applications of artificial intelligence. The term \"deepfake\" combines \"deep learning\" and \"fake,\" referring to synthetic media where a person's face, body, or voice is digitally altered (Sharma &amp; Kaur, 2022).\n",
      "\n",
      "**Key Statistics:**\n",
      "\n",
      "- Projected 8 million deepfakes will be shared in 2025\n",
      "- Significant increase from 500,000 in 2023 (European Parliament, 2025)\n",
      "- 49% of companies experienced audio/video deepfakes in 2024\n",
      "\n",
      "## Technical Foundation: Generative Adversarial Networks\n",
      "\n",
      "The core technology behind deepfakes is Generative Adversarial Networks (GANs), introduced by Goodfellow et al. in 2014. GANs use two competing neural networks:\n",
      "\n",
      "- **Generator:** Creates synthetic images, videos, or audio\n",
      "- **Discriminator:** Evaluates whether content is real or fake\n",
      "\n",
      "This adversarial process drives continuous improvement. Key developments include:\n",
      "\n",
      "- **DCGANs (2015):** Combined CNNs with GANs for better image quality\n",
      "- **StyleGAN &amp; ProGAN:** Achieved photorealistic synthesis\n",
      "- **Diffusion Models:** Emerging alternative with improved stability (Karakanis &amp; Leontaris, 2025)\n",
      "\n",
      "## Positive Applications of Deepfake Technology\n",
      "\n",
      "Despite concerns, deepfakes offer substantial benefits across multiple domains (Danry et al., 2022):\n",
      "\n",
      "**1. Entertainment Industry**\n",
      "\n",
      "- Resurrection of deceased actors for film productions\n",
      "- De-aging technology (e.g., Luke Skywalker in \"The Book of Boba Fett\")\n",
      "- Cost-effective visual effects for independent filmmakers\n",
      "- Multilingual dubbing with accurate lip-syncing (Murphy et al., 2023)\n",
      "\n",
      "**2. Education and Museums**\n",
      "\n",
      "- Interactive historical experiences (e.g., Salvador Dalí Museum in Florida)\n",
      "- Medical training simulations without ethical concerns\n",
      "- Bringing historical figures to life for immersive learning\n",
      "\n",
      "## Negative Implications and Ethical Concerns\n",
      "\n",
      "Deepfake technology presents severe risks when employed maliciously:\n",
      "\n",
      "**1. Financial Fraud**\n",
      "\n",
      "- 2024 case: Elon Musk deepfake promoted crypto scam, causing $690,000 loss to one victim\n",
      "- Projected $40 billion in fraud losses within three years (Westfall, 2024)\n",
      "- Identity theft and impersonation attacks on businesses\n",
      "\n",
      "**2. Misinformation and Political Manipulation**\n",
      "\n",
      "- Fabricated statements by public officials\n",
      "- Potential to influence elections and erode democratic trust\n",
      "- Low barrier to entry—minimal technical skills required\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Deepfake technology exemplifies the dual-use nature of AI innovations. Responsible use requires:\n",
      "\n",
      "- Development of robust detection mechanisms\n",
      "- Establishment of clear regulatory frameworks\n",
      "- Promotion of digital literacy among the public\n",
      "- Collaboration across industry, government, and academia\n",
      "\n",
      "The key lies in harnessing creative potential while mitigating capacity for harm through ethical guidelines, transparency, and consent.\n",
      "\n",
      "## References\n",
      "\n",
      "Danry, V., Leong, P., Epstein, Z., &amp; Holtzman, N. (2022). A deeper dive into deepfakes: Positive applications and ethical considerations. *Proceedings of the ACM Conference on Human Factors in Computing Systems* . https://doi.org/10.1145/3491102\n",
      "\n",
      "European Parliament. (2025). *Children and deepfakes: Risks and regulatory considerations* . European Parliamentary Research Service. https://www.europarl.europa.eu/RegData/etudes/BRIE/2025/775855/EPRS\\_BRI(2025)775855\\_EN.pdf\n",
      "\n",
      "Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., &amp; Bengio, Y. (2014). Generative adversarial nets. *Advances in Neural Information Processing Systems* , 27, 2672–2680. https://papers.nips.cc/paper/5423-generative-adversarial-nets\n",
      "\n",
      "Karakanis, S., &amp; Leontaris, G. (2025). Advancing GAN deepfake detection: Mixed datasets and comprehensive artifact analysis. *Applied Sciences* , 15(2), 923. https://doi.org/10.3390/app15020923\n",
      "\n",
      "Murphy, L., Cass, S., &amp; Williams, P. (2023). Face/off: Changing the face of movies with deepfakes. *PLOS ONE* , 18(7), e0287253. https://pmc.ncbi.nlm.nih.gov/articles/PMC10325052/\n",
      "\n",
      "Sharma, M., &amp; Kaur, M. (2022). A review of deepfake technology: An emerging AI threat. In *Soft Computing for Security Applications: Proceedings of ICSCS 2021* (pp. 605–619). Springer. https://doi.org/10.1007/978-981-16-5301-8\\_44\n"
     ]
    }
   ],
   "source": [
    "# Example: Converting a DOCX file (if you have one)\n",
    "# This demonstrates the pattern for Word documents\n",
    "\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, WordFormatOption\n",
    "\n",
    "# Configure for Word documents\n",
    "converter = DocumentConverter(\n",
    "    allowed_formats=[InputFormat.DOCX, InputFormat.PPTX, InputFormat.XLSX],  # Only allow DOCX\n",
    ")\n",
    "\n",
    "# Excel conversion pattern\n",
    "print(\"Excel (DOCX) Conversion:\")\n",
    "print(\"-\" * 40)\n",
    "result = converter.convert(\"sample_documents/sample.docx\")\n",
    "docx = result.document\n",
    "docx_markdown = docx.export_to_markdown()\n",
    "\n",
    "print(\"Word document conversion pattern demonstrated.\")\n",
    "print(\"To convert a Word document, use: converter.convert('your_document.docx')\")\n",
    "print(docx_markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 12:11:46,551 - INFO - detected formats: [<InputFormat.XLSX: 'xlsx'>]\n",
      "2025-12-04 12:11:46,568 - INFO - Going to convert document batch...\n",
      "2025-12-04 12:11:46,569 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-12-04 12:11:46,569 - INFO - Processing document sample.xlsx\n",
      "2025-12-04 12:11:46,570 - INFO - Processing sheet: plan\n",
      "2025-12-04 12:11:46,572 - INFO - Processing sheet: black\n",
      "2025-12-04 12:11:46,582 - INFO - Finished converting document sample.xlsx in 0.03 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Dates                                                                                                                                                                                                                                                                           | Modules                                                                                                      |\n",
      "|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"ARRAYFORMULA(   TEXT(     FILTER(       SEQUENCE(DATE(2026,4,14)-DATE(2025,11,1)+1,1,DATE(2025,11,1),1),       WEEKDAY(SEQUENCE(DATE(2026,4,14)-DATE(2025,11,1)+1,1,DATE(2025,11,1),1))=1     ),     \"\"d mmmm yyyy\"\"   ) )\"),\"2 November 2025\") | None                                                                                                         |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"9 November 2025\")                                                                                                                                                                                                         | None                                                                                                         |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"16 November 2025\")                                                                                                                                                                                                        | None                                                                                                         |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"23 November 2025\")                                                                                                                                                                                                        | None                                                                                                         |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"30 November 2025\")                                                                                                                                                                                                        | None                                                                                                         |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"7 December 2025\")                                                                                                                                                                                                         | Module 4: Document Parsers + Module 5 (Part 1): LlamaIndex Fundamentals                                      |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"14 December 2025\")                                                                                                                                                                                                        | Module 5 (Part 2): LlamaIndex (Document Handling, Indexing, Querying, Hybrid Search)                         |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"21 December 2025\")                                                                                                                                                                                                        | Module 6: Advanced LlamaIndex Techniques (Custom Configurations, Advanced Retrieval, System Integration)     |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"28 December 2025\")                                                                                                                                                                                                        | Module 7: Haystack (Fundamentals, Core RAG, Advanced Techniques)                                             |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"4 January 2026\")                                                                                                                                                                                                          | Module 7 (continued): Haystack Specialized Applications + Module 8 (Part 1): LangGraph Setup & Core Concepts |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"11 January 2026\")                                                                                                                                                                                                         | Module 8 (Part 2): LangGraph (Chatbot Development, Advanced Architectures)                                   |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"18 January 2026\")                                                                                                                                                                                                         | Module 8 (Part 3): LangGraph Production Features + Module 9: Enhanced RAG Techniques                         |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"25 January 2026\")                                                                                                                                                                                                         | Module 10: Multi-Modal and Structured RAG                                                                    |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"1 February 2026\")                                                                                                                                                                                                         | Module 11: Conversational and Contextual RAG                                                                 |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"8 February 2026\")                                                                                                                                                                                                         | Module 12: Agentic RAG Fundamentals                                                                          |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"15 February 2026\")                                                                                                                                                                                                        | Module 13: Advanced Agentic RAG                                                                              |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"22 February 2026\")                                                                                                                                                                                                        | Module 14: Production RAG Systems + Module 15 (Part 1): Self-RAG & Adaptive Retrieval                        |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"1 March 2026\")                                                                                                                                                                                                            | Module 15 (Part 2): Graph RAG & Fine-Tuning + Module 16: Model Context Protocol (MCP)                        |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"8 March 2026\")                                                                                                                                                                                                            | Project 1: Basic RAG Q&A System with CI/CD Foundation                                                        |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"15 March 2026\")                                                                                                                                                                                                           | Project 2: Multi-Source RAG with Vector Database                                                             |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"22 March 2026\")                                                                                                                                                                                                           | Project 3: Hybrid Search RAG with Advanced Chunking                                                          |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"29 March 2026\")                                                                                                                                                                                                           | Project 4: Multimodal RAG (Text + Images + Audio)                                                            |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"5 April 2026\")                                                                                                                                                                                                            | Project 5: Smart Code Review & Bug Fix Assistant with MCP                                                    |\n",
      "| =IFERROR(__xludf.DUMMYFUNCTION(\"\"\"COMPUTED_VALUE\"\"\"),\"12 April 2026\")                                                                                                                                                                                                           | None                                                                                                         |\n",
      "\n",
      "| Black Friday 2025: AI Services & Tools Discount Guide   | Black Friday 2025: AI Services & Tools Discount Guide   | Black Friday 2025: AI Services & Tools Discount Guide   | Black Friday 2025: AI Services & Tools Discount Guide   | Black Friday 2025: AI Services & Tools Discount Guide   | Black Friday 2025: AI Services & Tools Discount Guide   | Black Friday 2025: AI Services & Tools Discount Guide   |\n",
      "|---------------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------|\n",
      "| by Seulki Kang                                          | https://www.linkedin.com/in/seulki-kang/                | None                                                    | None                                                    | None                                                    | None                                                    | None                                                    |\n",
      "| Crawled by Genspark AI Sheet                            | None                                                    | None                                                    | None                                                    | None                                                    | None                                                    | None                                                    |\n",
      "\n",
      "| Want to try Genspark yourself?                                                                                                |\n",
      "|-------------------------------------------------------------------------------------------------------------------------------|\n",
      "| 🔗 Get 1,000 free credits: https://www.genspark.ai/invite_member?invite_code=NTQxMmI5M2ZMOTRhMUwyODg2TDhjZmZMNzE3ODRhYmI0Y2Jl |\n",
      "| 🔗 10% discount code: https://www.genspark.ai/?via=seulki875 (US) / https://www.genspark.ai/?via=seulki (Other Countries)     |\n",
      "\n",
      "| Name                                      | Description                                    | URL                                       | Benefits                                   | Monthly Plan                              | Annual Plan                                 | Notes                                                                         |\n",
      "|-------------------------------------------|------------------------------------------------|-------------------------------------------|--------------------------------------------|-------------------------------------------|---------------------------------------------|-------------------------------------------------------------------------------|\n",
      "| ⭐ Popular AI Services (Discount Info)    | ⭐ Popular AI Services (Discount Info)         | ⭐ Popular AI Services (Discount Info)    | ⭐ Popular AI Services (Discount Info)     | ⭐ Popular AI Services (Discount Info)    | ⭐ Popular AI Services (Discount Info)      | ⭐ Popular AI Services (Discount Info)                                        |\n",
      "| Perplexity Pro                            | AI search engine, real-time information search | https://perplexity.ai                     | 50% cashback with PayPal payment (max $50) | $20/month                                 | $200/year                                   | 11/25~12/1, PayPal first purchase only                                        |\n",
      "| Perplexity                                | Comet AI Browser                               | https://pplx.ai/                          | 1 month free                               | $20/month                                 | $200/year                                   | * A year-round discount that isn’t limited to Black Friday. Partnership link. |\n",
      "| 🎬 Latest AI Video/Image Generation Tools | 🎬 Latest AI Video/Image Generation Tools      | 🎬 Latest AI Video/Image Generation Tools | 🎬 Latest AI Video/Image Generation Tools  | 🎬 Latest AI Video/Image Generation Tools | 🎬 Latest AI Video/Image Generation Tools   | 🎬 Latest AI Video/Image Generation Tools                                     |\n",
      "| GenSpark AI                               | AI search engine and workspace                 | 🇺🇸 www.genspark.ai/                       | 40% off annual plan                        | $10/month (Plus), $50/month (Pro)         | Plus annual $100 off, Pro annual $1,000 off | 11/27~12/1, for free users                                                    |\n",
      "\n",
      "| 🌎 https://www.genspark.ai/   | 40% off annual plan                                  | $10/month (Plus), $50/month (Pro)              | Plus annual $100 off, Pro annual $1,000 off    | 11/27~12/1, for free users                                                                   |\n",
      "|-------------------------------|------------------------------------------------------|------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------|\n",
      "| https://klingai.com           | Annual plan 50% off + 40% bonus credits              | $9.99/month (Standard), $29.99/month (Pro)     | First year 50% off                             | 2.5 Turbo model access, unlimited queue                                                      |\n",
      "| https://elevenlabs.io         | Starter plan $1 (first month)                        | $1 (first month), then regular price           | Annual plan 2 months free                      | For YouTubers/filmmakers, ~12/1                                                              |\n",
      "| https://leonardo.ai           | Paid plans 20% off                                   | $10/month (Artisan), $24/month (Maestro)       | Annual plan 20% off                            | Fine-tuning, asset packs included. (Not a Black Friday Deal)                                 |\n",
      "| None                          | None                                                 | None                                           | None                                           | None                                                                                         |\n",
      "| https://suno.ai               | Annual plan 40% off                                  | $10/month (Pro), $30/month (Premier)           | Pro/Premier annual 40% off                     | 11/24~12/1, v5 and Studio access                                                             |\n",
      "| https://replit.com            | Annual plan 60% off + Free Fast mode (limited time)  | $25/month → $10/month (annual payment)         | $120/year (60% off)                            | 11/27~12/1, Replit Core + Agent included | ⚡ Fast mode 100% free (from 11/19, limited time) |\n",
      "| https://writesonic.com        | Annual plan 20-30% off                               | $16/month (Freelancer), $33/month (Small Team) | 20-30% off                                     | ~12/3, AI article writing                                                                    |\n",
      "| https://surferseo.com         | Scale plan 25 AI Tracker prompts free                | $89/month (Essential), $179/month (Scale)      | 20% off + 25 AI Tracker ($95 value)            | ~12/2, for Essential/Scale plans                                                             |\n",
      "| https://capcut.com            | Desktop only 40% off                                 | $9.99/month                                    | Annual plan 40% off                            | For first-time users, AI design/video tools                                                  |\n",
      "| https://web.descript.com/     | Annual plan + 1,000 AI credits + 10 media hours free | $12/month (Hobbyist), $24/month (Creator)      | About 35% off                                  | Until 12/1                                                                                   |\n",
      "| https://invideo.io            | Annual plan 60-70% off                               | $20/month (Plus), $60/month (Max)              | Up to 70% off                                  | Templates, premium media, auto TTS                                                           |\n",
      "| https://murf.ai               | Annual plan 25% off                                  | $19/month (Basic), $26/month (Pro)             | 25% off (code: BFSPL25)                        | Studio quality voiceovers                                                                    |\n",
      "| https://beautiful.ai          | 30% off                                              | $12/month (Pro)                                | 30% off (code: BLACKFRIDAY30)                  | Automatic layout design                                                                      |\n",
      "| None                          | None                                                 | None                                           | None                                           | None                                                                                         |\n",
      "| https://jasper.ai             | Annual plan 40% off                                  | $49/month (Creator), $125/month (Pro)          | Regular price $990 → about $594 (with 40% off) | Unlimited AI content generation                                                              |\n",
      "| https://copy.ai               | Annual plan up to 60% off                            | $49/month (Pro)                                | Pro plan about $259 discount                   | Past maximum 60% discount offered                                                            |\n",
      "| https://grammarly.com         | Premium plan 50% off                                 | $12/month                                      | Annual plan 50% off                            | 11/18~12/6                                                                                   |\n",
      "| https://adobe.com             | All apps 50% off                                     | Monthly 39,000 won → about 19,500 won          | About 50% off                                  | Includes generative AI Firefly                                                               |\n",
      "| https://mem.ai                | Standard plan first 2 months 50% off                 | $15/month                                      | 50% off (code: BLACKFRIDAY25)                  | First 2 months only                                                                          |\n",
      "| https://durable.co            | Up to 85% off + 2 months free                        | $12/month (Starter)                            | 85% off                                        | SEO optimized sites                                                                          |\n",
      "| https://contentatscale.ai     | Annual plan 40% off                                  | $250/month (Solo)                              | 40% off                                        | None                                                                                         |\n",
      "| https://apollo.io             | Annual 50% / 6-month 30% / 3-month 10%               | $49/month (Basic), $79/month (Professional)    | Annual plan 50% (code: BLACKFRIDAY)            | Until 12/3                                                                                   |\n",
      "| https://opus.pro              | Annual Pro plan 65% off                              | Monthly plan first month 50% off               | Annual Pro 65% off                             | For YouTubers/marketers                                                                      |\n",
      "| https://heygen.com            | 50% off + 2,400 credits                              | $29/month (Creator), $89/month (Business)      | 50% (code: BLACKFRIDAY2025)                    | None                                                                                         |\n",
      "| https://fliki.ai              | Annual plan 50% off                                  | $28/month (Standard), $88/month (Premium)      | 50% (code: FLIKIBLACKFRIDAY50)                 | None                                                                                         |\n",
      "| https://relevanceai.com       | Annual plan 60% off                                  | $39/month (Pro), $99/month (Business)          | 60% (code: BLACKFRIDAY25)                      | None                                                                                         |\n",
      "| https://runwayml.com          | Annual plan 20% off                                  | $12/month (Standard)                           | $28/month (Pro)                                | No Black Friday tradition, 20% off with annual payment                                       |\n",
      "| https://adobe.com/audition    | Annual plan 25% off (first year)                     | $22.99/month                                   | First year 25% off (auto-applied)              | Until 12/31                                                                                  |\n",
      "| https://beehiiv.com           | 20% off                                              | $39/month (Scale), $99/month (Max)             | 20% (code: 2025BFCM)                           | None                                                                                         |\n",
      "| https://reply.io              | Annual plan 40% off                                  | $60/month (Starter), $90/month (Professional)  | 40% (code: REPLY40)                            | Until 12/5                                                                                   |\n",
      "| https://10web.io              | 2 years for the price of 1                           | $10/month (Starter), $24/month (Premium)       | 2 years provided (1 year price)                | Until 12/1                                                                                   |\n",
      "| https://riverside.fm          | Pro 20% / Business 30% off                           | $19/month (Pro), $49/month (Business)          | Pro: 20% (code: BLACKFRIDAY2025PRO)            | Until 12/2                                                                                   |\n",
      "| https://quillbot.com          | Annual premium 40% off                               | $9.95/month                                    | 40% off                                        | None                                                                                         |\n",
      "| https://mailchimp.com         | All paid plans up to 30% off                         | $13/month (Essentials), $20/month (Standard)   | Up to 30% (no code required)                   | Until 12/4                                                                                   |\n",
      "| https://poe.com               | Monthly $15 (regular $49)                            | $15/month                                      | None                                           | Includes ChatGPT, MidJourney, Claude, etc.                                                   |\n",
      "| https://intercom.com          | Professional/Enterprise plans 30% off (first year)   | $74/month (Professional)                       | First year 30% off                             | For new customers                                                                            |\n",
      "| https://drift.com             | Starter/Pro plans 25% off (first year)               | $2,500/month (Premium)                         | First year 25% off                             | For new customers                                                                            |\n",
      "| https://alterhq.com/          | $99 lifetime deal (-70%)                             | None                                           | $240/year                                      | $720                                                                                         |\n",
      "| https://tagshop.ai/           | 60% off on all the annual plans                      | $29/month                                      | $132/year                                      | Until 12/7                                                                                   |\n",
      "\n",
      "| Kling AI                             | AI video generation (China Kuaishou)                                                                                                     | https://klingai.com                  | Annual plan 50% off + 40% bonus credits              | $9.99/month (Standard), $29.99/month (Pro)     | First year 50% off                             | 2.5 Turbo model access, unlimited queue                                                      |\n",
      "|--------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------|------------------------------------------------------|------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------|\n",
      "| ElevenLabs                           | AI voice generation and cloning (highest quality)                                                                                        | https://elevenlabs.io                | Starter plan $1 (first month)                        | $1 (first month), then regular price           | Annual plan 2 months free                      | For YouTubers/filmmakers, ~12/1                                                              |\n",
      "| Leonardo AI                          | AI image generation (for games/design)                                                                                                   | https://leonardo.ai                  | Paid plans 20% off                                   | $10/month (Artisan), $24/month (Maestro)       | Annual plan 20% off                            | Fine-tuning, asset packs included. (Not a Black Friday Deal)                                 |\n",
      "| 🎵 Music/Coding/SEO/Editing AI Tools | 🎵 Music/Coding/SEO/Editing AI Tools                                                                                                     | 🎵 Music/Coding/SEO/Editing AI Tools | 🎵 Music/Coding/SEO/Editing AI Tools                 | 🎵 Music/Coding/SEO/Editing AI Tools           | 🎵 Music/Coding/SEO/Editing AI Tools           | 🎵 Music/Coding/SEO/Editing AI Tools                                                         |\n",
      "| Suno AI                              | AI music generation (text→music)                                                                                                         | https://suno.ai                      | Annual plan 40% off                                  | $10/month (Pro), $30/month (Premier)           | Pro/Premier annual 40% off                     | 11/24~12/1, v5 and Studio access                                                             |\n",
      "| Replit AI                            | AI coding platform (browser IDE)                                                                                                         | https://replit.com                   | Annual plan 60% off + Free Fast mode (limited time)  | $25/month → $10/month (annual payment)         | $120/year (60% off)                            | 11/27~12/1, Replit Core + Agent included | ⚡ Fast mode 100% free (from 11/19, limited time) |\n",
      "| Writesonic                           | AI content writing and SEO optimization                                                                                                  | https://writesonic.com               | Annual plan 20-30% off                               | $16/month (Freelancer), $33/month (Small Team) | 20-30% off                                     | ~12/3, AI article writing                                                                    |\n",
      "| Surfer SEO                           | AI SEO analysis and content optimization                                                                                                 | https://surferseo.com                | Scale plan 25 AI Tracker prompts free                | $89/month (Essential), $179/month (Scale)      | 20% off + 25 AI Tracker ($95 value)            | ~12/2, for Essential/Scale plans                                                             |\n",
      "| CapCut Pro                           | AI video editing (ByteDance)                                                                                                             | https://capcut.com                   | Desktop only 40% off                                 | $9.99/month                                    | Annual plan 40% off                            | For first-time users, AI design/video tools                                                  |\n",
      "| Descript                             | AI video editing                                                                                                                         | https://web.descript.com/            | Annual plan + 1,000 AI credits + 10 media hours free | $12/month (Hobbyist), $24/month (Creator)      | About 35% off                                  | Until 12/1                                                                                   |\n",
      "| InVideo AI                           | AI video generation (template-based)                                                                                                     | https://invideo.io                   | Annual plan 60-70% off                               | $20/month (Plus), $60/month (Max)              | Up to 70% off                                  | Templates, premium media, auto TTS                                                           |\n",
      "| Murf AI                              | AI voiceover generation                                                                                                                  | https://murf.ai                      | Annual plan 25% off                                  | $19/month (Basic), $26/month (Pro)             | 25% off (code: BFSPL25)                        | Studio quality voiceovers                                                                    |\n",
      "| Beautiful.ai                         | AI presentation design tool                                                                                                              | https://beautiful.ai                 | 30% off                                              | $12/month (Pro)                                | 30% off (code: BLACKFRIDAY30)                  | Automatic layout design                                                                      |\n",
      "| Other Services                       | Other Services                                                                                                                           | Other Services                       | Other Services                                       | Other Services                                 | Other Services                                 | Other Services                                                                               |\n",
      "| Jasper AI                            | AI content writing tool, for bloggers/marketers                                                                                          | https://jasper.ai                    | Annual plan 40% off                                  | $49/month (Creator), $125/month (Pro)          | Regular price $990 → about $594 (with 40% off) | Unlimited AI content generation                                                              |\n",
      "| Copy.ai                              | AI copywriting tool for sales/marketing teams                                                                                            | https://copy.ai                      | Annual plan up to 60% off                            | $49/month (Pro)                                | Pro plan about $259 discount                   | Past maximum 60% discount offered                                                            |\n",
      "| Grammarly Premium                    | AI grammar correction and writing tool                                                                                                   | https://grammarly.com                | Premium plan 50% off                                 | $12/month                                      | Annual plan 50% off                            | 11/18~12/6                                                                                   |\n",
      "| Adobe Creative Cloud                 | Photoshop, Illustrator, and 20+ creative apps                                                                                            | https://adobe.com                    | All apps 50% off                                     | Monthly 39,000 won → about 19,500 won          | About 50% off                                  | Includes generative AI Firefly                                                               |\n",
      "| Mem.ai                               | AI workspace (notes, tasks, email)                                                                                                       | https://mem.ai                       | Standard plan first 2 months 50% off                 | $15/month                                      | 50% off (code: BLACKFRIDAY25)                  | First 2 months only                                                                          |\n",
      "| Durable AI                           | AI website builder                                                                                                                       | https://durable.co                   | Up to 85% off + 2 months free                        | $12/month (Starter)                            | 85% off                                        | SEO optimized sites                                                                          |\n",
      "| Content at Scale                     | AI writing and SEO article generation                                                                                                    | https://contentatscale.ai            | Annual plan 40% off                                  | $250/month (Solo)                              | 40% off                                        | None                                                                                         |\n",
      "| Apollo.io                            | Email discovery and sales automation                                                                                                     | https://apollo.io                    | Annual 50% / 6-month 30% / 3-month 10%               | $49/month (Basic), $79/month (Professional)    | Annual plan 50% (code: BLACKFRIDAY)            | Until 12/3                                                                                   |\n",
      "| OpusClip                             | AI video repurposing (short-form creation)                                                                                               | https://opus.pro                     | Annual Pro plan 65% off                              | Monthly plan first month 50% off               | Annual Pro 65% off                             | For YouTubers/marketers                                                                      |\n",
      "| HeyGen                               | AI video generation (script→video)                                                                                                       | https://heygen.com                   | 50% off + 2,400 credits                              | $29/month (Creator), $89/month (Business)      | 50% (code: BLACKFRIDAY2025)                    | None                                                                                         |\n",
      "| Fliki AI                             | AI text→video, text→voice                                                                                                                | https://fliki.ai                     | Annual plan 50% off                                  | $28/month (Standard), $88/month (Premium)      | 50% (code: FLIKIBLACKFRIDAY50)                 | None                                                                                         |\n",
      "| Relevance AI                         | AI agent builder (no coding required)                                                                                                    | https://relevanceai.com              | Annual plan 60% off                                  | $39/month (Pro), $99/month (Business)          | 60% (code: BLACKFRIDAY25)                      | None                                                                                         |\n",
      "| Runway ML                            | AI image/video generation                                                                                                                | https://runwayml.com                 | Annual plan 20% off                                  | $12/month (Standard)                           | $28/month (Pro)                                | No Black Friday tradition, 20% off with annual payment                                       |\n",
      "| Adobe Audition                       | AI voice and audio editing                                                                                                               | https://adobe.com/audition           | Annual plan 25% off (first year)                     | $22.99/month                                   | First year 25% off (auto-applied)              | Until 12/31                                                                                  |\n",
      "| Beehiiv                              | Newsletter platform (growth tools)                                                                                                       | https://beehiiv.com                  | 20% off                                              | $39/month (Scale), $99/month (Max)             | 20% (code: 2025BFCM)                           | None                                                                                         |\n",
      "| Reply.io                             | AI sales automation platform                                                                                                             | https://reply.io                     | Annual plan 40% off                                  | $60/month (Starter), $90/month (Professional)  | 40% (code: REPLY40)                            | Until 12/5                                                                                   |\n",
      "| 10Web                                | AI website builder                                                                                                                       | https://10web.io                     | 2 years for the price of 1                           | $10/month (Starter), $24/month (Premium)       | 2 years provided (1 year price)                | Until 12/1                                                                                   |\n",
      "| Riverside.fm                         | AI podcast production platform                                                                                                           | https://riverside.fm                 | Pro 20% / Business 30% off                           | $19/month (Pro), $49/month (Business)          | Pro: 20% (code: BLACKFRIDAY2025PRO)            | Until 12/2                                                                                   |\n",
      "| QuillBot Premium                     | AI sentence rewriting/paraphrasing                                                                                                       | https://quillbot.com                 | Annual premium 40% off                               | $9.95/month                                    | 40% off                                        | None                                                                                         |\n",
      "| Mailchimp                            | AI email marketing automation                                                                                                            | https://mailchimp.com                | All paid plans up to 30% off                         | $13/month (Essentials), $20/month (Standard)   | Up to 30% (no code required)                   | Until 12/4                                                                                   |\n",
      "| Poe.com                              | 1,500+ AI tools integration platform                                                                                                     | https://poe.com                      | Monthly $15 (regular $49)                            | $15/month                                      | None                                           | Includes ChatGPT, MidJourney, Claude, etc.                                                   |\n",
      "| Intercom                             | AI customer service platform                                                                                                             | https://intercom.com                 | Professional/Enterprise plans 30% off (first year)   | $74/month (Professional)                       | First year 30% off                             | For new customers                                                                            |\n",
      "| Drift                                | AI customer communication platform                                                                                                       | https://drift.com                    | Starter/Pro plans 25% off (first year)               | $2,500/month (Premium)                         | First year 25% off                             | For new customers                                                                            |\n",
      "| Alter                                | MacOS AI assistant that undestand your screen and your voice                                                                             | https://alterhq.com/                 | $99 lifetime deal (-70%)                             | None                                           | $240/year                                      | $720                                                                                         |\n",
      "| Tagshop AI                           | Helps performance marketers, brand managers and dropshippers to create realistic ugc style video ads quickly and in a cost-effective way | https://tagshop.ai/                  | 60% off on all the annual plans                      | $29/month                                      | $132/year                                      | Until 12/7                                                                                   |\n",
      "\n",
      "| ✅ Total 39 AI Services (Discounts Available) | Discount Range 20%~85% | Black Friday 2025 (11/28)   | ✅ Total 39 AI Services (Discounts Available) | Discount Range 20%~85% | Black Friday 2025 (11/28)   | ✅ Total 39 AI Services (Discounts Available) | Discount Range 20%~85% | Black Friday 2025 (11/28)   | ✅ Total 39 AI Services (Discounts Available) | Discount Range 20%~85% | Black Friday 2025 (11/28)   | ✅ Total 39 AI Services (Discounts Available) | Discount Range 20%~85% | Black Friday 2025 (11/28)   | ✅ Total 39 AI Services (Discounts Available) | Discount Range 20%~85% | Black Friday 2025 (11/28)   | ✅ Total 39 AI Services (Discounts Available) | Discount Range 20%~85% | Black Friday 2025 (11/28)   |\n",
      "|------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|\n",
      "| 📝 Fact-Checked: All discount information verified from official sources as of November 28, 2025     | 📝 Fact-Checked: All discount information verified from official sources as of November 28, 2025     | 📝 Fact-Checked: All discount information verified from official sources as of November 28, 2025     | 📝 Fact-Checked: All discount information verified from official sources as of November 28, 2025     | 📝 Fact-Checked: All discount information verified from official sources as of November 28, 2025     | 📝 Fact-Checked: All discount information verified from official sources as of November 28, 2025     | 📝 Fact-Checked: All discount information verified from official sources as of November 28, 2025     |\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter  \n",
    "from docling.datamodel.base_models import InputFormat  \n",
    "  \n",
    "# Initialize converter with office document support  \n",
    "converter = DocumentConverter(  \n",
    "    allowed_formats=[InputFormat.DOCX, InputFormat.XLSX, InputFormat.PPTX]  \n",
    ")  \n",
    "  \n",
    "# Convert any office document  \n",
    "result = converter.convert(\"sample_documents/sample.xlsx\")  \n",
    "print(result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 10:40:46,466 - INFO - detected formats: [<InputFormat.PPTX: 'pptx'>]\n",
      "2025-12-06 10:40:46,494 - INFO - Going to convert document batch...\n",
      "2025-12-06 10:40:46,498 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-12-06 10:40:46,501 - INFO - Processing document dl.pptx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PowerPoint (PPTX) Conversion:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 10:40:46,766 - INFO - Finished converting document dl.pptx in 0.30 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Introduction to Deep Learning\n",
      "\n",
      "1\n",
      "\n",
      "Date: 12 Nov, 2015\n",
      "\n",
      "# A Motivational Task: Percepts  Concepts\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "- Create algorithms\n",
      "- that can understand scenes and describe \tthem in natural language\n",
      "- that can infer semantic concepts to allow \tmachines to interact with humans using these \tconcepts\n",
      "- Requires creating a series of abstractions\n",
      "- Image (Pixel Intensities)  Objects in Image  Object\n",
      "- Deep learning aims to automatically learn these \tabstractions with little supervision\n",
      "\n",
      "Interactions  Scene Description\n",
      "\n",
      "Courtesy: Yoshua Bengio, Learning Deep Architectures for AI\n",
      "\n",
      "2\n",
      "\n",
      "# Deep Visual-Semantic Alignments for Generating Image Descriptions (Karpathy, Fei-Fei; CVPR 2015)\n",
      "\n",
      "\"boy is doing backflip\n",
      "\n",
      "on wakeboard.\"\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "“two young girls are playing with lego toy.”\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "\"man in black shirt is playing guitar.\"\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "\"construction worker in orange safety vest is working on road.\"\n",
      "\n",
      "3\n",
      "\n",
      "http://cs.stanford.edu/people/karpathy/deepimagesent/\n",
      "\n",
      "4\n",
      "\n",
      "# Challenge in Modelling Complex Behaviour\n",
      "\n",
      "- Too many concepts to learn\n",
      "- Too many object categories\n",
      "- Too many ways of interaction between objects categories\n",
      "- Behaviour is a highly varying function underlying factors\n",
      "- f: L  V\n",
      "- L: latent factors of variation\n",
      "- low dimensional latent factor space\n",
      "- V: visible behaviour\n",
      "- high dimensional observable space\n",
      "- f: highly non-linear function\n",
      "\n",
      "# Example: Learning the Configuration Space of a Robotic Arm\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "5\n",
      "\n",
      "# C-Space Discovery using Isomap\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "# How do We Train Deep Architectures?\n",
      "\n",
      "- Inspiration from mammal brain\n",
      "- Multiple Layers of “neurons” (Rumelhart et al 1986)\n",
      "- Train each layer to compose the representations of the previous layer \tto learn a higher level abstraction\n",
      "- Ex: Pixels  Edges  Contours  Object parts  Object categories\n",
      "- Local Features  Global Features\n",
      "- Train the layers one-by-one (Hinton et al 2006)\n",
      "- Greedy strategy\n",
      "\n",
      "# Multilayer Perceptron with Back-propagation\n",
      "\n",
      "# First deep learning model (Rumelhart, Hinton, Williams 1986)\n",
      "\n",
      "input vector\n",
      "\n",
      "hidden layers\n",
      "\n",
      "outputs\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Back-propagate error signal to get derivatives for learning\n",
      "\n",
      "Compare outputs with correct answer to get error signal\n",
      "\n",
      "Source: Hinton’s 2009 tutorial on Deep Belief Networks\n",
      "\n",
      "8\n",
      "\n",
      "# Drawbacks of Back-propagation based Deep Neural Networks\n",
      "\n",
      "- They are discriminative models\n",
      "- Get all the information from the labels\n",
      "- And the labels don’t give so much of information\n",
      "- Need a substantial amount of labeled data\n",
      "- \n",
      "- Gradient descent with random initialization leads to poor local \tminima\n",
      "\n",
      "# Hand-written digit recognition\n",
      "\n",
      "- Classification of MNIST hand-written digits\n",
      "- 10 digit classes\n",
      "- Input image: 28x28 gray scale\n",
      "- 784 dimensional input\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "# A Deeper Look at the Problem\n",
      "\n",
      "- One hidden layer with 500 neurons\n",
      "- Fitting a model that best explains the training data is an \toptimization problem in a 0.4 million dimensional space\n",
      "- It’s almost impossible for Gradient descent with random \tinitialization to arrive at the global optimum\n",
      "\n",
      "=&gt; 784 * 500 + 500 * 10\n",
      "\n",
      "≈ 0.4 million weights\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "# A Solution – Deep Belief Networks (Hinton et al. 2006)\n",
      "\n",
      "# Pre-trained N/W\tWeights\n",
      "\n",
      "Fast unsupervised pre-training\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Good\n",
      "\n",
      "Solution\n",
      "\n",
      "Slow Fine-tuning\n",
      "\n",
      "(Using Back-propagation)\n",
      "\n",
      "Very slow Back-propagation\n",
      "\n",
      "(Often gets stuck at poor local minima)\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Random Initial position\n",
      "\n",
      "Very high-dimensional parameter space\n",
      "\n",
      "# A Solution – Deep Belief Networks (Hinton et al. 2006)\n",
      "\n",
      "- Before applying back-propagation, pre-train the network as a \tseries of generative models\n",
      "- \n",
      "- Use the weights of the pre-trained network as the initial point \tfor the traditional back-propagation\n",
      "- This leads to quicker convergence to a good solution\n",
      "- \n",
      "- Pre-training is fast; fine-tuning can be slow\n",
      "\n",
      "# Quick Check: MLP vs DBN on MNIST\n",
      "\n",
      "- MLP (1 Hidden Layer)\n",
      "- 1 hour: 2.18%\n",
      "- 14 hours: 1.65%\n",
      "- \n",
      "- DBN\n",
      "- 1 hour: 1.65%\n",
      "- 14 hours: 1.10%\n",
      "- 21 hours: 0.97%\n",
      "\n",
      "Intel QuadCore 2.83GHz, 4GB RAM MLP: Python :: DBN: Matlab\n",
      "\n",
      "# Intermediate Representations in Brain\n",
      "\n",
      "- Disentanglement of factors of variation underlying the data\n",
      "\n",
      "- Distributed Representations\n",
      "- Activation of each neuron is a function of\n",
      "- Feature combinations of different neurons are not necessarily mutually exclusive\n",
      "\n",
      "multiple features of the previous layer\n",
      "\n",
      "- Sparse Representations\n",
      "- Only 1-4% neurons are active at a time\n",
      "\n",
      "Localized Representation\n",
      "\n",
      "Distributed Representation\n",
      "\n",
      "15\n",
      "\n",
      "16\n",
      "\n",
      "# Local vs. Distributed in Input Space\n",
      "\n",
      "- Local Methods\n",
      "- Assume smoothness prior\n",
      "- g(x) = f(g(x1), g(x2), …, g(xk))\n",
      "- {x1, x2, …, xk} are neighbours of x\n",
      "- Require a metric space\n",
      "- A notion of distance or similarity in the input space\n",
      "- Fail when the target function is highly varying\n",
      "- Examples\n",
      "- Nearest Neighbour methods\n",
      "- Kernel methods with a Gaussian kernel\n",
      "- Distributed Methods\n",
      "- No assumption of smoothness  No need for a notion of similarity\n",
      "- Ex: Neural networks\n",
      "\n",
      "# Multi-task Learning\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/Multi-task\\_learning\n",
      "\n",
      "17\n",
      "\n",
      "18\n",
      "\n",
      "# Desiderata for Learning AI\n",
      "\n",
      "- Ability to learn complex, highly-varying functions\n",
      "- Ability to learn multiple levels of abstraction with little human input\n",
      "- Ability to learn from a very large set of examples\n",
      "- Training time linear in the number of examples\n",
      "- Ability to learn from mostly unlabeled data\n",
      "- Unsupervised and semi-supervised\n",
      "- Multi-task learning\n",
      "- Sharing of representations across tasks\n",
      "- Fast predictions\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter  \n",
    "from docling.datamodel.base_models import InputFormat  \n",
    "  \n",
    "# Initialize converter with office document support  \n",
    "converter = DocumentConverter(  \n",
    "    allowed_formats=[InputFormat.DOCX, InputFormat.XLSX, InputFormat.PPTX]  \n",
    ")  \n",
    "print(\"\\nPowerPoint (PPTX) Conversion:\")\n",
    "print(\"-\" * 40)\n",
    "# Convert any office document \n",
    "# Each slide becomes a section in the document\n",
    "result = converter.convert(\"sample_documents/dl.pptx\")  \n",
    "print(result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Image Files with OCR\n",
    "\n",
    "Images are processed through the same pipeline as PDFs, with OCR enabled to extract text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 10:59:07,457 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-06 10:59:07,461 - INFO - Going to convert document batch...\n",
      "2025-12-06 10:59:07,461 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e647edf348883bed75367b22fbe60347\n",
      "2025-12-06 10:59:07,462 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 10:59:10,757 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 10:59:12,677 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 10:59:13,127 - INFO - Processing document scan.pdf\n",
      "2025-12-06 10:59:33,940 - INFO - Finished converting document scan.pdf in 26.48 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image OCR conversion pattern:\n",
      "----------------------------------------\n",
      "Cosine\n",
      "\n",
      "Similarity\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "```\n",
      "Action Rating Romance Rating Vector Persona 5 3 5,3 Person B 10 6 10,6 Person C 1 5 1,5 Step 1 Dot Product A B 5 10 3 6 68 Step 2 Calc the Magnitudes IAI V73 MY 5.83 11131 N F6 11.6 Step 3 Apply the formula Cosine Similarity 7.6 68.03 1 ~ 2 = 2 N\n",
      "```\n",
      "\n",
      "Casel\n",
      "\n",
      "A\n",
      "\n",
      "B\n",
      "\n",
      "Cosine\n",
      "\n",
      "Person\n",
      "\n",
      "A\n",
      "\n",
      "B\n",
      "\n",
      "are\n",
      "\n",
      "Visual\n",
      "\n",
      "1\n",
      "\n",
      "Value to\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "A\n",
      "\n",
      "and\n",
      "\n",
      "Vetore nearly\n",
      "\n",
      "Case identical\n",
      "\n",
      "2\n",
      "\n",
      "a\n",
      "\n",
      "AB\n",
      "\n",
      "Perpendicular\n",
      "\n",
      "Cosine\n",
      "\n",
      "Range\n",
      "\n",
      "I\n",
      "\n",
      "Person C\n",
      "\n",
      "0\n",
      "\n",
      "Cabe 3\n",
      "\n",
      "Â\n",
      "\n",
      "opposite\n",
      "\n",
      "Cosine\n",
      "\n",
      "1\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "## Word 2 Vue\n",
      "\n",
      "word embedding technique\n",
      "\n",
      "Two\n",
      "\n",
      "Architectures\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- formula-not-decoded -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Benefits\n",
      "\n",
      "1\n",
      "\n",
      "of\n",
      "\n",
      "Rare\n",
      "\n",
      "Con\n",
      "\n",
      "Slowwe to\n",
      "\n",
      "Skiquam words\n",
      "\n",
      "train as\n",
      "\n",
      "compared to\n",
      "\n",
      "CBOW\n",
      "\n",
      "Word\n",
      "\n",
      "Shallow\n",
      "\n",
      "2\n",
      "\n",
      "Vec\n",
      "\n",
      "Neural\n",
      "\n",
      "Input layer\n",
      "\n",
      "Vocabular Size\n",
      "\n",
      "10,000\n",
      "\n",
      "2013\n",
      "\n",
      "Network\n",
      "\n",
      "Hidden layer\n",
      "\n",
      "Embedding layer\n",
      "\n",
      "3000\n",
      "\n",
      "word\n",
      "\n",
      "Embecklings\n",
      "\n",
      "Output layer\n",
      "\n",
      "10,000\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Training\n",
      "\n",
      "Set\n",
      "\n",
      "Sample\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "Supported formats: PNG, JPEG, TIFF, BMP, WEBP\n",
      "Multi-page TIFF files are automatically handled.\n"
     ]
    }
   ],
   "source": [
    "# Image conversion with OCR\n",
    "from docling.document_converter import DocumentConverter, ImageFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "# Configure OCR for images\n",
    "image_pipeline_options = PdfPipelineOptions(\n",
    "    do_ocr=True,  # Enable OCR for text extraction from images\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.IMAGE: ImageFormatOption(\n",
    "            pipeline_options=image_pipeline_options\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# Conversion pattern:\n",
    "result = converter.convert(\"sample_documents/scan.pdf\")\n",
    "text = result.document.export_to_markdown()\n",
    "\n",
    "print(\"Image OCR conversion pattern:\")\n",
    "print(\"-\" * 40)\n",
    "print(text)\n",
    "print(\"Supported formats: PNG, JPEG, TIFF, BMP, WEBP\")\n",
    "print(\"Multi-page TIFF files are automatically handled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Audio Files (ASR Pipeline)\n",
    "\n",
    "Docling can transcribe audio files using Automatic Speech Recognition (ASR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run in a GPU\n",
    "\n",
    "https://colab.research.google.com/drive/1EemOQ8V5BeGz1v7W2xjD6YUC3eZdJLOU?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter  \n",
    "from docling.datamodel.base_models import InputFormat  \n",
    "from docling.datamodel import asr_model_specs  \n",
    "  \n",
    "# Initialize converter with ASR support  \n",
    "converter = DocumentConverter(  \n",
    "    allowed_formats=[InputFormat.AUDIO],  \n",
    "    format_options={  \n",
    "        InputFormat.AUDIO: AudioFormatOption(  \n",
    "            pipeline_cls=AsrPipeline,  \n",
    "            pipeline_options=AsrPipelineOptions(  \n",
    "                asr_options=asr_model_specs.WHISPER_TINY  \n",
    "            )  \n",
    "        )  \n",
    "    }  \n",
    ")  \n",
    "  \n",
    "# Convert audio file  \n",
    "result = converter.convert(\"sample_documents/sample.mp3\")  \n",
    "print(result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio transcription example (requires 'asr' extra)\n",
    "from docling.document_converter import DocumentConverter, AudioFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.asr_pipeline import AsrPipeline\n",
    "from docling.datamodel.pipeline_options import AsrPipelineOptions\n",
    "from docling.datamodel import asr_model_specs\n",
    "\n",
    "print(\"Audio Transcription (ASR) Pattern:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# Configure ASR pipeline\n",
    "asr_options = AsrPipelineOptions(\n",
    "    asr_options=asr_model_specs.WHISPER_TINY,  # or WHISPER_BASE, WHISPER_SMALL\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.AUDIO: AudioFormatOption(\n",
    "            pipeline_cls=AsrPipeline,\n",
    "            pipeline_options=asr_options,\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "result = converter.convert(\"sample_documents/sample.mp3\")  # or .wav\n",
    "transcript = result.document.export_to_markdown()\n",
    "print(transcript)\n",
    "print(\"\\nSupported formats: WAV, MP3\")\n",
    "print(\"Requires: pip install 'docling[asr]'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. GraniteDocling MLX (Apple Silicon M1/M2/M3/M4):\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 11:33:50,247 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-06 11:33:50,253 - INFO - Going to convert document batch...\n",
      "2025-12-06 11:33:50,254 - INFO - Initializing pipeline for VlmPipeline with options hash e58bc69b0ac7e3ef286a71274276cf73\n",
      "2025-12-06 11:33:51,207 - INFO - Processing document 2408.09869v5.pdf\n",
      "2025-12-06 11:38:16,214 - INFO - Finished converting document 2408.09869v5.pdf in 266.40 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!-- image -->\n",
      "\n",
      "## Docling Technical Report\n",
      "\n",
      "Version 1.0\n",
      "\n",
      "Christoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\n",
      "\n",
      "AI4K Group, IBM Research Rüschlikon, Switzerland\n",
      "\n",
      "## Abstract\n",
      "\n",
      "This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.\n",
      "\n",
      "## 1 Introduction\n",
      "\n",
      "Converting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.\n",
      "\n",
      "With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissi\n"
     ]
    }
   ],
   "source": [
    "# VLM Pipeline Configuration\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "\n",
    "print(\"\\n2. GraniteDocling MLX (Apple Silicon M1/M2/M3/M4):\")\n",
    "print(\"-\" * 40)\n",
    "pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=vlm_model_specs.GRANITEDOCLING_MLX,\n",
    ")\n",
    "\n",
    "vlm_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "# Convert with VLM\n",
    "pdf_url=\"https://arxiv.org/pdf/2408.09869\"\n",
    "result = vlm_converter.convert(pdf_url)\n",
    "vlm_markdown = result.document.export_to_markdown()\n",
    "print(vlm_markdown[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Pipeline Options & Configuration\n",
    "\n",
    "Docling provides extensive configuration options for customizing the document processing pipeline.\n",
    "\n",
    "### 4.1 OCR Configuration\n",
    "\n",
    "Multiple OCR engines are available, each with different strengths:\n",
    "\n",
    "| Engine | Best For | Installation |\n",
    "|--------|----------|-------------|\n",
    "| RapidOCR | General use (default) | Included |\n",
    "| EasyOCR | Multi-language | `pip install 'docling[easyocr]'` |\n",
    "| Tesseract | Production | System install + `pip install 'docling[tesserocr]'` |\n",
    "| OcrMac | macOS native | `pip install 'docling[ocrmac]'` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR configurations created successfully!\n",
      "\n",
      "Available OCR options:\n",
      "  - RapidOcrOptions: Fast, general-purpose\n",
      "  - EasyOcrOptions: Multi-language, GPU support\n",
      "  - TesseractOcrOptions: Production, requires system Tesseract\n",
      "  - OcrMacOptions: macOS Vision framework (macOS only)\n"
     ]
    }
   ],
   "source": [
    "# OCR Configuration Examples\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    EasyOcrOptions,\n",
    "    RapidOcrOptions,\n",
    "    TesseractOcrOptions,\n",
    ")\n",
    "\n",
    "# Option 1: RapidOCR (default, fast)\n",
    "rapid_ocr_options = PdfPipelineOptions(\n",
    "    do_ocr=True,\n",
    "    ocr_options=RapidOcrOptions(),\n",
    ")\n",
    "\n",
    "# Option 2: EasyOCR (multi-language support)\n",
    "easy_ocr_options = PdfPipelineOptions(\n",
    "    do_ocr=True,\n",
    "    ocr_options=EasyOcrOptions(\n",
    "        lang=[\"en\", \"fr\", \"de\"],  # English, French, German\n",
    "        use_gpu=True,  # Use GPU if available\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Option 3: Tesseract (production-ready)\n",
    "tesseract_options = PdfPipelineOptions(\n",
    "    do_ocr=True,\n",
    "    ocr_options=TesseractOcrOptions(\n",
    "        lang=[\"eng\", \"fra\"],  # Tesseract language codes\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"OCR configurations created successfully!\")\n",
    "print(\"\\nAvailable OCR options:\")\n",
    "print(\"  - RapidOcrOptions: Fast, general-purpose\")\n",
    "print(\"  - EasyOcrOptions: Multi-language, GPU support\")\n",
    "print(\"  - TesseractOcrOptions: Production, requires system Tesseract\")\n",
    "print(\"  - OcrMacOptions: macOS Vision framework (macOS only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 11:45:31,653 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-06 11:45:31,657 - INFO - Going to convert document batch...\n",
      "2025-12-06 11:45:31,658 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 154138fdf3f99bf9804fd62accd0504f\n",
      "2025-12-06 11:45:31,658 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 11:45:31,848 - WARNING - Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
      "2025-12-06 11:45:32,833 - INFO - Download complete.\n",
      "2025-12-06 11:45:36,638 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 11:45:38,205 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 11:45:38,715 - INFO - Processing document scan.pdf\n",
      "2025-12-06 11:45:59,345 - INFO - Finished converting document scan.pdf in 27.69 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converter configured with EasyOCR and accelerator options.\n",
      "Accelerator device: AcceleratorDevice.AUTO\n"
     ]
    }
   ],
   "source": [
    "# Using EasyOCR with custom language support\n",
    "# This example shows how to set up OCR for scanned documents\n",
    "\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, EasyOcrOptions\n",
    "from docling.datamodel.accelerator_options import AcceleratorOptions, AcceleratorDevice\n",
    "\n",
    "# Configure EasyOCR with accelerator options\n",
    "pipeline_options = PdfPipelineOptions(\n",
    "    do_ocr=True,\n",
    "    do_table_structure=True,\n",
    "    ocr_options=EasyOcrOptions(\n",
    "        lang=[\"en\"],\n",
    "    ),\n",
    "    accelerator_options=AcceleratorOptions(\n",
    "        device=AcceleratorDevice.AUTO,  # AUTO, CPU, CUDA, or MPS\n",
    "        num_threads=4,\n",
    "    ),\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Conversion pattern:\n",
    "result = converter.convert(\"sample_documents/scan.pdf\")\n",
    "text = result.document.export_to_markdown()\n",
    "print(\"Converter configured with EasyOCR and accelerator options.\")\n",
    "print(f\"Accelerator device: {AcceleratorDevice.AUTO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cosine\\n\\nSimilarity\\n\\n<!-- formula-not-decoded -->\\n\\n<!-- formula-not-decoded -->\\n\\n<!-- image -->\\n\\n```\\nAction Rating Romance Rating Vector Persona 5 3 5,3 Person B 10 6 10,6 Person C 1 5 1,5 Step 1 Dot Product A B 5 10 3 6 68 Step 2 Calc the Magnitudes IAI V73 MY 5.83 11131 N F6 11.6 Step 3 Apply the formula Cosine Similarity 7.6 68.03 1 ~ = = 2 N\\n```\\n\\nCasel\\n\\nA\\n\\nB\\n\\nCosine\\n\\nPerson\\n\\nA\\n\\nB\\n\\nare\\n\\nVisual\\n\\n1\\n\\nValue to\\n\\n<!-- formula-not-decoded -->\\n\\n<!-- formula-not-decoded -->\\n\\nA\\n\\nand\\n\\nVetore nearly\\n\\nCase identical\\n\\n2\\n\\na\\n\\nAB\\n\\nPerpendicular\\n\\nCosine\\n\\nRange\\n\\nI\\n\\nPerson C\\n\\n0\\n\\nCabe 3\\n\\nopposite\\n\\nCosine\\n\\n1\\n\\n<!-- formula-not-decoded -->\\n\\n<!-- formula-not-decoded -->\\n\\n<!-- formula-not-decoded -->\\n\\n<!-- formula-not-decoded -->\\n\\n## Word 2 Vue\\n\\nword embedding technique\\n\\nTwo\\n\\nArchitectures\\n\\n<!-- image -->\\n\\n<!-- formula-not-decoded -->\\n\\n<!-- image -->\\n\\nBenefits\\n\\n1\\n\\nof\\n\\nRare\\n\\nCon\\n\\nSlowwe to\\n\\nSkiquam words\\n\\ntrain as\\n\\ncompared to\\n\\nCBOW\\n\\nWord\\n\\nShallow\\n\\n2\\n\\nVec\\n\\nNeural\\n\\nInput layer\\n\\nVocabular Size\\n\\n10,000\\n\\n2013\\n\\nNetwork\\n\\nHidden layer\\n\\nEmbedding layer\\n\\n3000\\n\\nword\\n\\nEmbecklings\\n\\nOutput layer\\n\\n10,000\\n\\n<!-- image -->\\n\\nTraining\\n\\nSet\\n\\nSample\\n\\n<!-- image -->\\n\\n<!-- image -->'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Table Structure Options\n",
    "\n",
    "Configure table extraction with TableFormer model settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 11:56:30,572 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-06 11:56:30,580 - INFO - Going to convert document batch...\n",
      "2025-12-06 11:56:30,581 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e647edf348883bed75367b22fbe60347\n",
      "2025-12-06 11:56:30,582 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 11:56:34,601 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 11:56:36,252 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 11:56:36,748 - INFO - Processing document 2408.09869v1.pdf\n",
      "2025-12-06 11:56:51,934 - INFO - Finished converting document 2408.09869v1.pdf in 26.11 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table extraction configured:\n",
      "  - Cell matching: True\n",
      "  - Mode: TableFormerMode.ACCURATE\n"
     ]
    }
   ],
   "source": [
    "# Table structure configuration\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    TableStructureOptions,\n",
    "    TableFormerMode,\n",
    ")\n",
    "\n",
    "# Configure table extraction\n",
    "table_options = TableStructureOptions(\n",
    "    do_cell_matching=True,  # Match cells with text content\n",
    "    mode=TableFormerMode.ACCURATE,  # ACCURATE or FAST\n",
    ")\n",
    "\n",
    "pipeline_options = PdfPipelineOptions(\n",
    "    do_table_structure=True,\n",
    "    table_structure_options=table_options,\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Conversion pattern:\n",
    "pdf_url =\"https://arxiv.org/pdf/2408.09869v1\"\n",
    "result = converter.convert(pdf_url)\n",
    "text = result.document.export_to_markdown()\n",
    "print(\"Table extraction configured:\")\n",
    "print(f\"  - Cell matching: {table_options.do_cell_matching}\")\n",
    "print(f\"  - Mode: {table_options.mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!-- image -->\\n\\n## Docling Technical Report\\n\\nVersion 1.0\\n\\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\\n\\nAI4K Group, IBM Research R¨ uschlikon, Switzerland\\n\\n## Abstract\\n\\nThis technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.\\n\\n## 1 Introduction\\n\\nConverting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.\\n\\nWith Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.\\n\\nHere is what Docling delivers today:\\n\\n- Converts PDF documents to JSON or Markdown format, stable and lightning fast\\n- Understands detailed page layout, reading order, locates figures and recovers table structures\\n- Extracts metadata from the document, such as title, authors, references and language\\n- Optionally applies OCR, e.g. for scanned PDFs\\n- Can be configured to be optimal for batch-mode (i.e high throughput, low time-to-solution) or interactive mode (compromise on efficiency, low time-to-solution)\\n- Can leverage different accelerators (GPU, MPS, etc).\\n\\n## 2 Getting Started\\n\\nTo use Docling, you can simply install the docling package from PyPI. Documentation and examples are available in our GitHub repository at github.com/DS4SD/docling. All required model assets 1 are downloaded to a local huggingface datasets cache on first use, unless you choose to pre-install the model assets in advance.\\n\\nDocling provides an easy code interface to convert PDF documents from file system, URLs or binary streams, and retrieve the output in either JSON or Markdown format. For convenience, separate methods are offered to convert single documents or batches of documents. A basic usage example is illustrated below. Further examples are available in the Doclign code repository.\\n\\nfrom docling.document\\\\_converter import DocumentConverter\\n\\n```\\nsource = \"https://arxiv.org/pdf/2206.01062\" # PDF path or URL converter = DocumentConverter() doc = converter.convert_single(source) print(doc.export_to_markdown()) # output: \"## DocLayNet: A Large Human -Annotated Dataset for Document -Layout Analysis [...]\"\\n```\\n\\nOptionally, you can configure custom pipeline features and runtime options, such as turning on or off features (e.g. OCR, table structure recognition), enforcing limits on the input document size, and defining the budget of CPU threads. Advanced usage examples and options are documented in the README file. Docling also provides a Dockerfile to demonstrate how to install and run it inside a container.\\n\\n## 3 Processing pipeline\\n\\nDocling implements a linear pipeline of operations, which execute sequentially on each given document (see Fig. 1). Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support downstream operations. Then, the standard model pipeline applies a sequence of AI models independently on every page in the document to extract features and content, such as layout and table structures. Finally, the results from all pages are aggregated and passed through a post-processing stage, which augments metadata, detects the document language, infers reading-order and eventually assembles a typed document object which can be serialized to JSON or Markdown.\\n\\n## 3.1 PDF backends\\n\\nTwo basic requirements to process PDF documents in our pipeline are a) to retrieve all text content and their geometric coordinates on each page and b) to render the visual representation of each page as it would appear in a PDF viewer. Both these requirements are encapsulated in Docling\\'s PDF backend interface. While there are several open-source PDF parsing libraries available for python, we faced major obstacles with all of them for different reasons, among which were restrictive\\n\\n1 see huggingface.co/ds4sd/docling-models/\\n\\nFigure 1: Sketch of Docling\\'s default processing pipeline. The inner part of the model pipeline is easily customizable and extensible.\\n\\n<!-- image -->\\n\\nlicensing (e.g. pymupdf [7]), poor speed or unrecoverable quality issues, such as merged text cells across far-apart text tokens or table columns (pypdfium, PyPDF) [15, 14].\\n\\nWe therefore decided to provide multiple backend choices, and additionally open-source a custombuilt PDF parser, which is based on the low-level qpdf [4] library. It is made available in a separate package named docling-parse and powers the default PDF backend in Docling. As an alternative, we provide a PDF backend relying on pypdfium , which may be a safe backup choice in certain cases, e.g. if issues are seen with particular font encodings.\\n\\n## 3.2 AI models\\n\\nAs part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.\\n\\n## Layout Analysis Model\\n\\nOur layout analysis model is an object-detector which predicts the bounding-boxes and classes of various elements on the image of a given page. Its architecture is derived from RT-DETR [16] and re-trained on DocLayNet [13], our popular human-annotated dataset for document-layout analysis, among other proprietary datasets. For inference, our implementation relies on the onnxruntime [5].\\n\\nThe Docling pipeline feeds page images at 72 dpi resolution, which can be processed on a single CPU with sub-second latency. All predicted bounding-box proposals for document elements are post-processed to remove overlapping proposals based on confidence and size, and then intersected with the text tokens in the PDF to group them into meaningful and complete units such as paragraphs, section titles, list items, captions, figures or tables.\\n\\n## Table Structure Recognition\\n\\nThe TableFormer model [12], first published in 2022 and since refined with a custom structure token language [9], is a vision-transformer model for table structure recovery. It can predict the logical row and column structure of a given table based on an input image, and determine which table cells belong to column headers, row headers or the table body. Compared to earlier approaches, TableFormer handles many characteristics of tables, such as partial or no borderlines, empty cells, rows or columns, cell spans and hierarchy both on column-heading or row-heading level, tables with inconsistent indentation or alignment and other complexities. For inference, our implementation relies on PyTorch [2].\\n\\nThe Docling pipeline feeds all table objects detected in the layout analysis to the TableFormer model, by providing an image-crop of the table and the included text cells. TableFormer structure predictions are matched back to the PDF cells in post-processing to avoid expensive re-transcription text in the table image. Typical tables require between 2 and 6 seconds to be processed on a standard CPU, strongly depending on the amount of included table cells.\\n\\n## OCR\\n\\nDocling provides optional support for OCR, for example to cover scanned PDFs or content in bitmaps images embedded on a page. In our initial release, we rely on EasyOCR [1], a popular thirdparty OCR library with support for many languages. Docling, by default, feeds a high-resolution page image (216 dpi) to the OCR engine, to allow capturing small print detail in decent quality. While EasyOCR delivers reasonable transcription quality, we observe that it runs fairly slow on CPU (upwards of 30 seconds per page).\\n\\nWe are actively seeking collaboration from the open-source community to extend Docling with additional OCR backends and speed improvements.\\n\\n## 3.3 Assembly\\n\\nIn the final pipeline stage, Docling assembles all prediction results produced on each page into a well-defined datatype that encapsulates a converted document, as defined in the auxiliary package docling-core . The generated document object is passed through a post-processing model which leverages several algorithms to augment features, such as detection of the document language, correcting the reading order, matching figures with captions and labelling metadata such as title, authors and references. The final output can then be serialized to JSON or transformed into a Markdown representation at the users request.\\n\\n## 3.4 Extensibility\\n\\nDocling provides a straight-forward interface to extend its capabilities, namely the model pipeline. A model pipeline constitutes the central part in the processing, following initial document parsing and preceding output assembly, and can be fully customized by sub-classing from an abstract baseclass ( BaseModelPipeline ) or cloning the default model pipeline. This effectively allows to fully customize the chain of models, add or replace models, and introduce additional pipeline configuration parameters. To use a custom model pipeline, the custom pipeline class to instantiate can be provided as an argument to the main document conversion methods. We invite everyone in the community to propose additional or alternative models and improvements.\\n\\nImplementations of model classes must satisfy the python Callable interface. The \\\\_\\\\_call\\\\_\\\\_ method must accept an iterator over page objects, and produce another iterator over the page objects which were augmented with the additional features predicted by the model, by extending the provided PagePredictions data model accordingly.\\n\\n## 4 Performance\\n\\nIn this section, we establish some reference numbers for the processing speed of Docling and the resource budget it requires. All tests in this section are run with default options on our standard test set distributed with Docling, which consists of three papers from arXiv and two IBM Redbooks, with a total of 225 pages. Measurements were taken using both available PDF backends on two different hardware systems: one MacBook Pro M3 Max, and one bare-metal server running Ubuntu 20.04 LTS on an Intel Xeon E5-2690 CPU. For reproducibility, we fixed the thread budget (through setting OMP NUM THREADS environment variable ) once to 4 (Docling default) and once to 16 (equal to full core count on the test hardware). All results are shown in Table 1.\\n\\nIf you need to run Docling in very low-resource environments, please consider configuring the pypdfium backend. While it is faster and more memory efficient than the default docling-parse backend, it will come at the expense of worse quality results, especially in table structure recovery.\\n\\nEstablishing GPU acceleration support for the AI models is currently work-in-progress and largely untested, but may work implicitly when CUDA is available and discovered by the onnxruntime and\\n\\ntorch runtimes backing the Docling pipeline. We will deliver updates on this topic at in a future version of this report.\\n\\nTable 1: Runtime characteristics of Docling with the standard model pipeline and settings, on our test dataset of 225 pages, on two different systems. OCR is disabled. We show the time-to-solution (TTS), computed throughput in pages per second, and the peak memory used (resident set size) for both the Docling-native PDF backend and for the pypdfium backend, using 4 and 16 threads.\\n\\n| CPU                     | Thread budget   | native backend   | native backend   | native backend   | pypdfium backend   | pypdfium backend   | pypdfium backend   |\\n|-------------------------|-----------------|------------------|------------------|------------------|--------------------|--------------------|--------------------|\\n|                         |                 | TTS              | Pages/s          | Mem              | TTS                | Pages/s            | Mem                |\\n| Apple M3 Max (16 cores) | 4 16            | 177 s 167 s      | 1.27 1.34        | 6.20 GB          | 103 s 92 s         | 2.18 2.45          | 2.56 GB            |\\n| Intel(R) Xeon E5-2690   | 4 16            | 375 s 244 s      | 0.60 0.92        | 6.16 GB          | 239 s 143 s        | 0.94 1.57          | 2.42 GB            |\\n\\n## 5 Applications\\n\\nThanks to the high-quality, richly structured document conversion achieved by Docling, its output qualifies for numerous downstream applications. For example, Docling can provide a base for detailed enterprise document search, passage retrieval or classification use-cases, or support knowledge extraction pipelines, allowing specific treatment of different structures in the document, such as tables, figures, section structure or references. For popular generative AI application patterns, such as retrieval-augmented generation (RAG), we provide quackling , an open-source package which capitalizes on Docling\\'s feature-rich document output to enable document-native optimized vector embedding and chunking. It plugs in seamlessly with LLM frameworks such as LlamaIndex [8]. Since Docling is fast, stable and cheap to run, it also makes for an excellent choice to build document-derived datasets. With its powerful table structure recognition, it provides significant benefit to automated knowledge-base construction [11, 10]. Docling is also integrated within the open IBM data prep kit [6], which implements scalable data transforms to build large-scale multi-modal training datasets.\\n\\n## 6 Future work and contributions\\n\\nDocling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of content, as well as augment extracted document metadata with additional information. Further investment into testing and optimizing GPU acceleration as well as improving the Docling-native PDF backend are on our roadmap, too.\\n\\nWe encourage everyone to propose or implement additional features and models, and will gladly take your inputs and contributions under review . The codebase of Docling is open for use and contribution, under the MIT license agreement and in alignment with our contributing guidelines included in the Docling repository. If you use Docling in your projects, please consider citing this technical report.\\n\\n## References\\n\\n- [1] J. AI. Easyocr: Ready-to-use ocr with 80+ supported languages. https://github.com/ JaidedAI/EasyOCR , 2024. Version: 1.7.0.\\n- [2] J. Ansel, E. Yang, H. He, N. Gimelshein, A. Jain, M. Voznesensky, B. Bao, P. Bell, D. Berard, E. Burovski, G. Chauhan, A. Chourdia, W. Constable, A. Desmaison, Z. DeVito, E. Ellison, W. Feng, J. Gong, M. Gschwind, B. Hirsh, S. Huang, K. Kalambarkar, L. Kirsch, M. Lazos, M. Lezcano, Y. Liang, J. Liang, Y. Lu, C. Luk, B. Maher, Y. Pan, C. Puhrsch, M. Reso, M. Saroufim, M. Y. Siraichi, H. Suk, M. Suo, P. Tillet, E. Wang, X. Wang, W. Wen, S. Zhang, X. Zhao, K. Zhou, R. Zou, A. Mathews, G. Chanan, P. Wu, and S. Chintala. Pytorch 2: Faster\\n\\nmachine learning through dynamic python bytecode transformation and graph compilation. In Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS \\'24) . ACM, 4 2024. doi: 10.1145/3620665.3640366. URL https://pytorch.org/assets/pytorch2-2.pdf .\\n\\n- [3] C. Auer, M. Dolfi, A. Carvalho, C. B. Ramis, and P. W. Staar. Delivering document conversion as a cloud service with high throughput and responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) , pages 363-373. IEEE, 2022.\\n- [4] J. Berkenbilt. Qpdf: A content-preserving pdf document transformer, 2024. URL https: //github.com/qpdf/qpdf .\\n- [5] O. R. developers. Onnx runtime. https://onnxruntime.ai/ , 2024. Version: 1.18.1.\\n- [6] IBM. Data Prep Kit: a community project to democratize and accelerate unstructured data preparation for LLM app developers, 2024. URL https://github.com/IBM/ data-prep-kit .\\n- [7] A. S. Inc. PyMuPDF, 2024. URL https://github.com/pymupdf/PyMuPDF .\\n- [8] J. Liu. LlamaIndex, 11 2022. URL https://github.com/jerryjliu/llama\\\\_index .\\n- [9] M. Lysak, A. Nassar, N. Livathinos, C. Auer, and P. Staar. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos´ e, CA, USA, August 21-26, 2023, Proceedings, Part II , pages 37-50, Berlin, Heidelberg, Aug. 2023. Springer-Verlag. ISBN 978-3-031-41678-1. doi: 10. 1007/978-3-031-41679-8 3. URL https://doi.org/10.1007/978-3-031-41679-8\\\\_3 .\\n- [10] L. Mishra, S. Dhibi, Y. Kim, C. Berrospi Ramis, S. Gupta, M. Dolfi, and P. Staar. Statements: Universal information extraction from tables with large language models for ESG KPIs. In D. Stammbach, J. Ni, T. Schimanski, K. Dutia, A. Singh, J. Bingler, C. Christiaen, N. Kushwaha, V. Muccione, S. A. Vaghefi, and M. Leippold, editors, Proceedings of the 1st Workshop on Natural Language Processing Meets Climate Change (ClimateNLP 2024) , pages 193-214, Bangkok, Thailand, Aug. 2024. Association for Computational Linguistics. URL https://aclanthology.org/2024.climatenlp-1.15 .\\n- [11] L. Morin, V. Weber, G. I. Meijer, F. Yu, and P. W. J. Staar. Patcid: an open-access dataset of chemical structures in patent documents. Nature Communications , 15(1):6532, August 2024. ISSN 2041-1723. doi: 10.1038/s41467-024-50779-y. URL https://doi.org/10.1038/ s41467-024-50779-y .\\n- [12] A. Nassar, N. Livathinos, M. Lysak, and P. Staar. Tableformer: Table structure understanding with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4614-4623, 2022.\\n- [13] B. Pfitzmann, C. Auer, M. Dolfi, A. S. Nassar, and P. Staar. Doclaynet: a large humanannotated dataset for document-layout segmentation. pages 3743-3751, 2022.\\n- [14] pypdf Maintainers. pypdf: A Pure-Python PDF Library, 2024. URL https://github.com/ py-pdf/pypdf .\\n- [15] P. Team. PyPDFium2: Python bindings for PDFium, 2024. URL https://github.com/ pypdfium2-team/pypdfium2 .\\n- [16] Y. Zhao, W. Lv, S. Xu, J. Wei, G. Wang, Q. Dang, Y. Liu, and J. Chen. Detrs beat yolos on real-time object detection, 2023.\\n\\n## Appendix\\n\\nIn this section, we illustrate a few examples of Docling\\'s output in Markdown and JSON.\\n\\n<!-- image -->\\n\\n1 INTRODUCTION\\n\\nDespite the substantial improvements achieved with machine-learning (ML) approaches and deep neural networks in recent years, document conversion remains a challenging problem, as demonstrated by the numerous public competitions held on this topic [1-4]. The challenge originates from the huge variability in PDF documents regarding layout, language and formats (scanned, programmatic or a combination of both). Engineering a single ML model that can be applied on all types of documents and provides high-quality layout segmentation remains to this day extremely challenging [5]. To highlight the variability in document layouts, we show a few example documents from the DocLayNet dataset in Figure 1. Figure 2: Title page of the DocLayNet paper (arxiv.org/pdf/2206.01062) - left PDF, right rendered Markdown. If recognized, metadata such as authors are appearing first under the title. Text content inside figures is currently dropped, the caption is retained and linked to the figure in the JSON representation (not shown).\\n\\nKDD \\'22, August 14-18, 2022, Washington, DC, USA Birgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, and Peter Staar\\n\\nTable 2: Prediction performance (mAP@0.5-0.95) of object detection networks on DocLayNet test set. The MRCNN (Mask R-CNN) and FRCNN (Faster R-CNN) models with ResNet-50 or ResNet-101 backbone were trained based on the network architectures from the detectron2 model zoo (Mask R-CNN R50, R101-FPN 3x, Faster R-CNN R101-FPN 3x), with default configurations. The YOLO implementation utilized was YOLOv5x6 [13]. All models were initialised using pre-trained weights from the COCO 2017 dataset.\\n\\n|                                                                                                        | human                                                                   | MRCNN R50 R101                                                                                                          | FRCNN R101                                                  | YOLO v5x6                                                   |\\n|--------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------|-------------------------------------------------------------|\\n| Caption Footnote Formula List-item Page-footer Page-header Picture Section-header Table Text Title All | 84-89 83-91 83-85 87-88 93-94 85-89 69-71 83-84 77-81 84-86 60-72 82-83 | 68.4 71.5 70.9 71.8 60.1 63.4 81.2 80.8 61.6 59.3 71.9 70.0 71.7 72.7 67.6 69.3 82.2 82.9 84.6 85.8 76.7 80.4 72.4 73.5 | 70.1 73.7 63.5 81.0 58.9 72.0 72.0 68.4 82.2 85.4 79.9 73.4 | 77.7 77.2 66.2 86.2 61.1 67.9 77.1 74.6 86.3 88.1 82.7 76.8 |\\n\\nto avoid this at any cost in order to have clear, unbiased baseline numbers for human document-layout annotation. Third, we introduced the feature of snapping boxes around text segments to obtain a pixel-accurate annotation and again reduce time and effort. The CCS annotation tool automatically shrinks every user-drawn box to the minimum bounding-box around the enclosed text-cells for all purely text-based segments, which excludes only Table and Picture . For the latter, we instructed annotation staff to minimise inclusion of surrounding whitespace while including all graphical lines. A downside of snapping boxes to enclosed text cells is that some wrongly parsed PDF pages cannot be annotated correctly and need to be skipped. Fourth, we established a way to flag pages as rejected for cases where no valid annotation according to the label guidelines could be achieved. Example cases for this would be PDF pages that render incorrectly or contain layouts that are impossible to capture with non-overlapping rectangles. Such rejected pages are not contained in the final dataset. With all these measures in place, experienced annotation staff managed to annotate a single page in a typical timeframe of 20s to 60s, depending on its complexity.\\n\\n## 5 EXPERIMENTS\\n\\nThe primary goal of DocLayNet is to obtain high-quality ML models capable of accurate document-layout analysis on a wide variety of challenging layouts. As discussed in Section 2, object detection models are currently the easiest to use, due to the standardisation of ground-truth data in COCO format [16] and the availability of general frameworks such as detectron2 [17]. Furthermore, baseline numbers in PubLayNet and DocBank were obtained using standard object detection models such as Mask R-CNN and Faster R-CNN. As such, we will relate to these object detection methods in this\\n\\nFigure 5: Prediction performance (mAP@0.5-0.95) of a Mask R-CNNnetworkwithResNet50backbonetrainedonincreasing fractions of the DocLayNet dataset. The learning curve flattens around the 80% mark, indicating that increasing the size of the DocLayNet dataset with similar data will not yield significantly better predictions.\\n\\n<!-- image -->\\n\\npaper and leave the detailed evaluation of more recent methods mentioned in Section 2 for future work.\\n\\nIn this section, we will present several aspects related to the performance of object detection models on DocLayNet. Similarly as in PubLayNet, we will evaluate the quality of their predictions using mean average precision (mAP) with 10 overlaps that range from 0.5 to 0.95 in steps of 0.05 (mAP@0.5-0.95). These scores are computed by leveraging the evaluation code provided by the COCO API [16].\\n\\n## Baselines for Object Detection\\n\\nIn Table 2, we present baseline experiments (given in mAP) on Mask R-CNN [12], Faster R-CNN [11], and YOLOv5 [13]. Both training and evaluation were performed on RGB images with dimensions of 1025 × 1025 pixels. For training, we only used one annotation in case of redundantly annotated pages. As one can observe, the variation in mAP between the models is rather low, but overall between 6 and 10% lower than the mAP computed from the pairwise human annotations on triple-annotated pages. This gives a good indication that the DocLayNet dataset poses a worthwhile challenge for the research community to close the gap between human recognition and ML approaches. It is interesting to see that Mask R-CNN and Faster R-CNN produce very comparable mAP scores, indicating that pixel-based image segmentation derived from bounding-boxes does not help to obtain better predictions. On the other hand, the more recent Yolov5x model does very well and even out-performs humans on selected labels such as Text , Table and Picture . This is not entirely surprising, as Text , Table and Picture are abundant and the most visually distinctive in a document.\\n\\nmak enbrel\\n\\nFigure 3: Page 6 of the DocLayNet paper. If recognized, metadata such as authors are appearing first under the title. Elements recognized as page headers or footers are suppressed in Markdown to deliver uninterrupted content in reading order. Tables are inserted in reading order. The paragraph in \\'5. Experiments\\' wrapping over the column end is broken up in two and interrupted by the table.\\n\\nThird, achienec\\n\\n## EXPERIMENTS\\n\\nchalenongayouls ground-vuth dawa such WC\\n\\ncoioct dcochon modols\\n\\n## Baselines for Object Detection\\n\\nKDD \\'22, August 14-18, 2022, Washington, DC, USA\\n\\nBirgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, and Peter Staar\\n\\nTable 1: DocLayNet dataset overview. Along with the frequency of each class label, we present the relative occurrence (as %\\n\\n<!-- image -->\\n\\nof row \\'Total\\') in the train, test and validation sets. The inter-annotator agreement is computed as the mAP@0.5-0.95 metric we distributed the annotation workload and performed continuous\\n\\nonly. For phases three and four, a group of 40 dedicated annotators quality controls. Phase one and two required a small team of experts\\n\\nwere assembled and supervised.\\n\\nwhile coverage ensures that all meaningful items on a page can to a document category, such as\\n\\nbe annotated. We refrained from class labels that are very specific\\n\\nAbstract in the\\n\\nScientific Articles semantics of the text. Labels such as\\n\\ncategory. We also avoided class labels that are tightly linked to the\\n\\nAuthor\\n\\nAffiliation\\n\\nteria for documents were described in Section 3. A large effort went into ensuring that all documents are free to use. The data sources in DocBank, are often only distinguishable by discriminating on 3 https://arxiv.org/ Figure 4: Table 1 from the DocLayNet paper in the original PDF (A), as rendered Markdown (B) and in JSON representation (C). Spanning table cells, such as the multi-column header \\'triple interannotator mAP@0.5-0.95 (%)\\', is repeated for each column in the Markdown representation (B), which guarantees that every data point can be traced back to row and column headings only by its grid coordinates in the table. In the JSON representation, the span information is reflected in the fields of each table cell (C).\\n\\nand\\n\\n, as seen\\n\\nPhase 1: Data selection and preparation.\\n\\nOur inclusion cri-'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 VLM Pipeline (Vision-Language Models)\n",
    "\n",
    "For complex documents, Vision-Language Models provide end-to-end understanding.\n",
    "\n",
    "**Available VLM Models:**\n",
    "- `GRANITEDOCLING_TRANSFORMERS` - IBM GraniteDocling with Transformers\n",
    "- `GRANITEDOCLING_MLX` - GraniteDocling optimized for Apple Silicon\n",
    "- `SMOLDOCLING_TRANSFORMERS` - Smaller, faster model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VLM Pipeline Configuration\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "\n",
    "print(\"VLM Pipeline Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Option 1: GraniteDocling with Transformers (cross-platform)\n",
    "print(\"\\n1. GraniteDocling with Transformers (GPU/CPU):\")\n",
    "print(\"-\" * 40)\n",
    "print(\"\"\"pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=vlm_model_specs.GRANITEDOCLING_TRANSFORMERS,\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\"\"\")\n",
    "\n",
    "# Option 2: GraniteDocling MLX (Apple Silicon optimized)\n",
    "print(\"\\n2. GraniteDocling MLX (Apple Silicon M1/M2/M3/M4):\")\n",
    "print(\"-\" * 40)\n",
    "print(\"\"\"pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=vlm_model_specs.GRANITEDOCLING_MLX,\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. GraniteDocling MLX (Apple Silicon M1/M2/M3/M4):\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 13:15:23,664 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-04 13:15:23,716 - INFO - Going to convert document batch...\n",
      "2025-12-04 13:15:23,717 - INFO - Initializing pipeline for VlmPipeline with options hash e58bc69b0ac7e3ef286a71274276cf73\n",
      "2025-12-04 13:15:24,047 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2025-12-04 13:15:24,048 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-04 13:15:24,048 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-12-04 13:15:54,456 - INFO - Processing document 2408.09869v5.pdf\n",
      "2025-12-04 13:19:32,775 - INFO - Finished converting document 2408.09869v5.pdf in 249.58 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!-- image -->\n",
      "\n",
      "## Docling Technical Report\n",
      "\n",
      "Version 1.0\n",
      "\n",
      "Christoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\n",
      "\n",
      "AI4K Group, IBM Research Rüschlikon, Switzerland\n",
      "\n",
      "## Abstract\n",
      "\n",
      "This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.\n",
      "\n",
      "## 1 Introduction\n",
      "\n",
      "Converting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.\n",
      "\n",
      "With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissi\n"
     ]
    }
   ],
   "source": [
    "#Option 2: GraniteDocling MLX (Apple Silicon optimized)\n",
    "\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "\n",
    "print(\"\\n2. GraniteDocling MLX (Apple Silicon M1/M2/M3/M4):\")\n",
    "print(\"-\" * 40)\n",
    "pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=vlm_model_specs.GRANITEDOCLING_MLX,\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "# Convert with VLM\n",
    "pdf_url=\"https://arxiv.org/pdf/2408.09869\"\n",
    "result = converter.convert(pdf_url)\n",
    "vlm_markdown = result.document.export_to_markdown()\n",
    "print(vlm_markdown[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VLM Pipeline - Live Example (requires significant GPU/memory)\n",
    "# Uncomment to run if you have sufficient resources\n",
    "\n",
    "\"\"\"from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "\n",
    "# Configure VLM pipeline\n",
    "pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=vlm_model_specs.GRANITEDOCLING_TRANSFORMERS,\n",
    ")\n",
    "\n",
    "vlm_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert with VLM\n",
    "result = vlm_converter.convert(pdf_url)\n",
    "vlm_markdown = result.document.export_to_markdown()\n",
    "print(vlm_markdown[:2000])\n",
    "\"\"\"\n",
    "\n",
    "print(\"VLM example is commented out to avoid resource issues.\")\n",
    "print(\"Uncomment and run if you have GPU/sufficient memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. LangChain Integration\n",
    "\n",
    "Docling integrates seamlessly with LangChain through the `langchain-docling` package.\n",
    "\n",
    "### 6.1 DoclingLoader\n",
    "\n",
    "The `DoclingLoader` provides a LangChain-compatible document loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents with DoclingLoader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 12:06:29,772 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-06 12:06:29,778 - INFO - Going to convert document batch...\n",
      "2025-12-06 12:06:29,779 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e647edf348883bed75367b22fbe60347\n",
      "2025-12-06 12:06:29,780 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 12:06:33,477 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 12:06:35,156 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 12:06:35,683 - INFO - Processing document 2408.09869v5.pdf\n",
      "2025-12-06 12:06:51,090 - INFO - Finished converting document 2408.09869v5.pdf in 21.70 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 41 document chunks\n",
      "\n",
      "First document chunk:\n",
      "============================================================\n",
      "Content: Version 1.0\n",
      "Christoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\n",
      "AI4K Group, IBM Research R¨ uschlikon, Switzerland...\n",
      "\n",
      "Metadata: {'source': 'https://arxiv.org/pdf/2408.09869', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 113.643, 't': 481.532, 'r': 498.359, 'b': 439.849, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 295]}]}, {'self_ref': '#/texts/4', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 249.283, 't': 427.545, 'r': 362.717, 'b': 408.084, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 50]}]}], 'headings': ['Version 1.0'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}}\n"
     ]
    }
   ],
   "source": [
    "# DoclingLoader Basic Usage\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "pdf_url = \"https://arxiv.org/pdf/2408.09869\"\n",
    "\n",
    "# Create loader with DOC_CHUNKS export (recommended for RAG)\n",
    "loader = DoclingLoader(\n",
    "    file_path=pdf_url,\n",
    "    export_type=ExportType.DOC_CHUNKS,  # Returns chunked documents\n",
    ")\n",
    "\n",
    "print(\"Loading documents with DoclingLoader...\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"\\nLoaded {len(docs)} document chunks\")\n",
    "print(\"\\nFirst document chunk:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Content: {docs[0].page_content[:500]}...\")\n",
    "print(f\"\\nMetadata: {docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 12:09:34,465 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-06 12:09:34,470 - INFO - Going to convert document batch...\n",
      "2025-12-06 12:09:34,471 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e647edf348883bed75367b22fbe60347\n",
      "2025-12-06 12:09:34,471 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 12:09:38,220 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 12:09:39,868 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 12:09:40,432 - INFO - Processing document 2408.09869v5.pdf\n",
      "2025-12-06 12:09:55,645 - INFO - Finished converting document 2408.09869v5.pdf in 21.44 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s) as Markdown\n",
      "\n",
      "Document length: 29311 characters\n",
      "\n",
      "First 500 characters:\n",
      "## Docling Technical Report\n",
      "\n",
      "## Version 1.0\n",
      "\n",
      "Christoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\n",
      "\n",
      "AI4K Group, IBM Research R¨ uschlikon, Switzerland\n",
      "\n",
      "## Abstract\n",
      "\n",
      "This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-s\n"
     ]
    }
   ],
   "source": [
    "# DoclingLoader with MARKDOWN export\n",
    "loader_md = DoclingLoader(\n",
    "    file_path=pdf_url,\n",
    "    export_type=ExportType.MARKDOWN,  # Returns full document as Markdown\n",
    ")\n",
    "\n",
    "docs_md = loader_md.load()\n",
    "\n",
    "print(f\"Loaded {len(docs_md)} document(s) as Markdown\")\n",
    "print(f\"\\nDocument length: {len(docs_md[0].page_content)} characters\")\n",
    "print(\"\\nFirst 500 characters:\")\n",
    "print(docs_md[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 12:12:03,791 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-06 12:12:03,797 - INFO - Going to convert document batch...\n",
      "2025-12-06 12:12:03,798 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 60c8066c482b9239b869b997da3fb1da\n",
      "2025-12-06 12:12:03,798 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 12:12:05,287 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 12:12:05,832 - INFO - Processing document 2408.09869v5.pdf\n",
      "2025-12-06 12:12:12,155 - INFO - Finished converting document 2408.09869v5.pdf in 8.61 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40 chunks with custom converter\n"
     ]
    }
   ],
   "source": [
    "# DoclingLoader with custom converter\n",
    "from langchain_docling import DoclingLoader\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "# Create custom converter with specific options\n",
    "custom_pipeline = PdfPipelineOptions(\n",
    "    do_ocr=False,\n",
    "    do_table_structure=True,\n",
    ")\n",
    "\n",
    "custom_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=custom_pipeline)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Use custom converter with DoclingLoader\n",
    "loader_custom = DoclingLoader(\n",
    "    file_path=pdf_url,\n",
    "    converter=custom_converter,  # Pass custom converter\n",
    "    export_type=ExportType.DOC_CHUNKS,\n",
    ")\n",
    "\n",
    "docs_custom = loader_custom.load()\n",
    "print(f\"Loaded {len(docs_custom)} chunks with custom converter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 RAG Pipeline with LangChain\n",
    "\n",
    "Build a complete RAG pipeline using Docling, LangChain, and Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key found. Proceeding with RAG setup...\n"
     ]
    }
   ],
   "source": [
    "# Complete RAG Pipeline Setup\n",
    "import os\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "\n",
    "# Check for OpenAI API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Warning: OPENAI_API_KEY not set. RAG example will not work.\")\n",
    "    print(\"Set your API key: os.environ['OPENAI_API_KEY'] = 'your-key'\")\n",
    "else:\n",
    "    print(\"OpenAI API key found. Proceeding with RAG setup...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 12:14:05,621 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-06 12:14:05,626 - INFO - Going to convert document batch...\n",
      "2025-12-06 12:14:05,627 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e647edf348883bed75367b22fbe60347\n",
      "2025-12-06 12:14:05,628 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 12:14:09,487 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 12:14:11,039 - INFO - Accelerator device: 'mps'\n",
      "2025-12-06 12:14:11,546 - INFO - Processing document 2408.09869v5.pdf\n",
      "2025-12-06 12:14:28,580 - INFO - Finished converting document 2408.09869v5.pdf in 23.24 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 41 document chunks\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and chunk documents\n",
    "\n",
    "pdf_url = \"https://arxiv.org/pdf/2408.09869\"\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Step 1: Loading documents...\")\n",
    "    \n",
    "    loader = DoclingLoader(\n",
    "        file_path=pdf_url,\n",
    "        export_type=ExportType.DOC_CHUNKS,\n",
    "    )\n",
    "    \n",
    "    documents = loader.load()\n",
    "    print(f\"Loaded {len(documents)} document chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Creating embeddings and vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 12:15:45,710 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-12-06 12:15:47,632 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 41 documents\n",
      "Persisted to: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create embeddings and vector store\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Step 2: Creating embeddings and vector store...\")\n",
    "    \n",
    "    # Initialize embeddings\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    # Filter complex metadata from documents\n",
    "    filtered_documents = filter_complex_metadata(documents)\n",
    "    \n",
    "    # Create Chroma vector store\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=filtered_documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=\"./chroma_db\",  # Persist to disk\n",
    "        collection_name=\"docling_demo\",\n",
    "    )\n",
    "    \n",
    "    print(f\"Vector store created with {len(documents)} documents\")\n",
    "    print(f\"Persisted to: ./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Creating RAG chain...\n",
      "RAG chain created successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Step 3: Create RAG chain\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Step 3: Creating RAG chain...\")\n",
    "    \n",
    "    # Initialize LLM\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "          # Create prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "          (\"system\", \"Answer the question based only on the following context:\\n\\n{context}\"),\n",
    "          (\"human\", \"{input}\")\n",
    "      ])\n",
    "    \n",
    "    # Create retriever\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5},  # Return top 5 relevant chunks\n",
    "    )\n",
    "    \n",
    "    # Create QA chain\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "    \n",
    "    print(\"RAG chain created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 12:16:59,201 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-06 12:17:02,734 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is this document about?',\n",
       " 'context': [Document(id='c3670689-c337-484c-8c27-c8528b6926f4', metadata={'source': 'https://arxiv.org/pdf/2408.09869'}, page_content='References\\n- [3] C. Auer, M. Dolfi, A. Carvalho, C. B. Ramis, and P. W. Staar. Delivering document conversion as a cloud service with high throughput and responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) , pages 363-373. IEEE, 2022.\\n- [4] J. Berkenbilt. Qpdf: A content-preserving pdf document transformer, 2024. URL https: //github.com/qpdf/qpdf .\\n- [5] O. R. developers. Onnx runtime. https://onnxruntime.ai/ , 2024. Version: 1.18.1.\\n- [6] IBM. Data Prep Kit: a community project to democratize and accelerate unstructured data preparation for LLM app developers, 2024. URL https://github.com/IBM/ data-prep-kit .\\n- [7] A. S. Inc. PyMuPDF, 2024. URL https://github.com/pymupdf/PyMuPDF .'),\n",
       "  Document(id='b0c19398-9e1a-49b7-8bcc-cbe90d0d95a9', metadata={'source': 'https://arxiv.org/pdf/2408.09869'}, page_content='References\\n- [3] C. Auer, M. Dolfi, A. Carvalho, C. B. Ramis, and P. W. Staar. Delivering document conversion as a cloud service with high throughput and responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) , pages 363-373. IEEE, 2022.\\n- [4] J. Berkenbilt. Qpdf: A content-preserving pdf document transformer, 2024. URL https: //github.com/qpdf/qpdf .\\n- [5] O. R. developers. Onnx runtime. https://onnxruntime.ai/ , 2024. Version: 1.18.1.\\n- [6] IBM. Data Prep Kit: a community project to democratize and accelerate unstructured data preparation for LLM app developers, 2024. URL https://github.com/IBM/ data-prep-kit .\\n- [7] A. S. Inc. PyMuPDF, 2024. URL https://github.com/pymupdf/PyMuPDF .'),\n",
       "  Document(id='d04412bf-e103-42ce-beb0-2d67f566c95a', metadata={'source': 'https://arxiv.org/pdf/2408.09869'}, page_content='Abstract\\nThis technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.'),\n",
       "  Document(id='2bbe4a29-355a-415b-b5fe-e357bd211e66', metadata={'source': 'https://arxiv.org/pdf/2408.09869'}, page_content='Abstract\\nThis technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.'),\n",
       "  Document(id='03c410f1-fb66-4b8f-8dac-861a02e75a07', metadata={'source': 'https://arxiv.org/pdf/2408.09869'}, page_content=\"Appendix\\nIn this section, we illustrate a few examples of Docling's output in Markdown and JSON.\\n1 INTRODUCTION\\nDespite the substantial improvements achieved with machine-learning (ML) approaches and deep neural networks in recent years, document conversion remains a challenging problem, as demonstrated by the numerous public competitions held on this topic [1-4]. The challenge originates from the huge variability in PDF documents regarding layout, language and formats (scanned, programmatic or a combination of both). Engineering a single ML model that can be applied on all types of documents and provides high-quality layout segmentation remains to this day extremely challenging [5]. To highlight the variability in document layouts, we show a few example documents from the DocLayNet dataset in Figure 1. Figure 2: Title page of the DocLayNet paper (arxiv.org/pdf/2206.01062) - left PDF, right rendered Markdown. If recognized, metadata such as authors are appearing first under the title. Text content inside figures is currently dropped, the caption is retained and linked to the figure in the JSON representation (not shown).\")],\n",
       " 'answer': \"This document is a technical report introducing Docling, an open-source package for PDF document conversion. It highlights the challenges of document conversion due to the variability in PDF layouts, languages, and formats. Docling utilizes advanced AI models for layout analysis and table structure recognition, and it is designed to run efficiently on standard hardware. The report also discusses the extensibility of the code interface for adding new features and models. Additionally, it includes examples of Docling's output in Markdown and JSON formats.\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = qa_chain.invoke({\"input\": \"What is this document about?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Querying the RAG system...\n",
      "============================================================\n",
      "\n",
      "Q: What is Docling and what are its main features?\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 12:31:15,874 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-06 12:31:24,504 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Docling is an easy-to-use, self-contained, MIT-licensed open-source package for PDF document conversion. It is powered by advanced AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), allowing it to efficiently convert documents while maintaining high-quality, richly structured output. \n",
      "\n",
      "Main features of Docling include:\n",
      "\n",
      "1. **High-Quality Document Conversion**: It provides detailed and structured document conversion suitable for various applications.\n",
      "2. **Support for Downstream Applications**: Its output can be used for enterprise document search, passage retrieval, classification, and knowledge extraction pipelines.\n",
      "3. **Table Structure Recognition**: It has powerful capabilities for recognizing table structures, which aids in automated knowledge-base construction.\n",
      "4. **Integration with Generative AI**: Docling supports generative AI application patterns, such as retrieval-augmented generation (RAG), through the open-source package quackling, which optimizes vector embedding and chunking.\n",
      "5. **Scalability and Cost-Effectiveness**: It is fast, stable, and inexpensive to run, making it suitable for building document-derived datasets.\n",
      "6. **OCR Support**: Docling offers optional support for Optical Character Recognition (OCR) to handle scanned PDFs and bitmap images, utilizing the EasyOCR library.\n",
      "7. **Extensibility**: The code interface allows for easy addition of new features and models, promoting collaboration and enhancement from the open-source community. \n",
      "\n",
      "Overall, Docling is designed to run efficiently on commodity hardware and is suitable for a variety of document processing tasks.\n",
      "\n",
      "Q: What file formats does Docling support?\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 12:31:24,958 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-06 12:31:26,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Docling supports converting PDF documents. The output can be retrieved in either JSON or Markdown format.\n",
      "\n",
      "Q: How does Docling handle table extraction?\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 12:31:27,469 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-06 12:31:34,385 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Docling handles table extraction using the TableFormer model, which is a vision-transformer model designed for table structure recovery. The process involves the following steps:\n",
      "\n",
      "1. **Layout Analysis**: The Docling pipeline first performs layout analysis to detect all table objects within the document.\n",
      "\n",
      "2. **Image Cropping**: For each detected table, an image crop of the table along with the included text cells is provided to the TableFormer model.\n",
      "\n",
      "3. **Structure Prediction**: The TableFormer model predicts the logical row and column structure of the table, identifying which cells belong to column headers, row headers, or the table body. It can handle various complexities of tables, such as partial or no borderlines, empty cells, cell spans, and inconsistent indentation or alignment.\n",
      "\n",
      "4. **Post-Processing**: After the structure predictions are made, they are matched back to the original PDF cells in a post-processing step to avoid the need for expensive re-transcription of text in the table image.\n",
      "\n",
      "The typical processing time for tables is between 2 and 6 seconds on a standard CPU, depending on the number of included table cells.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Query the RAG system\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Step 4: Querying the RAG system...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example questions about Docling\n",
    "    questions = [\n",
    "        \"What is Docling and what are its main features?\",\n",
    "        \"What file formats does Docling support?\",\n",
    "        \"How does Docling handle table extraction?\",\n",
    "    ]\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"\\nQ: {question}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        response = qa_chain.invoke({\"input\": question})\n",
    "        \n",
    "        #print(f\"A: {response['input']}\")\n",
    "        #print(f\"\\n(Based on {len(response['source_documents'])} source documents)\")\n",
    "        print(\"=\" * 60)\n",
    "        print(response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Export & Serialization\n",
    "\n",
    "### 7.1 Export Methods\n",
    "\n",
    "Docling provides multiple export methods for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive export examples\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(pdf_url)\n",
    "doc = result.document\n",
    "\n",
    "# 1. Export to Markdown\n",
    "markdown = doc.export_to_markdown()\n",
    "print(f\"Markdown export: {len(markdown)} characters\")\n",
    "\n",
    "# 2. Export to Text (plain text, no formatting)\n",
    "text = doc.export_to_markdown(strict_text=True)\n",
    "print(f\"Text export: {len(text)} characters\")\n",
    "\n",
    "# 3. Export to Dictionary\n",
    "doc_dict = doc.export_to_dict()\n",
    "print(f\"Dict export: {len(doc_dict.keys())} top-level keys\")\n",
    "\n",
    "# 4. Save as JSON\n",
    "json_path = OUTPUT_DIR / \"export_demo.json\"\n",
    "doc.save_as_json(json_path)\n",
    "print(f\"JSON saved: {json_path}\")\n",
    "\n",
    "# 5. Save as HTML\n",
    "html_path = OUTPUT_DIR / \"export_demo.html\"\n",
    "doc.save_as_html(html_path)\n",
    "print(f\"HTML saved: {html_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Table Export\n",
    "\n",
    "Export tables to pandas DataFrames or CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table export to DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Access tables from the document\n",
    "if hasattr(doc, 'tables') and doc.tables:\n",
    "    print(f\"Found {len(doc.tables)} tables\\n\")\n",
    "    \n",
    "    for i, table in enumerate(doc.tables[:3]):  # First 3 tables\n",
    "        print(f\"Table {i+1}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Export to DataFrame\n",
    "            df = table.export_to_dataframe()\n",
    "            print(df.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            csv_path = OUTPUT_DIR / f\"table_{i+1}.csv\"\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\"Saved to: {csv_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error exporting table: {e}\")\n",
    "        \n",
    "        print()\n",
    "else:\n",
    "    print(\"No tables found in the document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Advanced Topics\n",
    "\n",
    "### 8.1 Batch Processing\n",
    "\n",
    "Process multiple documents efficiently with `convert_all()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing example\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.base_models import ConversionStatus\n",
    "from pathlib import Path\n",
    "\n",
    "# Define sources (can be paths, URLs, or streams)\n",
    "sources = [\n",
    "    str(SAMPLE_DIR / \"sample.html\"),\n",
    "    str(SAMPLE_DIR / \"sample.md\"),\n",
    "]\n",
    "\n",
    "# Filter to existing files only\n",
    "existing_sources = [s for s in sources if Path(s).exists()]\n",
    "\n",
    "if existing_sources:\n",
    "    converter = DocumentConverter()\n",
    "    \n",
    "    # Batch convert with error handling\n",
    "    results = {\n",
    "        \"success\": [],\n",
    "        \"partial\": [],\n",
    "        \"failed\": [],\n",
    "    }\n",
    "    \n",
    "    print(f\"Processing {len(existing_sources)} documents...\")\n",
    "    \n",
    "    for result in converter.convert_all(existing_sources, raises_on_error=False):\n",
    "        if result.status == ConversionStatus.SUCCESS:\n",
    "            results[\"success\"].append(result)\n",
    "            print(f\"  SUCCESS: {result.input.file.name}\")\n",
    "        elif result.status == ConversionStatus.PARTIAL_SUCCESS:\n",
    "            results[\"partial\"].append(result)\n",
    "            print(f\"  PARTIAL: {result.input.file.name}\")\n",
    "        else:\n",
    "            results[\"failed\"].append(result)\n",
    "            print(f\"  FAILED: {result.input.file.name}\")\n",
    "    \n",
    "    print(f\"\\nSummary: {len(results['success'])} success, \"\n",
    "          f\"{len(results['partial'])} partial, \"\n",
    "          f\"{len(results['failed'])} failed\")\n",
    "else:\n",
    "    print(\"No sample files found for batch processing demo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Document Enrichment\n",
    "\n",
    "Enable enrichment features like picture classification and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document enrichment configuration\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "# Enable enrichment features\n",
    "enrichment_options = PdfPipelineOptions(\n",
    "    do_table_structure=True,\n",
    "    do_picture_classification=True,   # Classify pictures (chart, diagram, etc.)\n",
    "    do_picture_description=False,     # Disable VLM description (resource intensive)\n",
    "    generate_picture_images=True,     # Save picture images\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=enrichment_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Enrichment features configured:\")\n",
    "print(f\"  - Picture classification: {enrichment_options.do_picture_classification}\")\n",
    "print(f\"  - Picture description: {enrichment_options.do_picture_description}\")\n",
    "print(f\"  - Generate picture images: {enrichment_options.generate_picture_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Error Handling\n",
    "\n",
    "Handle conversion errors gracefully with status checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error handling patterns\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.base_models import ConversionStatus\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "def safe_convert(source):\n",
    "    \"\"\"Safely convert a document with proper error handling.\"\"\"\n",
    "    try:\n",
    "        result = converter.convert(source, raises_on_error=False)\n",
    "        \n",
    "        if result.status == ConversionStatus.SUCCESS:\n",
    "            print(f\"Conversion successful: {result.input.file.name}\")\n",
    "            return result.document\n",
    "        \n",
    "        elif result.status == ConversionStatus.PARTIAL_SUCCESS:\n",
    "            print(f\"Partial success: {result.input.file.name}\")\n",
    "            print(f\"  Errors: {len(result.errors)}\")\n",
    "            for error in result.errors:\n",
    "                print(f\"    - {error.component_type}: {error.error_message}\")\n",
    "            return result.document  # Still usable\n",
    "        \n",
    "        else:\n",
    "            print(f\"Conversion failed: {result.input.file.name}\")\n",
    "            for error in result.errors:\n",
    "                print(f\"  - {error.component_type}: {error.error_message}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "doc = safe_convert(pdf_url)\n",
    "if doc:\n",
    "    print(f\"\\nDocument ready with {len(doc.export_to_markdown())} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "1. **Installation & Setup** - Installing Docling 2.55.1 with all dependencies\n",
    "2. **Basic Conversion** - Converting documents to Markdown, JSON, HTML\n",
    "3. **File Formats** - PDF, Office (DOCX, XLSX, PPTX), HTML, Markdown, Images, Audio\n",
    "4. **Pipeline Options** - OCR engines, table extraction, layout analysis, VLM\n",
    "5. **Chunking** - HybridChunker and HierarchicalChunker for RAG\n",
    "6. **LangChain Integration** - DoclingLoader and RAG pipeline\n",
    "7. **Export Methods** - Multiple output formats and table export\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Docling** provides unified document parsing across multiple formats\n",
    "- **DocumentConverter** is the main entry point for all conversions\n",
    "- **Pipeline options** allow fine-tuned control over processing\n",
    "- **Native chunking** is optimized for RAG applications\n",
    "- **LangChain integration** enables seamless RAG pipeline creation\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Docling Documentation](https://docling-project.github.io/docling/)\n",
    "- [Docling GitHub](https://github.com/docling-project/docling)\n",
    "- [LangChain Docling Integration](https://docs.langchain.com/oss/python/integrations/document_loaders/docling)\n",
    "- [Docling Examples](https://docling-project.github.io/docling/examples/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup (optional)\n",
    "import shutil\n",
    "\n",
    "# Uncomment to clean up generated files\n",
    "# if OUTPUT_DIR.exists():\n",
    "#     shutil.rmtree(OUTPUT_DIR)\n",
    "# if Path(\"./chroma_db\").exists():\n",
    "#     shutil.rmtree(\"./chroma_db\")\n",
    "# if Path(\"./chroma_rag_demo\").exists():\n",
    "#     shutil.rmtree(\"./chroma_rag_demo\")\n",
    "\n",
    "print(\"Notebook completed successfully!\")\n",
    "print(f\"Output files saved to: {OUTPUT_DIR.absolute()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
