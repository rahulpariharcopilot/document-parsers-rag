{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Parsing with LlamaParse for RAG Systems\n",
    "\n",
    "## Core Features & Parsing Fundamentals\n",
    "\n",
    "This comprehensive notebook demonstrates **LlamaParse (v0.6.77)** - a GenAI-native document parser designed for converting complex documents into LLM-ready data for Retrieval-Augmented Generation (RAG) systems.\n",
    "\n",
    "### What is LlamaParse?\n",
    "\n",
    "LlamaParse is a document parsing service by LlamaIndex that excels at:\n",
    "- **Complex Document Handling**: Financial reports, research papers, scanned PDFs\n",
    "- **Precise Extraction**: Tables, charts, images, and diagrams\n",
    "- **70+ File Formats**: PDF, DOCX, XLSX, PPTX, HTML, images, audio, and more\n",
    "- **LLM-Ready Output**: Clean markdown, text, or structured JSON\n",
    "\n",
    "### Pricing\n",
    "- **Free Tier**: 1,000 pages daily\n",
    "- **Paid Tier**: 7,000 pages/week + $0.003/additional page\n",
    "\n",
    "### Part 1 Contents\n",
    "1. Introduction & Setup\n",
    "2. Core Concepts\n",
    "3. Basic Document Parsing\n",
    "4. Presets & Built-in Configurations\n",
    "5. Parse Modes (Fast, Premium, Auto)\n",
    "6. Supported File Formats\n",
    "7. Multimodal Parsing Features\n",
    "8. Layout Extraction\n",
    "9. Structured Output\n",
    "\n",
    "**Part 2** covers: Custom Prompts, Advanced Configuration, Async Operations, LlamaIndex Integration, RAG Examples, CLI Usage, and Best Practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Introduction & Setup\n",
    "\n",
    "### 1.1 Installation\n",
    "\n",
    "Install the required packages for LlamaParse and RAG functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install LlamaParse and related packages\n",
    "# llama-parse: The core document parsing library (v0.6.77)\n",
    "# llama-index: Framework for building RAG applications\n",
    "# llama-cloud-services: Cloud service integrations\n",
    "\n",
    "!pip install llama-parse==0.6.77 llama-index llama-cloud-services -q\n",
    "\n",
    "# Additional dependencies for RAG and embeddings\n",
    "!pip install chromadb python-dotenv openai -q\n",
    "\n",
    "# Optional: Install llama-index components for vector stores\n",
    "!pip install llama-index-vector-stores-chroma llama-index-embeddings-openai -q\n",
    "\n",
    "print(\"Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 API Key Setup\n",
    "\n",
    "LlamaParse requires an API key from [LlamaCloud](https://cloud.llamaindex.ai/api-key).\n",
    "\n",
    "**Steps to get your API key:**\n",
    "1. Go to https://cloud.llamaindex.ai/\n",
    "2. Sign up or log in\n",
    "3. Navigate to API Keys section\n",
    "4. Create a new API key (starts with `llx-`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaCloud API key loaded: llx-ozAips...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set up API keys\n",
    "# Option 1: Set directly (not recommended for production)\n",
    "# os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-your-api-key-here\"\n",
    "\n",
    "# Option 2: Load from environment variable (recommended)\n",
    "# Make sure to add LLAMA_CLOUD_API_KEY to your .env file\n",
    "\n",
    "# OpenAI API key for embeddings (optional, for RAG examples)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "\n",
    "# Verify API key is set\n",
    "llama_api_key = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "if llama_api_key:\n",
    "    print(f\"LlamaCloud API key loaded: {llama_api_key[:10]}...\")\n",
    "else:\n",
    "    print(\"Warning: LLAMA_CLOUD_API_KEY not found in environment variables\")\n",
    "    print(\"Please set it before running parsing examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n",
      "0.6.54\n"
     ]
    }
   ],
   "source": [
    "# Core LlamaParse imports\n",
    "#from llama_parse import LlamaParse\n",
    "\n",
    "# Alternative import from llama_cloud_services (same functionality)\n",
    "from llama_cloud_services import LlamaParse\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# For async operations in Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "from importlib.metadata import version\n",
    "\n",
    "print(version(\"llama-parse\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Setup Sample Documents Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sample documents:\n",
      "  - sample_text_image.png (10.9 KB)\n",
      "  - sample.md (3.0 KB)\n",
      "  - sample1.docx (36.1 KB)\n",
      "  - .DS_Store (6.0 KB)\n",
      "  - sample.html (3.8 KB)\n",
      "  - sample.xlsx (14.9 KB)\n",
      "  - sample.mp3 (7745.0 KB)\n",
      "  - docling_paper.pdf (5436.1 KB)\n",
      "  - sample1.pptx (28.5 KB)\n",
      "  - sample.pptx (13921.4 KB)\n",
      "  - sample1.xlsx (4.9 KB)\n",
      "  - scanned.pdf (236.5 KB)\n",
      "  - dl.pptx (648.0 KB)\n",
      "  - sample.docx (11.9 KB)\n",
      "  - vdb.png (5649.7 KB)\n",
      "  - scan.pdf (1903.9 KB)\n"
     ]
    }
   ],
   "source": [
    "# Define paths for sample documents\n",
    "SAMPLE_DIR = Path(\"./sample_documents\")\n",
    "OUTPUT_DIR = Path(\"./llamaparse_output\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# List available sample documents\n",
    "if SAMPLE_DIR.exists():\n",
    "    print(\"Available sample documents:\")\n",
    "    for file in SAMPLE_DIR.iterdir():\n",
    "        if file.is_file():\n",
    "            print(f\"  - {file.name} ({file.stat().st_size / 1024:.1f} KB)\")\n",
    "else:\n",
    "    print(f\"Sample directory not found: {SAMPLE_DIR}\")\n",
    "    print(\"Creating sample directory...\")\n",
    "    SAMPLE_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Download a Sample PDF for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sample PDF from arXiv...\n",
      "Downloaded: sample_documents/attention_paper.pdf\n",
      "File size: 2163.3 KB\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Download a sample PDF (attention paper from arXiv)\n",
    "sample_pdf_url = \"https://arxiv.org/pdf/1706.03762.pdf\"  # \"Attention Is All You Need\" paper\n",
    "sample_pdf_path = SAMPLE_DIR / \"attention_paper.pdf\"\n",
    "\n",
    "if not sample_pdf_path.exists():\n",
    "    print(f\"Downloading sample PDF from arXiv...\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(sample_pdf_url, sample_pdf_path)\n",
    "        print(f\"Downloaded: {sample_pdf_path}\")\n",
    "        print(f\"File size: {sample_pdf_path.stat().st_size / 1024:.1f} KB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Download failed: {e}\")\n",
    "        print(\"You can manually download a PDF for testing\")\n",
    "else:\n",
    "    print(f\"Sample PDF already exists: {sample_pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Core Concepts\n",
    "\n",
    "### 2.1 Understanding the LlamaParse Architecture\n",
    "\n",
    "LlamaParse uses a **job-based architecture**:\n",
    "\n",
    "```\n",
    "Document → Submit Job → Poll Status → Get Results\n",
    "```\n",
    "\n",
    "**Key Components:**\n",
    "- **LlamaParse Client**: Main interface for document parsing\n",
    "- **Job**: Represents a parsing task (can be async)\n",
    "- **JobResult**: Contains parsed content, pages, images, charts, layout\n",
    "- **Document**: LlamaIndex Document object with text and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaParse Configuration Parameters:\n",
      "==================================================\n",
      "\n",
      "Authentication:\n",
      "  - api_key\n",
      "  - base_url\n",
      "\n",
      "Output Control:\n",
      "  - result_type\n",
      "  - language\n",
      "  - split_by_page\n",
      "\n",
      "Mode Selection:\n",
      "  - fast_mode\n",
      "  - premium_mode\n",
      "  - auto_mode\n",
      "  - preset\n",
      "\n",
      "OCR & Images:\n",
      "  - disable_ocr\n",
      "  - high_res_ocr\n",
      "  - extract_charts\n",
      "  - take_screenshot\n",
      "\n",
      "Layout:\n",
      "  - extract_layout\n",
      "  - do_not_unroll_columns\n",
      "\n",
      "Structured Output:\n",
      "  - structured_output\n",
      "  - structured_output_json_schema\n",
      "\n",
      "Prompts:\n",
      "  - parsing_instruction\n",
      "  - system_prompt\n",
      "  - formatting_instruction\n",
      "\n",
      "Performance:\n",
      "  - num_workers\n",
      "  - job_timeout_in_seconds\n",
      "  - verbose\n"
     ]
    }
   ],
   "source": [
    "# Understanding the LlamaParse client structure\n",
    "\n",
    "# The LlamaParse class is the main entry point\n",
    "# It can be instantiated with various configuration options\n",
    "\n",
    "# Basic instantiation\n",
    "parser_basic = LlamaParse(\n",
    "    result_type=\"markdown\"  # Output format: \"markdown\" or \"text\"\n",
    ")\n",
    "\n",
    "# View available configuration parameters\n",
    "print(\"LlamaParse Configuration Parameters:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Key parameters categorized\n",
    "config_categories = {\n",
    "    \"Authentication\": [\"api_key\", \"base_url\"],\n",
    "    \"Output Control\": [\"result_type\", \"language\", \"split_by_page\"],\n",
    "    \"Mode Selection\": [\"fast_mode\", \"premium_mode\", \"auto_mode\", \"preset\"],\n",
    "    \"OCR & Images\": [\"disable_ocr\", \"high_res_ocr\", \"extract_charts\", \"take_screenshot\"],\n",
    "    \"Layout\": [\"extract_layout\", \"do_not_unroll_columns\"],\n",
    "    \"Structured Output\": [\"structured_output\", \"structured_output_json_schema\"],\n",
    "    \"Prompts\": [\"parsing_instruction\", \"system_prompt\", \"formatting_instruction\"],\n",
    "    \"Performance\": [\"num_workers\", \"job_timeout_in_seconds\", \"verbose\"],\n",
    "}\n",
    "\n",
    "for category, params in config_categories.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for param in params:\n",
    "        print(f\"  - {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Result Types: Text vs Markdown\n",
    "\n",
    "LlamaParse supports two primary output formats:\n",
    "\n",
    "| Format | Best For | Features |\n",
    "|--------|----------|----------|\n",
    "| `markdown` | RAG, LLM input | Preserves structure, tables, formatting |\n",
    "| `text` | Simple extraction | Plain text, no formatting |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown Parser Configuration:\n",
      "  Result Type: ResultType.MD\n",
      "\n",
      "Text Parser Configuration:\n",
      "  Result Type: ResultType.TXT\n"
     ]
    }
   ],
   "source": [
    "# Comparing result types\n",
    "\n",
    "# Markdown parser - preserves structure and formatting\n",
    "parser_markdown = LlamaParse(\n",
    "    result_type=\"markdown\",  # Returns formatted markdown\n",
    "    verbose=True  # Show progress\n",
    ")\n",
    "\n",
    "# Text parser - plain text extraction\n",
    "parser_text = LlamaParse(\n",
    "    result_type=\"text\",  # Returns plain text\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Markdown Parser Configuration:\")\n",
    "print(f\"  Result Type: {parser_markdown.result_type}\")\n",
    "\n",
    "print(\"\\nText Parser Configuration:\")\n",
    "print(f\"  Result Type: {parser_text.result_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 JobResult Structure\n",
    "\n",
    "When parsing a document, LlamaParse returns a `JobResult` object with the following attributes:\n",
    "\n",
    "```python\n",
    "JobResult:\n",
    "├── pages: List[Page]         # Individual page data\n",
    "│   ├── text: str             # Plain text content\n",
    "│   ├── md: str               # Markdown content\n",
    "│   ├── images: List          # Extracted images\n",
    "│   ├── charts: List          # Extracted charts\n",
    "│   ├── layout: Dict          # Layout information\n",
    "│   └── structuredData: Dict  # Structured data (if enabled)\n",
    "├── text: str                 # Full document text\n",
    "├── md: str                   # Full document markdown\n",
    "└── images: List              # All extracted images\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobResult Access Methods:\n",
      "============================================================\n",
      "\n",
      "get_markdown_documents(split_by_page)\n",
      "  → Get LlamaIndex Documents with markdown content\n",
      "\n",
      "get_text_documents(split_by_page)\n",
      "  → Get LlamaIndex Documents with text content\n",
      "\n",
      "get_image_documents()\n",
      "  → Get extracted images as documents\n",
      "\n",
      "aget_image_documents()\n",
      "  → Async version with download capabilities\n",
      "\n",
      "get_json()\n",
      "  → Get structured JSON output\n",
      "\n",
      ".pages\n",
      "  → Direct access to page-by-page data\n",
      "\n",
      ".text\n",
      "  → Full document as plain text\n",
      "\n",
      ".md\n",
      "  → Full document as markdown\n"
     ]
    }
   ],
   "source": [
    "# Understanding JobResult structure (conceptual)\n",
    "\n",
    "# The JobResult provides multiple ways to access parsed content:\n",
    "\n",
    "job_result_methods = {\n",
    "    \"get_markdown_documents(split_by_page)\": \"Get LlamaIndex Documents with markdown content\",\n",
    "    \"get_text_documents(split_by_page)\": \"Get LlamaIndex Documents with text content\",\n",
    "    \"get_image_documents()\": \"Get extracted images as documents\",\n",
    "    \"aget_image_documents()\": \"Async version with download capabilities\",\n",
    "    \"get_json()\": \"Get structured JSON output\",\n",
    "    \".pages\": \"Direct access to page-by-page data\",\n",
    "    \".text\": \"Full document as plain text\",\n",
    "    \".md\": \"Full document as markdown\",\n",
    "}\n",
    "\n",
    "print(\"JobResult Access Methods:\")\n",
    "print(\"=\"*60)\n",
    "for method, description in job_result_methods.items():\n",
    "    print(f\"\\n{method}\")\n",
    "    print(f\"  → {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Sync vs Async Methods\n",
    "\n",
    "LlamaParse provides both synchronous and asynchronous methods:\n",
    "\n",
    "| Sync Method | Async Method | Description |\n",
    "|------------|--------------|-------------|\n",
    "| `load_data()` | `aload_data()` | Parse and return Documents |\n",
    "| `parse()` | `aparse()` | Parse and return JobResult |\n",
    "| `get_images()` | `aget_images()` | Get extracted images |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sync and Async patterns defined.\n",
      "\n",
      "Sync: Use load_data(), parse() for simple scripts\n",
      "Async: Use aload_data(), aparse() for concurrent processing\n"
     ]
    }
   ],
   "source": [
    "# Sync vs Async usage patterns\n",
    "\n",
    "# Synchronous usage (blocking)\n",
    "def sync_parse_example(file_path: str):\n",
    "    \"\"\"\n",
    "    Synchronous parsing - blocks until complete.\n",
    "    Best for: Simple scripts, single document parsing\n",
    "    \"\"\"\n",
    "    parser = LlamaParse(result_type=\"markdown\")\n",
    "    documents = parser.load_data(file_path)\n",
    "    return documents\n",
    "\n",
    "# Asynchronous usage (non-blocking)\n",
    "async def async_parse_example(file_path: str):\n",
    "    \"\"\"\n",
    "    Asynchronous parsing - allows concurrent operations.\n",
    "    Best for: Multiple documents, web applications, batch processing\n",
    "    \"\"\"\n",
    "    parser = LlamaParse(result_type=\"markdown\")\n",
    "    documents = await parser.aload_data(file_path)\n",
    "    return documents\n",
    "\n",
    "print(\"Sync and Async patterns defined.\")\n",
    "print(\"\\nSync: Use load_data(), parse() for simple scripts\")\n",
    "print(\"Async: Use aload_data(), aparse() for concurrent processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Basic Document Parsing\n",
    "\n",
    "### 3.1 Simple PDF Parsing with load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: sample_documents/attention_paper.pdf\n",
      "--------------------------------------------------\n",
      "Started parsing the file under job_id cbe9d1f5-ff21-46d4-a7a7-9d076552569e\n",
      "\n",
      "Parsing complete!\n",
      "Number of documents returned: 15\n",
      "\n",
      "Document type: Document\n",
      "Content length: 2767 characters\n",
      "\n",
      "First 1000 characters:\n",
      "==================================================\n",
      "arXiv:1706.03762v7 [cs.CL] 2 Aug 2023\n",
      "\n",
      "# Attention Is All You Need\n",
      "\n",
      "Ashish Vaswani∗  Noam Shazeer∗        Niki Parmar∗  Jakob Uszkoreit∗\n",
      "\n",
      "Google Brain         Google Brain     Google Research    Google Research\n",
      "\n",
      "avaswani@google.com    noam@google.com    nikip@google.com    usz@google.com\n",
      "\n",
      "Llion Jones∗     Aidan N. Gomez∗ †         Łukasz Kaiser∗\n",
      "\n",
      "Google Research    University of Toronto          Google Brain\n",
      "\n",
      "llion@google.com    aidan@cs.toronto.edu    lukaszkaiser@google.com\n",
      "\n",
      "Illia Polosukhin∗ ‡\n",
      "\n",
      "illia.polosukhin@gmail.com\n",
      "\n",
      "# Abstract\n",
      "\n",
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these model\n"
     ]
    }
   ],
   "source": [
    "# Basic PDF parsing example\n",
    "# This is the simplest way to parse a document\n",
    "\n",
    "# Initialize parser with markdown output\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # Output as markdown (best for RAG)\n",
    "    verbose=True,            # Show parsing progress\n",
    ")\n",
    "\n",
    "# Parse the sample PDF\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(f\"Parsing: {pdf_path}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # load_data() returns a list of LlamaIndex Document objects\n",
    "    documents = parser.load_data(pdf_path)\n",
    "    \n",
    "    print(f\"\\nParsing complete!\")\n",
    "    print(f\"Number of documents returned: {len(documents)}\")\n",
    "    \n",
    "    # Preview the first document\n",
    "    if documents:\n",
    "        doc = documents[0]\n",
    "        print(f\"\\nDocument type: {type(doc).__name__}\")\n",
    "        print(f\"Content length: {len(doc.text)} characters\")\n",
    "        print(f\"\\nFirst 1000 characters:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(doc.text[:1000])\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")\n",
    "    print(\"Please run the download cell first or provide your own PDF.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Getting Text Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing with TEXT output...\n",
      "Started parsing the file under job_id eed9a919-afb7-4e6f-9119-0ccf3ca12481\n",
      "\n",
      "Text output preview (first 800 chars):\n",
      "==================================================\n",
      "    arXiv:1706.03762v7 [cs.CL] 2 Aug 2023\n",
      "\n",
      "  Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "    scholarly works.\n",
      "\n",
      "    Attention Is All You Need\n",
      "\n",
      "    Ashish Vaswani∗  Noam Shazeer∗        Niki Parmar∗  Jakob Uszkoreit∗\n",
      "    Google Brain         Google Brain     Google Research    Google Research\n",
      "avaswani@google.com    noam@google.com    nikip@google.com    usz@google.com\n",
      "\n",
      "    Llion Jones∗     Aidan N. Gomez∗ †         Łukasz Kaiser∗\n",
      "Google Research    University of Toronto          Google Brain\n",
      "llion@google.com    aidan@cs.toronto.edu    lukaszkaiser@google.com\n",
      "\n",
      "                     Illia Polosukhin∗ ‡\n",
      "                     illia.polosukhin@gmail.com\n",
      "\n",
      "                                 \n"
     ]
    }
   ],
   "source": [
    "# Parsing with plain text output\n",
    "\n",
    "parser_text = LlamaParse(\n",
    "    result_type=\"text\",  # Plain text output (no formatting)\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"Parsing with TEXT output...\")\n",
    "    documents_text = parser_text.load_data(pdf_path)\n",
    "    \n",
    "    if documents_text:\n",
    "        print(f\"\\nText output preview (first 800 chars):\")\n",
    "        print(\"=\" * 50)\n",
    "        print(documents_text[0].text[:800])\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Using parse() for More Control\n",
    "\n",
    "The `parse()` method returns a `JobResult` object which provides more granular access to parsed content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parse() method for detailed results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting job results:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 1d99d972-3c7d-493f-b360-c2f8c9685b4b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting job results: 100%|██████████| 1/1 [00:09<00:00,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JobResult type: JobResult\n",
      "Number of pages: 15\n",
      "\n",
      "Page 1 content (first 500 chars):\n",
      "==================================================\n",
      "arXiv:1706.03762v7 [cs.CL] 2 Aug 2023\n",
      "\n",
      "# Attention Is All You Need\n",
      "\n",
      "Ashish Vaswani∗  Noam Shazeer∗        Niki Parmar∗  Jakob Uszkoreit∗\n",
      "\n",
      "Google Brain         Google Brain     Google Research    Google Research\n",
      "\n",
      "avaswani@google.com    noam@google.com    nikip@google.com    usz@google.com\n",
      "\n",
      "Llion Jones∗     Aidan N. Gomez∗ †         Łukasz Kaiser∗\n",
      "\n",
      "Google Research    University of Toronto          Google Brain\n",
      "\n",
      "llion@google.com    aidan@cs.toronto.edu    lukaszkaiser@google.com\n",
      "\n",
      "Illia Polosukhin∗ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Using parse() for more detailed results\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"Using parse() method for detailed results...\")\n",
    "    \n",
    "    # parse() returns JobResult objects (one per file)\n",
    "    job_results = parser.parse([pdf_path])  # Note: takes a list of files\n",
    "    \n",
    "    if job_results:\n",
    "        result = job_results[0]\n",
    "        print(f\"\\nJobResult type: {type(result).__name__}\")\n",
    "        print(f\"Number of pages: {len(result.pages)}\")\n",
    "        \n",
    "        # Access page-by-page content\n",
    "        print(f\"\\nPage 1 content (first 500 chars):\")\n",
    "        print(\"=\" * 50)\n",
    "        if result.pages:\n",
    "            page1 = result.pages[0]\n",
    "            print(page1.md[:500] if page1.md else page1.text[:500])\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Accessing Individual Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting job results: 100%|██████████| 1/1 [00:08<00:00,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document has 15 pages\n",
      "==================================================\n",
      "\n",
      "--- Page 1 ---\n",
      "Text length: 3364 chars\n",
      "Markdown length: 2766 chars\n",
      "Images: 0\n",
      "Charts: 0\n",
      "Preview: arXiv:1706.03762v7 [cs.CL] 2 Aug 2023  # Attention Is All You Need  Ashish Vaswani∗  Noam Shazeer∗        Niki Parmar∗  Jakob Uszkoreit∗  Google Brain         Google Brain     Google Research    Googl...\n",
      "\n",
      "--- Page 2 ---\n",
      "Text length: 4310 chars\n",
      "Markdown length: 4269 chars\n",
      "Images: 0\n",
      "Charts: 0\n",
      "Preview:  # 1 Introduction  Recurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks in particular, have been firmly established as state of the art approaches in sequence...\n",
      "\n",
      "--- Page 3 ---\n",
      "Text length: 1956 chars\n",
      "Markdown length: 1854 chars\n",
      "Images: 1\n",
      "Charts: 0\n",
      "Preview:  # 2020  Figure 1: The Transformer - model architecture.  The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Accessing page-by-page content from JobResult\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    verbose=False,  # Suppress progress output\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    job_results = parser.parse([pdf_path])\n",
    "    \n",
    "    if job_results:\n",
    "        result = job_results[0]\n",
    "        \n",
    "        print(f\"Document has {len(result.pages)} pages\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Iterate through pages\n",
    "        for i, page in enumerate(result.pages[:3]):  # First 3 pages\n",
    "            print(f\"\\n--- Page {i + 1} ---\")\n",
    "            print(f\"Text length: {len(page.text) if page.text else 0} chars\")\n",
    "            print(f\"Markdown length: {len(page.md) if page.md else 0} chars\")\n",
    "            print(f\"Images: {len(page.images) if page.images else 0}\")\n",
    "            print(f\"Charts: {len(page.charts) if hasattr(page, 'charts') and page.charts else 0}\")\n",
    "            \n",
    "            # Preview content\n",
    "            content = page.md if page.md else page.text\n",
    "            if content:\n",
    "                preview = content[:200].replace('\\n', ' ')\n",
    "                print(f\"Preview: {preview}...\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Split by Page Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents (pages): 15\n",
      "==================================================\n",
      "\n",
      "Document 1 (Page 1):\n",
      "  Length: 2767 chars\n",
      "  Metadata: {}\n",
      "  Preview: arXiv:1706.03762v7 [cs.CL] 2 Aug 2023  # Attention Is All You Need  Ashish Vaswani∗  Noam Shazeer∗        Niki Parmar∗  Jakob Uszkoreit∗  Google Brain...\n",
      "\n",
      "Document 2 (Page 2):\n",
      "  Length: 4271 chars\n",
      "  Metadata: {}\n",
      "  Preview:   # 1 Introduction  Recurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks in particular, have been firmly est...\n",
      "\n",
      "Document 3 (Page 3):\n",
      "  Length: 1856 chars\n",
      "  Metadata: {}\n",
      "  Preview:   # 2020  Figure 1: The Transformer - model architecture.  The Transformer follows this overall architecture using stacked self-attention and point-wi...\n",
      "\n",
      "Document 4 (Page 4):\n",
      "  Length: 2646 chars\n",
      "  Metadata: {}\n",
      "  Preview:   # Scaled Dot-Product Attention  # Multi-Head Attention  # Linear  # MatMul  # SoftMax  # Mask (opt.)  # Scaled Dot-Product  # Attention  # MatMul  #...\n",
      "\n",
      "Document 5 (Page 5):\n",
      "  Length: 3202 chars\n",
      "  Metadata: {}\n",
      "  Preview:   output values. These are concatenated and once again projected, resulting in the final values, as depicted in Figure 2.  Multi-head attention allows...\n"
     ]
    }
   ],
   "source": [
    "# Using split_by_page to get separate documents per page\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    split_by_page=True,  # Each page becomes a separate document\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    # With split_by_page=True, load_data returns one Document per page\n",
    "    documents = parser.load_data(pdf_path)\n",
    "    \n",
    "    print(f\"Total documents (pages): {len(documents)}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Preview each page document\n",
    "    for i, doc in enumerate(documents[:5]):  # First 5 pages\n",
    "        print(f\"\\nDocument {i + 1} (Page {i + 1}):\")\n",
    "        print(f\"  Length: {len(doc.text)} chars\")\n",
    "        print(f\"  Metadata: {doc.metadata}\")\n",
    "        preview = doc.text[:150].replace('\\n', ' ')\n",
    "        print(f\"  Preview: {preview}...\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Page Formatting Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom page formatting applied:\n",
      "==================================================\n",
      "r research.\n",
      "\n",
      "†Work performed while at Google Brain.\n",
      "\n",
      "‡Work performed while at Google Research.\n",
      "\n",
      "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n",
      "\n",
      "[Page End]\n",
      "\n",
      "---PAGE BREAK---\n",
      "\n",
      "[Page Start]\n",
      "\n",
      "# 1 Introduction\n",
      "\n",
      "Recurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and trans\n"
     ]
    }
   ],
   "source": [
    "# Customizing page separators and formatting\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    split_by_page=False,      # Single document output\n",
    "    page_separator=\"\\n\\n---PAGE BREAK---\\n\\n\",  # Custom separator between pages\n",
    "    page_prefix=\"[Page Start]\",   # Prefix for each page\n",
    "    page_suffix=\"[Page End]\",     # Suffix for each page\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    documents = parser.load_data(pdf_path)\n",
    "    \n",
    "    if documents:\n",
    "        # Find page separators in output\n",
    "        content = documents[0].text\n",
    "        \n",
    "        print(\"Custom page formatting applied:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Show a section with page break\n",
    "        if \"---PAGE BREAK---\" in content:\n",
    "            # Find first page break\n",
    "            break_pos = content.find(\"---PAGE BREAK---\")\n",
    "            start = max(0, break_pos - 200)\n",
    "            end = min(len(content), break_pos + 250)\n",
    "            print(content[start:end])\n",
    "        else:\n",
    "            print(\"Page separators may not be visible in output\")\n",
    "            print(f\"\\nFirst 500 chars:\")\n",
    "            print(content[:500])\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Presets & Built-in Configurations\n",
    "\n",
    "LlamaParse provides pre-optimized configurations (presets) for different document types.\n",
    "\n",
    "### Available Presets\n",
    "\n",
    "| Preset | Best For | Description |\n",
    "|--------|----------|-------------|\n",
    "| `fast` | Quick extraction | No OCR, fastest processing |\n",
    "| `balanced` | General documents | Balance of speed and accuracy |\n",
    "| `premium` | Complex documents | Best quality, uses advanced models |\n",
    "| `structured` | Forms, tables | Optimized for structured data |\n",
    "| `auto` | Mixed content | Automatic mode selection |\n",
    "| `scientific` | Research papers | LaTeX, equations, citations |\n",
    "| `invoice` | Invoices, receipts | Financial document extraction |\n",
    "| `slides` | Presentations | PowerPoint, slide content |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Fast Preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing with FAST preset...\n",
      "(Best for: digital PDFs with selectable text)\n",
      "--------------------------------------------------\n",
      "Started parsing the file under job_id 299fb021-9c47-45b5-87d1-bf1d1dbaae59\n",
      "Error while parsing the file 'sample_documents/attention_paper.pdf': 'markdown'\n",
      "\n",
      "Parsing time: 11.30 seconds\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m elapsed = time.time() - start\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mParsing time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mContent length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mdocuments\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chars\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPreview:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(documents[\u001b[32m0\u001b[39m].text[:\u001b[32m500\u001b[39m])\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Fast preset - quickest parsing, skips OCR\n",
    "\n",
    "parser_fast = LlamaParse(\n",
    "    preset=\"fast\",  # Quick extraction without OCR\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"Parsing with FAST preset...\")\n",
    "    print(\"(Best for: digital PDFs with selectable text)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    documents = parser_fast.load_data(pdf_path)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"\\nParsing time: {elapsed:.2f} seconds\")\n",
    "    print(f\"Content length: {len(documents[0].text)} chars\")\n",
    "    print(f\"\\nPreview:\")\n",
    "    print(documents[0].text[:500])\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Premium Preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Premium preset - best quality parsing\n",
    "\n",
    "parser_premium = LlamaParse(\n",
    "    preset=\"premium\",  # Best quality, uses advanced models\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"Parsing with PREMIUM preset...\")\n",
    "    print(\"(Best for: complex layouts, scanned documents)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    documents = parser_premium.load_data(pdf_path)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"\\nParsing time: {elapsed:.2f} seconds\")\n",
    "    print(f\"Content length: {len(documents[0].text)} chars\")\n",
    "    print(f\"\\nPreview:\")\n",
    "    print(documents[0].text[:500])\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Scientific Preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scientific preset - optimized for research papers\n",
    "\n",
    "parser_scientific = LlamaParse(\n",
    "    preset=\"scientific\",  # Handles LaTeX, equations, citations\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"Parsing with SCIENTIFIC preset...\")\n",
    "    print(\"(Best for: academic papers, equations, citations)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    documents = parser_scientific.load_data(pdf_path)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"\\nParsing time: {elapsed:.2f} seconds\")\n",
    "    print(f\"Content length: {len(documents[0].text)} chars\")\n",
    "    print(f\"\\nPreview (look for equations and formatting):\")\n",
    "    print(documents[0].text[:800])\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Invoice Preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoice Preset Configuration:\n",
      "==================================================\n",
      "Best for: Invoices, receipts, financial documents\n",
      "Features:\n",
      "  - Optimized for tabular data (line items)\n",
      "  - Extracts dates, amounts, totals\n",
      "  - Handles various invoice formats\n",
      "\n",
      "Usage:\n",
      "  parser = LlamaParse(preset=\"invoice\")\n",
      "  docs = parser.load_data(\"invoice.pdf\")\n"
     ]
    }
   ],
   "source": [
    "# Invoice preset - optimized for financial documents\n",
    "\n",
    "parser_invoice = LlamaParse(\n",
    "    preset=\"invoice\",  # Handles invoices, receipts\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Note: For best results, use this with actual invoice documents\n",
    "# This example shows the configuration\n",
    "\n",
    "print(\"Invoice Preset Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Best for: Invoices, receipts, financial documents\")\n",
    "print(\"Features:\")\n",
    "print(\"  - Optimized for tabular data (line items)\")\n",
    "print(\"  - Extracts dates, amounts, totals\")\n",
    "print(\"  - Handles various invoice formats\")\n",
    "print(\"\\nUsage:\")\n",
    "print('  parser = LlamaParse(preset=\"invoice\")')\n",
    "print('  docs = parser.load_data(\"invoice.pdf\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Slides Preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slides Preset Configuration:\n",
      "==================================================\n",
      "Best for: PowerPoint, Google Slides, Keynote\n",
      "Features:\n",
      "  - Preserves slide structure\n",
      "  - Extracts speaker notes\n",
      "  - Handles diagrams and charts\n",
      "  - Maintains bullet point hierarchy\n",
      "\n",
      "Usage:\n",
      "  parser = LlamaParse(preset=\"slides\")\n",
      "  docs = parser.load_data(\"presentation.pptx\")\n"
     ]
    }
   ],
   "source": [
    "# Slides preset - optimized for presentations\n",
    "\n",
    "parser_slides = LlamaParse(\n",
    "    preset=\"slides\",  # Optimized for PowerPoint/presentations\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Note: Use with PPTX files for best results\n",
    "\n",
    "print(\"Slides Preset Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Best for: PowerPoint, Google Slides, Keynote\")\n",
    "print(\"Features:\")\n",
    "print(\"  - Preserves slide structure\")\n",
    "print(\"  - Extracts speaker notes\")\n",
    "print(\"  - Handles diagrams and charts\")\n",
    "print(\"  - Maintains bullet point hierarchy\")\n",
    "print(\"\\nUsage:\")\n",
    "print('  parser = LlamaParse(preset=\"slides\")')\n",
    "print('  docs = parser.load_data(\"presentation.pptx\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Comparing Presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing presets on the same document...\n",
      "============================================================\n",
      "\n",
      "Parsing with 'fast' preset...\n",
      "Error while parsing the file 'sample_documents/attention_paper.pdf': 'markdown'\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     24\u001b[39m     docs = parser.load_data(pdf_path)\n\u001b[32m     25\u001b[39m     elapsed = time.time() - start\n\u001b[32m     27\u001b[39m     results[preset] = {\n\u001b[32m     28\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m: elapsed,\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlength\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(\u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.text),\n\u001b[32m     30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpreview\u001b[39m\u001b[33m\"\u001b[39m: docs[\u001b[32m0\u001b[39m].text[:\u001b[32m200\u001b[39m]\n\u001b[32m     31\u001b[39m     }\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms, Content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(docs[\u001b[32m0\u001b[39m].text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chars\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Summary table\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Compare different presets on the same document\n",
    "\n",
    "import time\n",
    "\n",
    "presets_to_compare = [\"fast\", \"balanced\", \"premium\"]\n",
    "results = {}\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"Comparing presets on the same document...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for preset in presets_to_compare:\n",
    "        print(f\"\\nParsing with '{preset}' preset...\")\n",
    "        \n",
    "        parser = LlamaParse(\n",
    "            preset=preset,\n",
    "            result_type=\"markdown\",\n",
    "            verbose=False,\n",
    "        )\n",
    "        \n",
    "        start = time.time()\n",
    "        docs = parser.load_data(pdf_path)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        results[preset] = {\n",
    "            \"time\": elapsed,\n",
    "            \"length\": len(docs[0].text),\n",
    "            \"preview\": docs[0].text[:200]\n",
    "        }\n",
    "        \n",
    "        print(f\"  Time: {elapsed:.2f}s, Content: {len(docs[0].text)} chars\")\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"COMPARISON SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Preset':<12} {'Time (s)':<12} {'Content Length':<15}\")\n",
    "    print(\"-\" * 40)\n",
    "    for preset, data in results.items():\n",
    "        print(f\"{preset:<12} {data['time']:<12.2f} {data['length']:<15}\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Parse Modes\n",
    "\n",
    "LlamaParse offers granular control over parsing behavior through different modes.\n",
    "\n",
    "### Mode Categories\n",
    "\n",
    "**1. High-Level Modes (Boolean flags):**\n",
    "- `fast_mode`: Skip OCR, fastest processing\n",
    "- `premium_mode`: Best available parser\n",
    "- `auto_mode`: Automatic mode selection\n",
    "\n",
    "**2. Granular Parse Modes (Page-level):**\n",
    "- `parse_page_without_llm`: Fast extraction without AI\n",
    "- `parse_page_with_llm`: Uses LLM for each page\n",
    "- `parse_page_with_lvm`: Uses vision model for pages\n",
    "- `parse_page_with_agent`: Agentic reasoning per page\n",
    "- `parse_page_with_layout_agent`: Layout-aware agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Fast Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAST MODE Parsing\n",
      "==================================================\n",
      "Characteristics:\n",
      "  - No OCR processing\n",
      "  - Extracts only embedded/selectable text\n",
      "  - Fastest processing time\n",
      "  - Best for: Digital PDFs with selectable text\n",
      "--------------------------------------------------\n",
      "Started parsing the file under job_id 836a6816-2ba6-41ef-a90d-94c69aea1bed\n",
      "Error while parsing the file 'sample_documents/attention_paper.pdf': 'markdown'\n",
      "\n",
      "Time: 12.63s\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m     elapsed = time.time() - start\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTime: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mContent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mdocuments\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chars\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Fast mode - skips OCR for faster processing\n",
    "\n",
    "parser_fast = LlamaParse(\n",
    "    fast_mode=True,  # Skip OCR, extract text only\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"FAST MODE Parsing\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Characteristics:\")\n",
    "    print(\"  - No OCR processing\")\n",
    "    print(\"  - Extracts only embedded/selectable text\")\n",
    "    print(\"  - Fastest processing time\")\n",
    "    print(\"  - Best for: Digital PDFs with selectable text\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    documents = parser_fast.load_data(pdf_path)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"\\nTime: {elapsed:.2f}s\")\n",
    "    print(f\"Content: {len(documents[0].text)} chars\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Premium Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREMIUM MODE Parsing\n",
      "==================================================\n",
      "Characteristics:\n",
      "  - Uses advanced AI models\n",
      "  - Better table extraction\n",
      "  - Improved layout understanding\n",
      "  - Best for: Complex documents, financial reports\n",
      "--------------------------------------------------\n",
      "Started parsing the file under job_id f112bfe9-69d9-4541-aed0-f78721841a38\n",
      "\n",
      "Time: 40.23s\n",
      "Content: 3027 chars\n"
     ]
    }
   ],
   "source": [
    "# Premium mode - best quality parsing\n",
    "\n",
    "parser_premium = LlamaParse(\n",
    "    premium_mode=True,  # Use best available parser\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"PREMIUM MODE Parsing\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Characteristics:\")\n",
    "    print(\"  - Uses advanced AI models\")\n",
    "    print(\"  - Better table extraction\")\n",
    "    print(\"  - Improved layout understanding\")\n",
    "    print(\"  - Best for: Complex documents, financial reports\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    documents = parser_premium.load_data(pdf_path)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"\\nTime: {elapsed:.2f}s\")\n",
    "    print(f\"Content: {len(documents[0].text)} chars\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Auto Mode with Triggers\n",
    "\n",
    "Auto mode dynamically selects the best parsing strategy based on page content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTO MODE with Triggers\n",
      "==================================================\n",
      "Configuration:\n",
      "  - auto_mode: True\n",
      "  - Trigger on images: True\n",
      "  - Trigger on tables: True\n",
      "\n",
      "Behavior:\n",
      "  - Simple text pages → Fast parsing\n",
      "  - Pages with images/tables → Premium parsing\n",
      "--------------------------------------------------\n",
      "Started parsing the file under job_id b19e2699-9534-4da4-9f5d-f02265443d63\n",
      ".\n",
      "Time: 92.20s\n",
      "Content: 2942 chars\n"
     ]
    }
   ],
   "source": [
    "# Auto mode - automatically selects parsing strategy per page\n",
    "\n",
    "parser_auto = LlamaParse(\n",
    "    auto_mode=True,  # Enable automatic mode selection\n",
    "    \n",
    "    # Trigger conditions for upgrading to premium parsing\n",
    "    auto_mode_trigger_on_image_in_page=True,   # Upgrade pages with images\n",
    "    auto_mode_trigger_on_table_in_page=True,   # Upgrade pages with tables\n",
    "    \n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"AUTO MODE with Triggers\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Configuration:\")\n",
    "    print(\"  - auto_mode: True\")\n",
    "    print(\"  - Trigger on images: True\")\n",
    "    print(\"  - Trigger on tables: True\")\n",
    "    print(\"\\nBehavior:\")\n",
    "    print(\"  - Simple text pages → Fast parsing\")\n",
    "    print(\"  - Pages with images/tables → Premium parsing\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    documents = parser_auto.load_data(pdf_path)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"\\nTime: {elapsed:.2f}s\")\n",
    "    print(f\"Content: {len(documents[0].text)} chars\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Auto Mode with Text Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTO MODE with Text Trigger\n",
      "==================================================\n",
      "Configuration:\n",
      "  - Trigger pattern: \"table|figure|equation\"\n",
      "\n",
      "Behavior:\n",
      "  - Pages containing 'table', 'figure', or 'equation' → Premium\n",
      "  - Other pages → Fast parsing\n"
     ]
    }
   ],
   "source": [
    "# Auto mode with text-based trigger\n",
    "\n",
    "parser_auto_text = LlamaParse(\n",
    "    auto_mode=True,\n",
    "    auto_mode_trigger_on_text_in_page=\"table|figure|equation\",  # Regex pattern\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"AUTO MODE with Text Trigger\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration:\")\n",
    "print('  - Trigger pattern: \"table|figure|equation\"')\n",
    "print(\"\\nBehavior:\")\n",
    "print(\"  - Pages containing 'table', 'figure', or 'equation' → Premium\")\n",
    "print(\"  - Other pages → Fast parsing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Auto Mode with Regex Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTO MODE with Regex Trigger\n",
      "==================================================\n",
      "Configuration:\n",
      "  - Regex pattern: \"\\d+\\.\\d+%|\\$[\\d,]+\"\n",
      "  - Matches: Percentages (45.5%) or dollar amounts ($1,000)\n",
      "\n",
      "Use case:\n",
      "  - Upgrade pages with financial data to premium parsing\n",
      "  - Keep text-only pages in fast mode\n"
     ]
    }
   ],
   "source": [
    "# Auto mode with regex pattern trigger\n",
    "\n",
    "parser_auto_regex = LlamaParse(\n",
    "    auto_mode=True,\n",
    "    auto_mode_trigger_on_regexp_in_page=r\"\\d+\\.\\d+%|\\$[\\d,]+\",  # Percentages or dollar amounts\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"AUTO MODE with Regex Trigger\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration:\")\n",
    "print(r'  - Regex pattern: \"\\d+\\.\\d+%|\\$[\\d,]+\"')\n",
    "print(\"  - Matches: Percentages (45.5%) or dollar amounts ($1,000)\")\n",
    "print(\"\\nUse case:\")\n",
    "print(\"  - Upgrade pages with financial data to premium parsing\")\n",
    "print(\"  - Keep text-only pages in fast mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Auto Mode with JSON Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTO MODE with JSON Configuration\n",
      "==================================================\n",
      "Configuration JSON:\n",
      "{\n",
      "  \"trigger_conditions\": {\n",
      "    \"on_image\": true,\n",
      "    \"on_table\": true,\n",
      "    \"on_text_patterns\": [\n",
      "      \"figure\",\n",
      "      \"table\",\n",
      "      \"chart\"\n",
      "    ]\n",
      "  },\n",
      "  \"fallback_mode\": \"fast\",\n",
      "  \"upgrade_mode\": \"premium\"\n",
      "}\n",
      "\n",
      "This allows complex conditional parsing logic.\n"
     ]
    }
   ],
   "source": [
    "# Auto mode with advanced JSON configuration\n",
    "\n",
    "auto_config = {\n",
    "    \"trigger_conditions\": {\n",
    "        \"on_image\": True,\n",
    "        \"on_table\": True,\n",
    "        \"on_text_patterns\": [\"figure\", \"table\", \"chart\"],\n",
    "    },\n",
    "    \"fallback_mode\": \"fast\",\n",
    "    \"upgrade_mode\": \"premium\"\n",
    "}\n",
    "\n",
    "parser_auto_json = LlamaParse(\n",
    "    auto_mode=True,\n",
    "    auto_mode_configuration_json=json.dumps(auto_config),\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"AUTO MODE with JSON Configuration\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration JSON:\")\n",
    "print(json.dumps(auto_config, indent=2))\n",
    "print(\"\\nThis allows complex conditional parsing logic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Granular Parse Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRANULAR PARSE MODES\n",
      "======================================================================\n",
      "\n",
      "parse_page_without_llm:\n",
      "  Description: Fast extraction without AI reconstruction\n",
      "  Use Case: Simple text documents, speed priority\n",
      "  Cost: Low\n",
      "\n",
      "parse_page_with_llm:\n",
      "  Description: Uses language model for page parsing\n",
      "  Use Case: Mixed content, text-heavy documents\n",
      "  Cost: Medium\n",
      "\n",
      "parse_page_with_lvm:\n",
      "  Description: Uses vision-language model for each page\n",
      "  Use Case: Image-heavy documents, diagrams\n",
      "  Cost: Medium-High\n",
      "\n",
      "parse_page_with_agent:\n",
      "  Description: Agentic reasoning for complex pages\n",
      "  Use Case: Complex layouts, nested structures\n",
      "  Cost: High\n",
      "\n",
      "parse_page_with_layout_agent:\n",
      "  Description: Layout-aware agent for visual structure\n",
      "  Use Case: Multi-column documents, forms\n",
      "  Cost: High\n"
     ]
    }
   ],
   "source": [
    "# Overview of granular parse modes\n",
    "\n",
    "granular_modes = {\n",
    "    \"parse_page_without_llm\": {\n",
    "        \"description\": \"Fast extraction without AI reconstruction\",\n",
    "        \"use_case\": \"Simple text documents, speed priority\",\n",
    "        \"cost\": \"Low\"\n",
    "    },\n",
    "    \"parse_page_with_llm\": {\n",
    "        \"description\": \"Uses language model for page parsing\",\n",
    "        \"use_case\": \"Mixed content, text-heavy documents\",\n",
    "        \"cost\": \"Medium\"\n",
    "    },\n",
    "    \"parse_page_with_lvm\": {\n",
    "        \"description\": \"Uses vision-language model for each page\",\n",
    "        \"use_case\": \"Image-heavy documents, diagrams\",\n",
    "        \"cost\": \"Medium-High\"\n",
    "    },\n",
    "    \"parse_page_with_agent\": {\n",
    "        \"description\": \"Agentic reasoning for complex pages\",\n",
    "        \"use_case\": \"Complex layouts, nested structures\",\n",
    "        \"cost\": \"High\"\n",
    "    },\n",
    "    \"parse_page_with_layout_agent\": {\n",
    "        \"description\": \"Layout-aware agent for visual structure\",\n",
    "        \"use_case\": \"Multi-column documents, forms\",\n",
    "        \"cost\": \"High\"\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"GRANULAR PARSE MODES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for mode, info in granular_modes.items():\n",
    "    print(f\"\\n{mode}:\")\n",
    "    print(f\"  Description: {info['description']}\")\n",
    "    print(f\"  Use Case: {info['use_case']}\")\n",
    "    print(f\"  Cost: {info['cost']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Comparing Parse Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARING FAST MODE vs PREMIUM MODE\n",
      "============================================================\n",
      "\n",
      "1. Fast Mode:\n",
      "Error while parsing the file 'sample_documents/attention_paper.pdf': 'markdown'\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m docs_fast = parser_fast.load_data(pdf_path)\n\u001b[32m     16\u001b[39m time_fast = time.time() - start\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_fast\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms, Length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mdocs_fast\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chars\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Premium mode\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m2. Premium Mode:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Compare fast_mode vs premium_mode\n",
    "\n",
    "import time\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"COMPARING FAST MODE vs PREMIUM MODE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Fast mode\n",
    "    print(\"\\n1. Fast Mode:\")\n",
    "    parser_fast = LlamaParse(fast_mode=True, result_type=\"markdown\", verbose=False)\n",
    "    start = time.time()\n",
    "    docs_fast = parser_fast.load_data(pdf_path)\n",
    "    time_fast = time.time() - start\n",
    "    print(f\"   Time: {time_fast:.2f}s, Length: {len(docs_fast[0].text)} chars\")\n",
    "    \n",
    "    # Premium mode\n",
    "    print(\"\\n2. Premium Mode:\")\n",
    "    parser_premium = LlamaParse(premium_mode=True, result_type=\"markdown\", verbose=False)\n",
    "    start = time.time()\n",
    "    docs_premium = parser_premium.load_data(pdf_path)\n",
    "    time_premium = time.time() - start\n",
    "    print(f\"   Time: {time_premium:.2f}s, Length: {len(docs_premium[0].text)} chars\")\n",
    "    \n",
    "    # Auto mode\n",
    "    print(\"\\n3. Auto Mode:\")\n",
    "    parser_auto = LlamaParse(\n",
    "        auto_mode=True, \n",
    "        auto_mode_trigger_on_table_in_page=True,\n",
    "        result_type=\"markdown\", \n",
    "        verbose=False\n",
    "    )\n",
    "    start = time.time()\n",
    "    docs_auto = parser_auto.load_data(pdf_path)\n",
    "    time_auto = time.time() - start\n",
    "    print(f\"   Time: {time_auto:.2f}s, Length: {len(docs_auto[0].text)} chars\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SUMMARY\")\n",
    "    print(f\"{'Mode':<15} {'Time (s)':<12} {'Content Length':<15} {'Speed Ratio'}\")\n",
    "    print(\"-\" * 55)\n",
    "    print(f\"{'Fast':<15} {time_fast:<12.2f} {len(docs_fast[0].text):<15} 1.0x\")\n",
    "    print(f\"{'Premium':<15} {time_premium:<12.2f} {len(docs_premium[0].text):<15} {time_premium/time_fast:.1f}x\")\n",
    "    print(f\"{'Auto':<15} {time_auto:<12.2f} {len(docs_auto[0].text):<15} {time_auto/time_fast:.1f}x\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Supported File Formats\n",
    "\n",
    "LlamaParse supports 70+ file formats:\n",
    "\n",
    "| Category | Formats |\n",
    "|----------|----------|\n",
    "| Documents | PDF, DOC, DOCX, RTF, TXT, EPUB |\n",
    "| Spreadsheets | XLSX, XLS, CSV, ODS |\n",
    "| Presentations | PPTX, PPT |\n",
    "| Images | JPG, PNG, GIF, BMP, TIFF, WEBP, SVG |\n",
    "| Web | HTML, HTM |\n",
    "| Audio | MP3, MP4, WAV, WEBM, M4A (≤20MB) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Parsing PDF Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF PARSING\n",
      "==================================================\n",
      "Started parsing the file under job_id 8494049d-9bf4-48d0-8b98-2acb7eecfacf\n",
      "\n",
      "Parsed 15 document(s)\n",
      "Content length: 2767 characters\n",
      "\n",
      "Document Metadata:\n"
     ]
    }
   ],
   "source": [
    "# PDF parsing - the most common use case\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"PDF PARSING\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    documents = parser.load_data(pdf_path)\n",
    "    \n",
    "    print(f\"\\nParsed {len(documents)} document(s)\")\n",
    "    print(f\"Content length: {len(documents[0].text)} characters\")\n",
    "    \n",
    "    # Check metadata\n",
    "    print(f\"\\nDocument Metadata:\")\n",
    "    for key, value in documents[0].metadata.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Parsing PDF with OCR Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF OCR OPTIONS\n",
      "==================================================\n",
      "\n",
      "1. high_res_ocr=True:\n",
      "   - Higher accuracy for scanned documents\n",
      "   - Slower processing\n",
      "   - Best for: Scanned PDFs, poor quality images\n",
      "\n",
      "2. disable_ocr=True:\n",
      "   - Only extracts embedded/selectable text\n",
      "   - Fastest processing\n",
      "   - Best for: Digital PDFs with selectable text\n"
     ]
    }
   ],
   "source": [
    "# PDF with different OCR configurations\n",
    "\n",
    "# High-resolution OCR (slower but more accurate)\n",
    "parser_high_ocr = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    high_res_ocr=True,  # Better OCR quality\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Disable OCR (only extract embedded text)\n",
    "parser_no_ocr = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    disable_ocr=True,  # Skip OCR completely\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"PDF OCR OPTIONS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n1. high_res_ocr=True:\")\n",
    "print(\"   - Higher accuracy for scanned documents\")\n",
    "print(\"   - Slower processing\")\n",
    "print(\"   - Best for: Scanned PDFs, poor quality images\")\n",
    "print(\"\\n2. disable_ocr=True:\")\n",
    "print(\"   - Only extracts embedded/selectable text\")\n",
    "print(\"   - Fastest processing\")\n",
    "print(\"   - Best for: Digital PDFs with selectable text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Parsing HTML Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML PARSING\n",
      "==================================================\n",
      "Started parsing the file under job_id f509be59-9f3f-41b6-9922-b537275e1e2f\n",
      "\n",
      "Parsed 2 document(s)\n",
      "Content length: 1965 characters\n",
      "\n",
      "Extracted content preview:\n",
      "--------------------------------------------------\n",
      "\n",
      "# Introduction to Document Parsing\n",
      "\n",
      "A comprehensive guide to understanding document parsing techniques\n",
      "\n",
      "# 1. Overview\n",
      "\n",
      "Document parsing is the process of analyzing and extracting structured information from various document formats. This includes PDFs, Word documents, HTML pages, and more.\n",
      "\n",
      "# 1.1 Key Benefits\n",
      "\n",
      "- Automated data extraction\n",
      "- Structured content analysis\n",
      "- Integration with AI/ML pipelines\n",
      "- Support for multiple formats\n",
      "\n",
      "# 2. Core Features\n",
      "\n",
      "Modern document parsers offer a variety of features:\n",
      "\n",
      "| Feature          | Description                                         | Use Case                         |\n",
      "| ---------------- | --------------------------------------------------- | -------------------------------- |\n",
      "| OCR Support      | Optical Character Recognition for scanned docum\n"
     ]
    }
   ],
   "source": [
    "# HTML parsing\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "html_path = str(SAMPLE_DIR / \"sample.html\")\n",
    "\n",
    "if Path(html_path).exists():\n",
    "    print(\"HTML PARSING\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    documents = parser.load_data(html_path)\n",
    "    \n",
    "    print(f\"\\nParsed {len(documents)} document(s)\")\n",
    "    print(f\"Content length: {len(documents[0].text)} characters\")\n",
    "    print(f\"\\nExtracted content preview:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(documents[0].text[:800])\n",
    "else:\n",
    "    print(f\"HTML file not found: {html_path}\")\n",
    "    print(\"\\nExample usage:\")\n",
    "    print('  documents = parser.load_data(\"webpage.html\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Parsing Markdown Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARKDOWN PARSING\n",
      "==================================================\n",
      "Error while parsing the file 'sample_documents/sample.md': Currently, only the following file types are supported: ['.pdf', '.602', '.abw', '.cgm', '.cwk', '.doc', '.docx', '.docm', '.dot', '.dotm', '.hwp', '.key', '.lwp', '.mw', '.mcw', '.pages', '.pbd', '.ppt', '.pptm', '.pptx', '.pot', '.potm', '.potx', '.rtf', '.sda', '.sdd', '.sdp', '.sdw', '.sgl', '.sti', '.sxi', '.sxw', '.stw', '.sxg', '.txt', '.uof', '.uop', '.uot', '.vor', '.wpd', '.wps', '.xml', '.zabw', '.epub', '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg', '.tiff', '.webp', '.htm', '.html', '.xlsx', '.xls', '.xlsm', '.xlsb', '.xlw', '.csv', '.dif', '.sylk', '.slk', '.prn', '.numbers', '.et', '.ods', '.fods', '.uos1', '.uos2', '.dbf', '.wk1', '.wk2', '.wk3', '.wk4', '.wks', '.123', '.wq1', '.wq2', '.wb1', '.wb2', '.wb3', '.qpw', '.xlr', '.eth', '.tsv', '.mp3', '.mp4', '.mpeg', '.mpga', '.m4a', '.wav', '.webm']\n",
      "Current file type: .md\n",
      "\n",
      "Parsed 0 document(s)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m documents = parser.load_data(md_path)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mParsed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m document(s)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mContent length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mdocuments\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m characters\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mExtracted content preview:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Markdown parsing\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "md_path = str(SAMPLE_DIR / \"sample.md\")\n",
    "\n",
    "if Path(md_path).exists():\n",
    "    print(\"MARKDOWN PARSING\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    documents = parser.load_data(md_path)\n",
    "    \n",
    "    print(f\"\\nParsed {len(documents)} document(s)\")\n",
    "    print(f\"Content length: {len(documents[0].text)} characters\")\n",
    "    print(f\"\\nExtracted content preview:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(documents[0].text[:600])\n",
    "else:\n",
    "    print(f\"Markdown file not found: {md_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Parsing Microsoft Office Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='6f5a7ad0-c22f-4eaf-90f3-b5c6a1964b27', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Deepfake Technology: A Technical Analysis\\n\\n# Deepfake Technology: A Technical Analysis of GAN-Based Synthetic Media\\n\\n# Technical Report\\n\\n# Introduction\\n\\nDeepfake technology represents one of the most significant applications of artificial intelligence. The term \"deepfake\" combines \"deep learning\" and \"fake,\" referring to synthetic media where a person\\'s face, body, or voice is digitally altered (Sharma &#x26; Kaur, 2022).\\n\\n# Key Statistics:\\n\\n- Projected 8 million deepfakes will be shared in 2025\\n- Significant increase from 500,000 in 2023 (European Parliament, 2025)\\n- 49% of companies experienced audio/video deepfakes in 2024\\n\\n# Technical Foundation: Generative Adversarial Networks\\n\\nThe core technology behind deepfakes is Generative Adversarial Networks (GANs), introduced by Goodfellow et al. in 2014. GANs use two competing neural networks:\\n\\n- Generator: Creates synthetic images, videos, or audio\\n- Discriminator: Evaluates whether content is real or fake\\n\\nThis adversarial process drives continuous improvement. Key developments include:\\n\\n- DCGANs (2015): Combined CNNs with GANs for better image quality\\n- StyleGAN &#x26; ProGAN: Achieved photorealistic synthesis\\n- Diffusion Models: Emerging alternative with improved stability (Karakanis &#x26; Leontaris, 2025)\\n\\n# Positive Applications of Deepfake Technology\\n\\nDespite concerns, deepfakes offer substantial benefits across multiple domains (Danry et al., 2022):\\n\\n1. Entertainment Industry\\n- Resurrection of deceased actors for film productions\\n- De-aging technology (e.g., Luke Skywalker in \"The Book of Boba Fett\")\\n- Cost-effective visual effects for independent filmmakers\\n- Multilingual dubbing with accurate lip-syncing (Murphy et al., 2023)\\n2. Education and Museums\\n- Interactive historical experiences (e.g., Salvador Dalí Museum in Florida)\\n\\nPage 1\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ab565ba4-f722-4152-9f4b-bf7873969499', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='\\n# Deepfake Technology: A Technical Analysis\\n\\n- Medical training simulations without ethical concerns\\n- Bringing historical figures to life for immersive learning\\n\\n# Negative Implications and Ethical Concerns\\n\\nDeepfake technology presents severe risks when employed maliciously:\\n\\n# 1. Financial Fraud\\n\\n- 2024 case: Elon Musk deepfake promoted crypto scam, causing $690,000 loss to one victim\\n- Projected $40 billion in fraud losses within three years (Westfall, 2024)\\n- Identity theft and impersonation attacks on businesses\\n\\n# 2. Misinformation and Political Manipulation\\n\\n- Fabricated statements by public officials\\n- Potential to influence elections and erode democratic trust\\n- Low barrier to entry—minimal technical skills required\\n\\n# Conclusion\\n\\nDeepfake technology exemplifies the dual-use nature of AI innovations. Responsible use requires:\\n\\n- Development of robust detection mechanisms\\n- Establishment of clear regulatory frameworks\\n- Promotion of digital literacy among the public\\n- Collaboration across industry, government, and academia\\n\\nThe key lies in harnessing creative potential while mitigating capacity for harm through ethical guidelines, transparency, and consent.\\n\\n# References\\n\\n- Danry, V., Leong, P., Epstein, Z., &#x26; Holtzman, N. (2022). A deeper dive into deepfakes: Positive applications and ethical considerations. Proceedings of the ACM Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3491102\\n- European Parliament. (2025). Children and deepfakes: Risks and regulatory considerations. European Parliamentary Research Service. https://www.europarl.europa.eu/RegData/etudes/BRIE/2025/775855/EPRS_BRI(2025)775855_EN.pdf\\n- Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., &#x26; Bengio, Y. (2014). Generative adversarial nets. Advances in Neural Information Processing Systems, 27, 2672–2680. https://papers.nips.cc/paper/5423-generative-adversarial-nets\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='2915cd7b-89ac-48ba-843f-a4132ae78000', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='\\n\\nDeepfake Technology: A Technical Analysis\\n\\nKarakanis, S., &#x26; Leontaris, G. (2025). Advancing GAN deepfake detection: Mixed datasets and comprehensive artifact analysis. *Applied Sciences*, 15(2), 923. https://doi.org/10.3390/app15020923\\n\\nMurphy, L., Cass, S., &#x26; Williams, P. (2023). Face/off: Changing the face of movies with deepfakes. *PLOS ONE*, 18(7), e0287253. https://pmc.ncbi.nlm.nih.gov/articles/PMC10325052/\\n\\nSharma, M., &#x26; Kaur, M. (2022). A review of deepfake technology: An emerging AI threat. In *Soft Computing for Security Applications: Proceedings of ICSCS 2021* (pp. 605–619). Springer. https://doi.org/10.1007/978-981-16-5301-8_44\\n\\nPage 3\\n\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICROSOFT OFFICE PARSING\n",
      "==================================================\n",
      "\n",
      "1. DOCX (Word Documents):\n",
      "Started parsing the file under job_id 86a9e7dc-21db-47a7-9605-2b84830c68e0\n",
      "   - Preserves headings, lists, tables\n",
      "   - Extracts embedded images\n"
     ]
    }
   ],
   "source": [
    "# Microsoft Office document parsing\n",
    "\n",
    "# DOCX parsing\n",
    "parser_docx = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"MICROSOFT OFFICE PARSING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1. DOCX (Word Documents):\")\n",
    "result = parser_docx.load_data('sample_documents/sample.docx')\n",
    "print(\"   - Preserves headings, lists, tables\")\n",
    "print(\"   - Extracts embedded images\")\n",
    "\n",
    "# print(\"\\n2. XLSX (Excel Spreadsheets):\")\n",
    "# parser = LlamaParse(\n",
    "#     spreadsheet_extract_sub_tables=True,\n",
    "#     guess_xlsx_sheet_names=True,\n",
    "# )\n",
    "# parser.load_data('spreadsheet.xlsx')\n",
    "\n",
    "# print(\"\\n3. PPTX (PowerPoint):\")\n",
    "# parser = LlamaParse(preset=\"slides\")\n",
    "# parser.load_data('presentation.pptx')\n",
    "# print(\"   - Extracts slide content\")\n",
    "# print(\"   - Includes speaker notes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Parsing Excel Spreadsheets with Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel-specific parsing options\n",
    "\n",
    "parser_excel = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    \n",
    "    # Excel-specific options\n",
    "    spreadsheet_extract_sub_tables=True,  # Extract sub-tables within sheets\n",
    "    guess_xlsx_sheet_names=True,          # Try to infer meaningful sheet names\n",
    "    compact_markdown_table=True,          # More compact table output\n",
    "    output_tables_as_HTML=False,          # Keep as markdown (not HTML)\n",
    "    \n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"EXCEL PARSING OPTIONS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration:\")\n",
    "print(\"  - spreadsheet_extract_sub_tables: True\")\n",
    "print(\"  - guess_xlsx_sheet_names: True\")\n",
    "print(\"  - compact_markdown_table: True\")\n",
    "print(\"  - output_tables_as_HTML: False\")\n",
    "print(\"\\nUsage:\")\n",
    "print('  documents = parser_excel.load_data(\"financial_data.xlsx\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Parsing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parsing with OCR\n",
    "\n",
    "parser_image = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    high_res_ocr=True,  # High quality OCR for images\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"IMAGE PARSING\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Supported formats: JPG, JPEG, PNG, GIF, BMP, TIFF, WEBP, SVG\")\n",
    "print(\"\\nRecommended settings for images:\")\n",
    "print(\"  - high_res_ocr=True: Better text extraction\")\n",
    "print(\"  - premium_mode=True: Best quality for complex images\")\n",
    "print(\"\\nUsage:\")\n",
    "print('  documents = parser_image.load_data(\"scanned_document.png\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8 Parsing Multiple File Types Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing multiple files of different types\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    num_workers=4,  # Parallel processing for multiple files\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Collect available sample files\n",
    "files_to_parse = []\n",
    "for ext in [\"*.pdf\", \"*.html\", \"*.md\"]:\n",
    "    files_to_parse.extend(list(SAMPLE_DIR.glob(ext)))\n",
    "\n",
    "print(\"MULTI-FILE PARSING\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Found {len(files_to_parse)} files to parse:\")\n",
    "for f in files_to_parse:\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "if files_to_parse:\n",
    "    # Parse all files\n",
    "    file_paths = [str(f) for f in files_to_parse]\n",
    "    \n",
    "    print(f\"\\nParsing {len(file_paths)} files...\")\n",
    "    all_documents = []\n",
    "    for path in file_paths:\n",
    "        docs = parser.load_data(path)\n",
    "        all_documents.extend(docs)\n",
    "        print(f\"  Parsed: {Path(path).name} ({len(docs)} doc(s))\")\n",
    "    \n",
    "    print(f\"\\nTotal documents: {len(all_documents)}\")\n",
    "else:\n",
    "    print(\"\\nNo sample files found. Add files to sample_documents/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Multimodal Parsing Features\n",
    "\n",
    "LlamaParse can extract and process visual elements from documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Extract Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable chart extraction from documents\n",
    "\n",
    "parser_charts = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    extract_charts=True,  # Extract charts and graphs\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"CHART EXTRACTION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Use parse() to access charts\n",
    "    job_results = parser_charts.parse([pdf_path])\n",
    "    \n",
    "    if job_results:\n",
    "        result = job_results[0]\n",
    "        \n",
    "        # Check for charts in each page\n",
    "        total_charts = 0\n",
    "        for i, page in enumerate(result.pages):\n",
    "            if hasattr(page, 'charts') and page.charts:\n",
    "                print(f\"Page {i+1}: {len(page.charts)} chart(s) found\")\n",
    "                total_charts += len(page.charts)\n",
    "        \n",
    "        print(f\"\\nTotal charts extracted: {total_charts}\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Take Screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable page screenshots\n",
    "\n",
    "parser_screenshots = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    take_screenshot=True,  # Capture page screenshots\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"PAGE SCREENSHOTS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration: take_screenshot=True\")\n",
    "print(\"\\nBehavior:\")\n",
    "print(\"  - Captures visual rendering of each page\")\n",
    "print(\"  - Useful for preserving visual context\")\n",
    "print(\"  - Screenshots accessible via aget_image_documents()\")\n",
    "print(\"\\nUsage:\")\n",
    "print(\"  result = await parser.aparse('document.pdf')\")\n",
    "print(\"  images = await result.aget_image_documents(\")\n",
    "print(\"      include_screenshot_images=True\")\n",
    "print(\"  )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 High-Resolution OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-resolution OCR for better text extraction\n",
    "\n",
    "parser_high_ocr = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    high_res_ocr=True,  # Enable high-resolution OCR\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"HIGH-RESOLUTION OCR\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration: high_res_ocr=True\")\n",
    "print(\"\\nBenefits:\")\n",
    "print(\"  - Better accuracy for scanned documents\")\n",
    "print(\"  - Improved extraction of small text\")\n",
    "print(\"  - Better handling of poor quality images\")\n",
    "print(\"\\nTrade-offs:\")\n",
    "print(\"  - Slower processing time\")\n",
    "print(\"  - Higher computational cost\")\n",
    "print(\"\\nBest for:\")\n",
    "print(\"  - Scanned PDFs\")\n",
    "print(\"  - Historical documents\")\n",
    "print(\"  - Low-quality image sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Using Vendor Multimodal Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using external multimodal models (e.g., GPT-4V)\n",
    "\n",
    "# Note: Requires your own API key for the multimodal provider\n",
    "parser_multimodal = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    use_vendor_multimodal_model=True,           # Enable vendor model\n",
    "    vendor_multimodal_model_name=\"gpt-4o\",      # Model name\n",
    "    # vendor_multimodal_api_key=\"your-api-key\", # Your OpenAI API key\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"VENDOR MULTIMODAL MODEL\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration:\")\n",
    "print(\"  - use_vendor_multimodal_model: True\")\n",
    "print(\"  - vendor_multimodal_model_name: 'gpt-4o'\")\n",
    "print(\"  - vendor_multimodal_api_key: Your API key\")\n",
    "print(\"\\nSupported models:\")\n",
    "print(\"  - OpenAI: gpt-4o, gpt-4-vision-preview\")\n",
    "print(\"  - Anthropic: claude-3-opus, claude-3-sonnet\")\n",
    "print(\"  - Other vision-capable models\")\n",
    "print(\"\\nUse case:\")\n",
    "print(\"  - Complex visual understanding\")\n",
    "print(\"  - Diagram interpretation\")\n",
    "print(\"  - Visual question answering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Accessing Extracted Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing extracted images from parsed documents\n",
    "\n",
    "async def extract_images_example(file_path: str):\n",
    "    \"\"\"\n",
    "    Demonstrate image extraction from documents.\n",
    "    \"\"\"\n",
    "    parser = LlamaParse(\n",
    "        result_type=\"markdown\",\n",
    "        extract_charts=True,\n",
    "        take_screenshot=True,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    # Parse document\n",
    "    result = await parser.aparse(file_path)\n",
    "    \n",
    "    # Get image documents\n",
    "    image_docs = await result.aget_image_documents(\n",
    "        include_screenshot_images=True,  # Include page screenshots\n",
    "        include_object_images=True,      # Include extracted objects\n",
    "    )\n",
    "    \n",
    "    return image_docs\n",
    "\n",
    "print(\"IMAGE EXTRACTION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Using aget_image_documents() method:\")\n",
    "print(\"\")\n",
    "print(\"Parameters:\")\n",
    "print(\"  - include_screenshot_images: Include page screenshots\")\n",
    "print(\"  - include_object_images: Include extracted charts/images\")\n",
    "print(\"\")\n",
    "print(\"Example:\")\n",
    "print(\"  images = await result.aget_image_documents(\")\n",
    "print(\"      include_screenshot_images=True,\")\n",
    "print(\"      include_object_images=True\")\n",
    "print(\"  )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Image and Chart Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding image and chart metadata\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    extract_charts=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"IMAGE AND CHART METADATA\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    job_results = parser.parse([pdf_path])\n",
    "    \n",
    "    if job_results:\n",
    "        result = job_results[0]\n",
    "        \n",
    "        for i, page in enumerate(result.pages[:5]):  # First 5 pages\n",
    "            print(f\"\\nPage {i+1}:\")\n",
    "            \n",
    "            # Images\n",
    "            if hasattr(page, 'images') and page.images:\n",
    "                print(f\"  Images: {len(page.images)}\")\n",
    "                for j, img in enumerate(page.images[:2]):\n",
    "                    print(f\"    Image {j+1}: {type(img).__name__}\")\n",
    "            else:\n",
    "                print(\"  Images: 0\")\n",
    "            \n",
    "            # Charts\n",
    "            if hasattr(page, 'charts') and page.charts:\n",
    "                print(f\"  Charts: {len(page.charts)}\")\n",
    "                for j, chart in enumerate(page.charts[:2]):\n",
    "                    print(f\"    Chart {j+1}: {type(chart).__name__}\")\n",
    "            else:\n",
    "                print(\"  Charts: 0\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Layout Extraction\n",
    "\n",
    "LlamaParse can extract and preserve document layout information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Enable Layout Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable layout extraction\n",
    "\n",
    "parser_layout = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    extract_layout=True,  # Extract layout information\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"LAYOUT EXTRACTION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    job_results = parser_layout.parse([pdf_path])\n",
    "    \n",
    "    if job_results:\n",
    "        result = job_results[0]\n",
    "        \n",
    "        # Check for layout data in pages\n",
    "        for i, page in enumerate(result.pages[:3]):\n",
    "            print(f\"\\nPage {i+1}:\")\n",
    "            if hasattr(page, 'layout') and page.layout:\n",
    "                print(f\"  Layout data available: Yes\")\n",
    "                print(f\"  Layout type: {type(page.layout).__name__}\")\n",
    "                if isinstance(page.layout, dict):\n",
    "                    print(f\"  Layout keys: {list(page.layout.keys())[:5]}\")\n",
    "            else:\n",
    "                print(\"  Layout data available: No\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Preserve Column Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserve column layout (don't unroll columns)\n",
    "\n",
    "parser_columns = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    extract_layout=True,\n",
    "    do_not_unroll_columns=True,  # Keep column structure\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"PRESERVE COLUMN LAYOUT\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration: do_not_unroll_columns=True\")\n",
    "print(\"\\nBehavior:\")\n",
    "print(\"  - Default: Columns are merged into single-column text\")\n",
    "print(\"  - With flag: Column structure is preserved\")\n",
    "print(\"\\nBest for:\")\n",
    "print(\"  - Multi-column academic papers\")\n",
    "print(\"  - Newspapers and magazines\")\n",
    "print(\"  - Documents with parallel content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Preserve Layout Alignment Across Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserve layout alignment across pages\n",
    "\n",
    "parser_aligned = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    extract_layout=True,\n",
    "    do_not_unroll_columns=True,\n",
    "    preserve_layout_alignment_across_pages=True,  # Grid alignment\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"CROSS-PAGE LAYOUT ALIGNMENT\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration: preserve_layout_alignment_across_pages=True\")\n",
    "print(\"\\nBehavior:\")\n",
    "print(\"  - Maintains consistent grid across pages\")\n",
    "print(\"  - Aligns columns that span multiple pages\")\n",
    "print(\"  - Useful for consistent document structure\")\n",
    "print(\"\\nBest for:\")\n",
    "print(\"  - Books with consistent layout\")\n",
    "print(\"  - Technical manuals\")\n",
    "print(\"  - Standardized forms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Bounding Box Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only specific regions using bounding box\n",
    "\n",
    "# Bounding box values are percentages (0.0 to 1.0)\n",
    "parser_bbox = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    bbox_top=0.1,      # Start 10% from top\n",
    "    bbox_bottom=0.9,   # End at 90% from top (10% margin at bottom)\n",
    "    bbox_left=0.05,    # Start 5% from left\n",
    "    bbox_right=0.95,   # End at 95% from left (5% margin at right)\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"BOUNDING BOX EXTRACTION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration (percentages of page):\")\n",
    "print(\"  - bbox_top: 0.1 (10% from top)\")\n",
    "print(\"  - bbox_bottom: 0.9 (90% from top)\")\n",
    "print(\"  - bbox_left: 0.05 (5% from left)\")\n",
    "print(\"  - bbox_right: 0.95 (95% from left)\")\n",
    "print(\"\\nUse cases:\")\n",
    "print(\"  - Skip headers and footers\")\n",
    "print(\"  - Extract specific page regions\")\n",
    "print(\"  - Ignore page margins\")\n",
    "print(\"\\nExample - Extract only main content:\")\n",
    "print(\"  parser = LlamaParse(\")\n",
    "print(\"      bbox_top=0.15,    # Skip header\")\n",
    "print(\"      bbox_bottom=0.85, # Skip footer\")\n",
    "print(\"  )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Accessing Layout Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing layout information from results\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    extract_layout=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "pdf_path = str(SAMPLE_DIR / \"attention_paper.pdf\")\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"ACCESSING LAYOUT DATA\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    job_results = parser.parse([pdf_path])\n",
    "    \n",
    "    if job_results:\n",
    "        result = job_results[0]\n",
    "        \n",
    "        # Layout data is available per page\n",
    "        print(\"Layout data structure:\")\n",
    "        print(\"  result.pages[i].layout\")\n",
    "        print(\"\\nTypical layout information includes:\")\n",
    "        print(\"  - Bounding boxes for text blocks\")\n",
    "        print(\"  - Column definitions\")\n",
    "        print(\"  - Reading order\")\n",
    "        print(\"  - Element classifications (heading, paragraph, table, etc.)\")\n",
    "        \n",
    "        # Check first page layout\n",
    "        if result.pages:\n",
    "            page = result.pages[0]\n",
    "            print(f\"\\nPage 1 layout available: {hasattr(page, 'layout') and page.layout is not None}\")\n",
    "else:\n",
    "    print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Structured Output\n",
    "\n",
    "LlamaParse can extract structured data from documents using JSON schemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Enable Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable structured output extraction\n",
    "\n",
    "parser_structured = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    structured_output=True,  # Enable structured data extraction\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"STRUCTURED OUTPUT\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration: structured_output=True\")\n",
    "print(\"\\nBehavior:\")\n",
    "print(\"  - Extracts structured data from documents\")\n",
    "print(\"  - Returns data in JSON format\")\n",
    "print(\"  - Accessible via page.structuredData\")\n",
    "print(\"\\nAccessing structured data:\")\n",
    "print(\"  result = parser.parse(['document.pdf'])[0]\")\n",
    "print(\"  for page in result.pages:\")\n",
    "print(\"      print(page.structuredData)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Auto-Infer Schema (imFeelingLucky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-infer schema using \"imFeelingLucky\"\n",
    "\n",
    "parser_auto_schema = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    structured_output=True,\n",
    "    structured_output_json_schema_name=\"imFeelingLucky\",  # Auto-infer schema\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"AUTO-INFER SCHEMA (imFeelingLucky)\")\n",
    "print(\"=\" * 50)\n",
    "print('Configuration: structured_output_json_schema_name=\"imFeelingLucky\"')\n",
    "print(\"\\nBehavior:\")\n",
    "print(\"  - LlamaParse automatically detects document structure\")\n",
    "print(\"  - Creates appropriate JSON schema\")\n",
    "print(\"  - Great for exploring unknown document types\")\n",
    "print(\"\\nBest for:\")\n",
    "print(\"  - Quick prototyping\")\n",
    "print(\"  - Unknown document formats\")\n",
    "print(\"  - Exploratory analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Custom JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using custom JSON schema for structured extraction\n",
    "\n",
    "# Define a custom schema for academic papers\n",
    "paper_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"title\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The title of the paper\"\n",
    "        },\n",
    "        \"authors\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\"},\n",
    "            \"description\": \"List of author names\"\n",
    "        },\n",
    "        \"abstract\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The paper abstract\"\n",
    "        },\n",
    "        \"keywords\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\"},\n",
    "            \"description\": \"Keywords or topics\"\n",
    "        },\n",
    "        \"sections\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"heading\": {\"type\": \"string\"},\n",
    "                    \"content\": {\"type\": \"string\"}\n",
    "                }\n",
    "            },\n",
    "            \"description\": \"Main sections of the paper\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"title\", \"abstract\"]\n",
    "}\n",
    "\n",
    "parser_custom_schema = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    structured_output=True,\n",
    "    structured_output_json_schema=json.dumps(paper_schema),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"CUSTOM JSON SCHEMA\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Schema defined for academic papers:\")\n",
    "print(json.dumps(paper_schema, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Invoice Extraction Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom schema for invoice extraction\n",
    "\n",
    "invoice_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"invoice_number\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Invoice ID or number\"\n",
    "        },\n",
    "        \"invoice_date\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Date of the invoice\"\n",
    "        },\n",
    "        \"due_date\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Payment due date\"\n",
    "        },\n",
    "        \"vendor\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\"type\": \"string\"},\n",
    "                \"address\": {\"type\": \"string\"},\n",
    "                \"tax_id\": {\"type\": \"string\"}\n",
    "            }\n",
    "        },\n",
    "        \"customer\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\"type\": \"string\"},\n",
    "                \"address\": {\"type\": \"string\"}\n",
    "            }\n",
    "        },\n",
    "        \"line_items\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"description\": {\"type\": \"string\"},\n",
    "                    \"quantity\": {\"type\": \"number\"},\n",
    "                    \"unit_price\": {\"type\": \"number\"},\n",
    "                    \"total\": {\"type\": \"number\"}\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"subtotal\": {\"type\": \"number\"},\n",
    "        \"tax\": {\"type\": \"number\"},\n",
    "        \"total\": {\"type\": \"number\"}\n",
    "    },\n",
    "    \"required\": [\"invoice_number\", \"total\"]\n",
    "}\n",
    "\n",
    "parser_invoice = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    structured_output=True,\n",
    "    structured_output_json_schema=json.dumps(invoice_schema),\n",
    "    preset=\"invoice\",  # Combine with invoice preset\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"INVOICE EXTRACTION SCHEMA\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Schema for invoice data extraction:\")\n",
    "print(json.dumps(invoice_schema, indent=2)[:800] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Table Output Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table-specific output options\n",
    "\n",
    "# Compact markdown tables\n",
    "parser_compact = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    compact_markdown_table=True,  # More compact table output\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# HTML table output\n",
    "parser_html_tables = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    output_tables_as_HTML=True,  # Tables as HTML instead of markdown\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Adaptive long tables\n",
    "parser_long_tables = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    adaptive_long_table=True,  # Better handling of multi-page tables\n",
    "    continuous_mode=True,      # Required for long table detection\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"TABLE OUTPUT OPTIONS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n1. compact_markdown_table=True\")\n",
    "print(\"   - More compact table formatting\")\n",
    "print(\"   - Reduces whitespace\")\n",
    "print(\"\\n2. output_tables_as_HTML=True\")\n",
    "print(\"   - Tables rendered as HTML\")\n",
    "print(\"   - Better for web display\")\n",
    "print(\"\\n3. adaptive_long_table=True + continuous_mode=True\")\n",
    "print(\"   - Detects tables spanning multiple pages\")\n",
    "print(\"   - Merges into single table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary - Part 1\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "1. **Setup**: Installation, API keys, imports\n",
    "2. **Core Concepts**: JobResult structure, sync/async methods\n",
    "3. **Basic Parsing**: load_data(), parse(), page access\n",
    "4. **Presets**: fast, balanced, premium, scientific, invoice, slides\n",
    "5. **Parse Modes**: fast_mode, premium_mode, auto_mode with triggers\n",
    "6. **File Formats**: PDF, HTML, DOCX, XLSX, images\n",
    "7. **Multimodal**: Charts, screenshots, high-res OCR\n",
    "8. **Layout**: Column preservation, bounding boxes\n",
    "9. **Structured Output**: JSON schemas, auto-inference\n",
    "\n",
    "**Continue to Part 2** for:\n",
    "- Custom Prompts & Instructions\n",
    "- Advanced Configuration\n",
    "- Async Operations & Batch Processing\n",
    "- LlamaIndex Integration\n",
    "- Complete RAG Example with ChromaDB\n",
    "- CLI Usage\n",
    "- Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference - Common configurations\n",
    "\n",
    "print(\"LLAMAPARSE QUICK REFERENCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "configs = {\n",
    "    \"Fast extraction\": 'LlamaParse(fast_mode=True)',\n",
    "    \"Best quality\": 'LlamaParse(premium_mode=True)',\n",
    "    \"Scientific papers\": 'LlamaParse(preset=\"scientific\")',\n",
    "    \"Auto mode\": 'LlamaParse(auto_mode=True, auto_mode_trigger_on_table_in_page=True)',\n",
    "    \"With OCR\": 'LlamaParse(high_res_ocr=True)',\n",
    "    \"Extract charts\": 'LlamaParse(extract_charts=True)',\n",
    "    \"Preserve columns\": 'LlamaParse(do_not_unroll_columns=True)',\n",
    "    \"Structured output\": 'LlamaParse(structured_output=True)',\n",
    "}\n",
    "\n",
    "for use_case, config in configs.items():\n",
    "    print(f\"\\n{use_case}:\")\n",
    "    print(f\"  {config}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
